{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Training-a-neural-network-revolves-around-the-following-objects:\" data-toc-modified-id=\"Training-a-neural-network-revolves-around-the-following-objects:-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Training a neural network revolves around the following objects:</a></span></li><li><span><a href=\"#3.1-Relationship-between-the-netowrk,layers,loss-function,and-optimizer\" data-toc-modified-id=\"3.1-Relationship-between-the-netowrk,layers,loss-function,and-optimizer-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>3.1 Relationship between the netowrk,layers,loss function,and optimizer</a></span><ul class=\"toc-item\"><li><span><a href=\"#Layers\" data-toc-modified-id=\"Layers-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Layers</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Loss-function-and-optimizers\" data-toc-modified-id=\"Loss-function-and-optimizers-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Loss function and optimizers</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1　神经网络剖析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a neural network revolves around the following objects:\n",
    "+ Layers,which are combined into a network(or model)\n",
    "+ The input data and corresponding targets\n",
    "+ the loss funciton,which defines the feedback signal used for learning\n",
    "+ the optimizer,which determines,how learning proceeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  层，多个层组合成网络（或模型）。\n",
    "*  输入数据和相应的目标。 \n",
    "*  损失函数，即用于学习的反馈信号。\n",
    "*  优化器，决定学习过程如何进行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/3-1神经网络.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Relationship between the netowrk,layers,loss function,and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layers\n",
    "\n",
    "Simple vector data, stored in 2D tensors of shape(samples,features),is ofen processed by densely connected layers,also called fully connected or dense layers(the Dense class in Keras).Sequence data,stored in 3D tensors of shape(sample,timesteps,features),is typically processed by recurrent layers such as an LSTM layer.Image data,stored in 40 tensors,is usually processed by 2D convolution layers(Conv2D)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model\n",
    "\n",
    "+ The most common instance is a linear stack of layers,mapping a single input to a single output.\n",
    "\n",
    "+ As you move forward,you'll be exposed to a much broader variety of network topologies.Some common ones include the following:\n",
    "\n",
    "> + Two-branch networks\n",
    "> + Multithead networks\n",
    "> + Inception blocks\n",
    "\n",
    "The topology of a network defines a hypothesis space.By chossing a network topology,you constrain your space of possibilities(hypothesis space)..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function and optimizers\n",
    "\n",
    "Once the network architecture is defined,you still have to choose two more things:\n",
    "\n",
    ">+ Loss funciton(object function)- The quantity that will be minimized during training.It represents a measure of success for the task at hand.\n",
    ">+ Optimizer--Determines how the network will be updated based on the loss function.It implements a specific variant of stochastic gradient descent(SGD)\n",
    "\n",
    "+ A neural network thath has multiple outputs may have multiple loss function(one per output).But the gradient-descent process must be based on a single scalar loss value;so,for multiloss networks,all losses are combined(via averaging) into a single scalar quantity.\n",
    "+ Choosing the right objective function for the right problem is extrmely important:your network willl take any shortcut it can,to minimize the loss;so if the objective doesn't fully corelate with success for the task at hand,your network will end up doing things you may not have wanted.\n",
    "+ You'll use **binary crossentropy for a two-class classification problem**,**categorical crossentropy for a many-class classification problem**,**meansquared error for a regression problem**,connectionist temporal classification(CTC) for a sequence-learing problem,and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
