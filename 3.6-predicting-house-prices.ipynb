{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Predicting-house-prices:-a-regression-example\" data-toc-modified-id=\"Predicting-house-prices:-a-regression-example-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Predicting house prices: a regression example</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Boston-Housing-Price-dataset\" data-toc-modified-id=\"The-Boston-Housing-Price-dataset-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>The Boston Housing Price dataset</a></span></li><li><span><a href=\"#Preparing-the-data\" data-toc-modified-id=\"Preparing-the-data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Preparing the data</a></span></li><li><span><a href=\"#Building-our-network\" data-toc-modified-id=\"Building-our-network-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Building our network</a></span></li><li><span><a href=\"#Validating-our-approach-using-K-fold-validation\" data-toc-modified-id=\"Validating-our-approach-using-K-fold-validation-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Validating our approach using K-fold validation</a></span></li><li><span><a href=\"#Wrapping-up\" data-toc-modified-id=\"Wrapping-up-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Wrapping up</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6　预测房价：回归问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting house prices: a regression example\n",
    "\n",
    "This notebook contains the code samples found in Chapter 3, Section 6 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff). Note that the original text features far more content, in particular further explanations and figures: in this notebook, you will only find source code and related comments.\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "In our two previous examples, we were considering classification problems, where the goal was to predict a single discrete label of an \n",
    "input data point. Another common type of machine learning problem is \"regression\", which consists of predicting a continuous value instead \n",
    "of a discrete label. For instance, predicting the temperature tomorrow, given meteorological data, or predicting the time that a \n",
    "software project will take to complete, given its specifications.\n",
    "\n",
    "Do not mix up \"regression\" with the algorithm \"logistic regression\": confusingly, \"logistic regression\" is not a regression algorithm, \n",
    "it is a classification algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面两个例子都是分类问题，其目标是预测输入数据点所对应的单一离散的标签。另一种\n",
    "常见的机器学习问题是回归问题，它预测一个连续值而不是离散的标签，例如，根据气象数据\n",
    "预测明天的气温，或者根据软件说明书预测完成软件项目所需要的时间。 \n",
    "---\n",
    "注意 不要将回归问题与 logistic 回归算法混为一谈。令人困惑的是，logistic 回归不是回归算法，\n",
    "而是分类算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Boston Housing Price dataset\n",
    "\n",
    "\n",
    "We will be attempting to predict the median price of homes in a given Boston suburb in the mid-1970s, given a few data points about the \n",
    "suburb at the time, such as the crime rate, the local property tax rate, etc.\n",
    "\n",
    "The dataset we will be using has another interesting difference from our two previous examples: it has very few data points, only 506 in \n",
    "total, split between 404 training samples and 102 test samples, and each \"feature\" in the input data (e.g. the crime rate is a feature) has \n",
    "a different scale. For instance some values are proportions, which take a values between 0 and 1, others take values between 1 and 12, \n",
    "others between 0 and 100...\n",
    "\n",
    "Let's take a look at the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6.1　波士顿房价数据集  \n",
    "本节将要预测 20 世纪 70 年代中期波士顿郊区房屋价格的中位数，已知当时郊区的一些数\n",
    "据点，比如犯罪率、当地房产税率等。本节用到的数据集与前面两个例子有一个有趣的区别。\n",
    "它包含的数据点相对较少，只有 506 个，分为 404 个训练样本和 102 个测试样本。输入数据的\n",
    "每个特征（比如犯罪率）都有不同的取值范围。例如，有些特性是比例，取值范围为0~1,  \n",
    "有的取值范围为 1~12,还有的取值范围为 0~100，等等。    \n",
    "我们来看一下数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) =  boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 13)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As you can see, we have 404 training samples and 102 test samples. The data comprises 13 features. The 13 features in the input data are as \n",
    "follow:\n",
    "\n",
    "1. Per capita crime rate.\n",
    "2. Proportion of residential land zoned for lots over 25,000 square feet.\n",
    "3. Proportion of non-retail business acres per town.\n",
    "4. Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "5. Nitric oxides concentration (parts per 10 million).\n",
    "6. Average number of rooms per dwelling.\n",
    "7. Proportion of owner-occupied units built prior to 1940.\n",
    "8. Weighted distances to five Boston employment centres.\n",
    "9. Index of accessibility to radial highways.\n",
    "10. Full-value property-tax rate per $10,000.\n",
    "11. Pupil-teacher ratio by town.\n",
    "12. 1000 * (Bk - 0.63) ** 2 where Bk is the proportion of Black people by town.\n",
    "13. % lower status of the population.\n",
    "\n",
    "The targets are the median values of owner-occupied homes, in thousands of dollars:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如你所见，我们有 404 个训练样本和 102 个测试样本，每个样本都有 13 个数值特征，比如\n",
    "人均犯罪率、每个住宅的平均房间数、高速公路可达性等。  \n",
    "\n",
    "目标是房屋价格的中位数，单位是千美元。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n",
       "       17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n",
       "       32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n",
       "       23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n",
       "       12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n",
       "       22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n",
       "       15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n",
       "       14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n",
       "       14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n",
       "       28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n",
       "       19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n",
       "       18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n",
       "       31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n",
       "       19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n",
       "       22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n",
       "       27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n",
       "        8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n",
       "       19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n",
       "       23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n",
       "       21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n",
       "       17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n",
       "       16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n",
       "       24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n",
       "       13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n",
       "       22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n",
       "       23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n",
       "        7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n",
       "        8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n",
       "       19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n",
       "       19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n",
       "       23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n",
       "       19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n",
       "       23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n",
       "       33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n",
       "       28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n",
       "       24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n",
       "       11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The prices are typically between \\$10,000 and \\$50,000. If that sounds cheap, remember this was the mid-1970s, and these prices are not \n",
    "inflation-adjusted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "房价大都在 10 000~50 000 美元。如果你觉得这很便宜，不要忘记当时是 20 世纪 70 年代中\n",
    "期，而且这些价格没有根据通货膨胀进行调整。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "\n",
    "It would be problematic to feed into a neural network values that all take wildly different ranges. The network might be able to \n",
    "automatically adapt to such heterogeneous data, but it would definitely make learning more difficult. A widespread best practice to deal \n",
    "with such data is to do feature-wise normalization: for each feature in the input data (a column in the input data matrix), we \n",
    "will subtract the mean of the feature and divide by the standard deviation, so that the feature will be centered around 0 and will have a \n",
    "unit standard deviation. This is easily done in Numpy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6.2　准备数据  \n",
    "将取值范围差异很大的数据输入到神经网络中，这是有问题的。网络可能会自动适应这种\n",
    "取值范围不同的数据，但学习肯定变得更加困难。对于这种数据，普遍采用的最佳实践是对每\n",
    "个特征做标准化，即对于输入数据的每个特征（输入数据矩阵中的列），减去特征平均值，再除\n",
    "以标准差，这样得到的特征平均值为 0，标准差为 1。用 Numpy 可以很容易实现标准化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0) #(axis=0):y轴\n",
    "train_data -= mean #train_data=train_data-mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std #train_data=train_data/std\n",
    "\n",
    "#注意：测试集也适用训练集的mean,std\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.74511057e+00, 1.14801980e+01, 1.11044307e+01, 6.18811881e-02,\n",
       "       5.57355941e-01, 6.26708168e+00, 6.90106436e+01, 3.74027079e+00,\n",
       "       9.44059406e+00, 4.05898515e+02, 1.84759901e+01, 3.54783168e+02,\n",
       "       1.27408168e+01])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.22929073e+00, 2.37382770e+01, 6.80287253e+00, 2.40939633e-01,\n",
       "       1.17147847e-01, 7.08908627e-01, 2.79060634e+01, 2.02770050e+00,\n",
       "       8.68758849e+00, 1.66168506e+02, 2.19765689e+00, 9.39946015e+01,\n",
       "       7.24556085e+00])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note that the quantities that we use for normalizing the test data have been computed using the training data. We should never use in our \n",
    "workflow any quantity computed on the test data, even for something as simple as data normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our network\n",
    "\n",
    "\n",
    "Because so few samples are available, we will be using a very small network with two \n",
    "hidden layers, each with 64 units. In general, the less training data you have, the worse overfitting will be, and using \n",
    "a small network is one way to mitigate overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6.3　构建网络   \n",
    "由于样本数量很少，我们将使用一个非常小的网络，其中包含两个隐藏层，每层有 64 个单\n",
    "元。一般来说，训练数据越少，过拟合会越严重，而较小的网络可以降低过拟合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def build_model():\n",
    "    # Because we will need to instantiate\n",
    "    # the same model multiple times,\n",
    "    # we use a function to construct it.\n",
    "    #因为需要将同一个模型多次实例化，\n",
    "    #所以用一个函数来构建模型\n",
    "    model = models.Sequential()\n",
    "    # 训练集过少，神经网络不要太大，不然神经网络把所有东西都背下来，导致过拟合。\n",
    "    model.add(layers.Dense(64, activation='relu',\n",
    "                           input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae']) #回归使用mse，\n",
    "    #回归问题metrics使用mae：误差绝对值相加/mean\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our network ends with a single unit, and no activation (i.e. it will be linear layer). \n",
    "This is a typical setup for scalar regression (i.e. regression where we are trying to predict a single continuous value). \n",
    "Applying an activation function would constrain the range that the output can take; for instance if \n",
    "we applied a `sigmoid` activation function to our last layer, the network could only learn to predict values between 0 and 1. Here, because \n",
    "the last layer is purely linear, the network is free to learn to predict values in any range.\n",
    "\n",
    "Note that we are compiling the network with the `mse` loss function -- Mean Squared Error, the square of the difference between the \n",
    "predictions and the targets, a widely used loss function for regression problems.\n",
    "\n",
    "We are also monitoring a new metric during training: `mae`. This stands for Mean Absolute Error. It is simply the absolute value of the \n",
    "difference between the predictions and the targets. For instance, a MAE of 0.5 on this problem would mean that our predictions are off by \n",
    "\\$500 on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网络的最后一层只有一个单元，没有激活，是一个线性层。这是标量回归（标量回归是预\n",
    "测单一连续值的回归）的典型设置。添加激活函数将会限制输出范围。例如，如果向最后一层\n",
    "添加 sigmoid 激活函数，网络只能学会预测 0~1 范围内的值。这里最后一层是纯线性的，所以\n",
    "网络可以学会预测任意范围内的值。  \n",
    "\n",
    "注意，编译网络用的是 mse 损失函数，即均方误差（MSE，mean squared error），预测值与\n",
    "目标值之差的平方。这是回归问题常用的损失函数。  \n",
    "\n",
    "在训练过程中还监控一个新指标：平均绝对误差（MAE，mean absolute error）。它是预测值\n",
    "与目标值之差的绝对值。比如，如果这个问题的 MAE 等于 0.5，就表示你预测的房价与实际价\n",
    "格平均相差 500 美元。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating our approach using K-fold validation\n",
    "\n",
    "\n",
    "To evaluate our network while we keep adjusting its parameters (such as the number of epochs used for training), we could simply split the \n",
    "data into a training set and a validation set, as we were doing in our previous examples. However, because we have so few data points, the \n",
    "validation set would end up being very small (e.g. about 100 examples). A consequence is that our validation scores may change a lot \n",
    "depending on _which_ data points we choose to use for validation and which we choose for training, i.e. the validation scores may have a \n",
    "high _variance_ with regard to the validation split. This would prevent us from reliably evaluating our model.\n",
    "\n",
    "The best practice in such situations is to use K-fold cross-validation. It consists of splitting the available data into K partitions \n",
    "(typically K=4 or 5), then instantiating K identical models, and training each one on K-1 partitions while evaluating on the remaining \n",
    "partition. The validation score for the model used would then be the average of the K validation scores obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6.4　利用 K 折验证来验证你的方法  \n",
    "为了在调节网络参数（比如训练的轮数）的同时对网络进行评估，你可以将数据划分为训\n",
    "练集和验证集，正如前面例子中所做的那样。但由于数据点很少，验证集会非常小（比如大约\n",
    "100 个样本）。因此，验证分数可能会有很大波动，这取决于你所选择的验证集和训练集。也就\n",
    "是说，验证集的划分方式可能会造成验证分数上有很大的方差，这样就无法对模型进行可靠的\n",
    "评估。  \n",
    "\n",
    "在这种情况下，最佳做法是使用 K 折交叉验证（见图 3-11）。这种方法将可用数据划分为 K\n",
    "个分区（K 通常取 4 或 5），实例化 K 个相同的模型，将每个模型在 K-1 个分区上训练，并在剩\n",
    "下的一个分区上进行评估。模型的验证分数等于 K 个验证分数的平均值。这种方法的代码实现\n",
    "很简单。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/3-6-k折验证.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of code, this is straightforward:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/3-6-k折test.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Epoch 1/100\n",
      "303/303 - 0s - loss: 243.6439 - mae: 11.9128\n",
      "Epoch 2/100\n",
      "303/303 - 0s - loss: 26.8168 - mae: 3.5939\n",
      "Epoch 3/100\n",
      "303/303 - 0s - loss: 20.3108 - mae: 3.0343\n",
      "Epoch 4/100\n",
      "303/303 - 0s - loss: 17.2502 - mae: 2.7291\n",
      "Epoch 5/100\n",
      "303/303 - 0s - loss: 15.9905 - mae: 2.5514\n",
      "Epoch 6/100\n",
      "303/303 - 0s - loss: 14.9442 - mae: 2.4823\n",
      "Epoch 7/100\n",
      "303/303 - 0s - loss: 13.8999 - mae: 2.4328\n",
      "Epoch 8/100\n",
      "303/303 - 0s - loss: 13.9695 - mae: 2.3927\n",
      "Epoch 9/100\n",
      "303/303 - 0s - loss: 13.0384 - mae: 2.3246\n",
      "Epoch 10/100\n",
      "303/303 - 0s - loss: 13.0319 - mae: 2.3229\n",
      "Epoch 11/100\n",
      "303/303 - 0s - loss: 11.8862 - mae: 2.2258\n",
      "Epoch 12/100\n",
      "303/303 - 0s - loss: 11.5712 - mae: 2.2505\n",
      "Epoch 13/100\n",
      "303/303 - 0s - loss: 11.4551 - mae: 2.1945\n",
      "Epoch 14/100\n",
      "303/303 - 0s - loss: 10.7502 - mae: 2.1786\n",
      "Epoch 15/100\n",
      "303/303 - 0s - loss: 10.5967 - mae: 2.1485\n",
      "Epoch 16/100\n",
      "303/303 - 0s - loss: 10.6231 - mae: 2.1378\n",
      "Epoch 17/100\n",
      "303/303 - 0s - loss: 10.3723 - mae: 2.0954\n",
      "Epoch 18/100\n",
      "303/303 - 0s - loss: 10.0861 - mae: 2.0612\n",
      "Epoch 19/100\n",
      "303/303 - 0s - loss: 9.6569 - mae: 2.1071\n",
      "Epoch 20/100\n",
      "303/303 - 0s - loss: 9.3281 - mae: 1.9602\n",
      "Epoch 21/100\n",
      "303/303 - 0s - loss: 9.6987 - mae: 2.0218\n",
      "Epoch 22/100\n",
      "303/303 - 0s - loss: 9.1128 - mae: 2.0048\n",
      "Epoch 23/100\n",
      "303/303 - 0s - loss: 9.0106 - mae: 1.9759\n",
      "Epoch 24/100\n",
      "303/303 - 0s - loss: 8.5950 - mae: 2.0273\n",
      "Epoch 25/100\n",
      "303/303 - 0s - loss: 8.7476 - mae: 1.9468\n",
      "Epoch 26/100\n",
      "303/303 - 0s - loss: 8.7779 - mae: 1.9313\n",
      "Epoch 27/100\n",
      "303/303 - 0s - loss: 8.3049 - mae: 1.9206\n",
      "Epoch 28/100\n",
      "303/303 - 0s - loss: 7.9743 - mae: 1.8862\n",
      "Epoch 29/100\n",
      "303/303 - 0s - loss: 7.9235 - mae: 1.8120\n",
      "Epoch 30/100\n",
      "303/303 - 0s - loss: 8.0497 - mae: 1.8794\n",
      "Epoch 31/100\n",
      "303/303 - 0s - loss: 7.8869 - mae: 1.8570\n",
      "Epoch 32/100\n",
      "303/303 - 0s - loss: 7.2884 - mae: 1.8160\n",
      "Epoch 33/100\n",
      "303/303 - 0s - loss: 7.8016 - mae: 1.7931\n",
      "Epoch 34/100\n",
      "303/303 - 0s - loss: 7.2616 - mae: 1.7986\n",
      "Epoch 35/100\n",
      "303/303 - 0s - loss: 6.8761 - mae: 1.7246\n",
      "Epoch 36/100\n",
      "303/303 - 0s - loss: 6.6697 - mae: 1.7045\n",
      "Epoch 37/100\n",
      "303/303 - 0s - loss: 7.1097 - mae: 1.7846\n",
      "Epoch 38/100\n",
      "303/303 - 0s - loss: 6.9287 - mae: 1.7757\n",
      "Epoch 39/100\n",
      "303/303 - 0s - loss: 6.8052 - mae: 1.6894\n",
      "Epoch 40/100\n",
      "303/303 - 0s - loss: 6.3029 - mae: 1.7098\n",
      "Epoch 41/100\n",
      "303/303 - 0s - loss: 6.3813 - mae: 1.7189\n",
      "Epoch 42/100\n",
      "303/303 - 0s - loss: 6.2199 - mae: 1.6750\n",
      "Epoch 43/100\n",
      "303/303 - 0s - loss: 6.0081 - mae: 1.6696\n",
      "Epoch 44/100\n",
      "303/303 - 0s - loss: 6.5362 - mae: 1.6965\n",
      "Epoch 45/100\n",
      "303/303 - 0s - loss: 6.0285 - mae: 1.5935\n",
      "Epoch 46/100\n",
      "303/303 - 0s - loss: 6.3188 - mae: 1.6841\n",
      "Epoch 47/100\n",
      "303/303 - 0s - loss: 6.0429 - mae: 1.6134\n",
      "Epoch 48/100\n",
      "303/303 - 0s - loss: 6.2023 - mae: 1.6380\n",
      "Epoch 49/100\n",
      "303/303 - 0s - loss: 5.5520 - mae: 1.6089\n",
      "Epoch 50/100\n",
      "303/303 - 0s - loss: 5.7543 - mae: 1.6063\n",
      "Epoch 51/100\n",
      "303/303 - 0s - loss: 5.6652 - mae: 1.6241\n",
      "Epoch 52/100\n",
      "303/303 - 0s - loss: 5.5904 - mae: 1.5665\n",
      "Epoch 53/100\n",
      "303/303 - 0s - loss: 5.4264 - mae: 1.5922\n",
      "Epoch 54/100\n",
      "303/303 - 0s - loss: 5.5464 - mae: 1.5654\n",
      "Epoch 55/100\n",
      "303/303 - 0s - loss: 5.5109 - mae: 1.5723\n",
      "Epoch 56/100\n",
      "303/303 - 0s - loss: 5.4590 - mae: 1.5562\n",
      "Epoch 57/100\n",
      "303/303 - 0s - loss: 5.1716 - mae: 1.5540\n",
      "Epoch 58/100\n",
      "303/303 - 0s - loss: 5.4418 - mae: 1.5669\n",
      "Epoch 59/100\n",
      "303/303 - 0s - loss: 5.5151 - mae: 1.5071\n",
      "Epoch 60/100\n",
      "303/303 - 0s - loss: 5.1478 - mae: 1.5204\n",
      "Epoch 61/100\n",
      "303/303 - 0s - loss: 5.0714 - mae: 1.5170\n",
      "Epoch 62/100\n",
      "303/303 - 0s - loss: 4.8859 - mae: 1.5462\n",
      "Epoch 63/100\n",
      "303/303 - 0s - loss: 5.0525 - mae: 1.5483\n",
      "Epoch 64/100\n",
      "303/303 - 0s - loss: 4.8961 - mae: 1.5110\n",
      "Epoch 65/100\n",
      "303/303 - 0s - loss: 4.8820 - mae: 1.4935\n",
      "Epoch 66/100\n",
      "303/303 - 0s - loss: 4.7650 - mae: 1.4709\n",
      "Epoch 67/100\n",
      "303/303 - 0s - loss: 4.5862 - mae: 1.4773\n",
      "Epoch 68/100\n",
      "303/303 - 0s - loss: 4.7503 - mae: 1.5117\n",
      "Epoch 69/100\n",
      "303/303 - 0s - loss: 4.6757 - mae: 1.4145\n",
      "Epoch 70/100\n",
      "303/303 - 0s - loss: 4.6548 - mae: 1.4795\n",
      "Epoch 71/100\n",
      "303/303 - 0s - loss: 4.3182 - mae: 1.3784\n",
      "Epoch 72/100\n",
      "303/303 - 0s - loss: 4.4325 - mae: 1.4268\n",
      "Epoch 73/100\n",
      "303/303 - 0s - loss: 4.7952 - mae: 1.5509\n",
      "Epoch 74/100\n",
      "303/303 - 0s - loss: 4.2050 - mae: 1.3421\n",
      "Epoch 75/100\n",
      "303/303 - 0s - loss: 4.7798 - mae: 1.4517\n",
      "Epoch 76/100\n",
      "303/303 - 0s - loss: 4.4286 - mae: 1.4669\n",
      "Epoch 77/100\n",
      "303/303 - 0s - loss: 4.6093 - mae: 1.3946\n",
      "Epoch 78/100\n",
      "303/303 - 0s - loss: 4.2232 - mae: 1.3879\n",
      "Epoch 79/100\n",
      "303/303 - 0s - loss: 4.0540 - mae: 1.3998\n",
      "Epoch 80/100\n",
      "303/303 - 0s - loss: 4.4236 - mae: 1.3770\n",
      "Epoch 81/100\n",
      "303/303 - 0s - loss: 4.2427 - mae: 1.4135\n",
      "Epoch 82/100\n",
      "303/303 - 0s - loss: 3.9506 - mae: 1.3601\n",
      "Epoch 83/100\n",
      "303/303 - 0s - loss: 3.8915 - mae: 1.3650\n",
      "Epoch 84/100\n",
      "303/303 - 0s - loss: 3.8625 - mae: 1.3534\n",
      "Epoch 85/100\n",
      "303/303 - 0s - loss: 3.8790 - mae: 1.3346\n",
      "Epoch 86/100\n",
      "303/303 - 0s - loss: 3.9074 - mae: 1.3685\n",
      "Epoch 87/100\n",
      "303/303 - 0s - loss: 3.8218 - mae: 1.3726\n",
      "Epoch 88/100\n",
      "303/303 - 0s - loss: 4.0485 - mae: 1.3592\n",
      "Epoch 89/100\n",
      "303/303 - 0s - loss: 3.7984 - mae: 1.3521\n",
      "Epoch 90/100\n",
      "303/303 - 0s - loss: 3.8524 - mae: 1.3014\n",
      "Epoch 91/100\n",
      "303/303 - 0s - loss: 3.6499 - mae: 1.3446\n",
      "Epoch 92/100\n",
      "303/303 - 0s - loss: 3.8203 - mae: 1.3632\n",
      "Epoch 93/100\n",
      "303/303 - 0s - loss: 3.5356 - mae: 1.3105\n",
      "Epoch 94/100\n",
      "303/303 - 0s - loss: 3.3799 - mae: 1.2560\n",
      "Epoch 95/100\n",
      "303/303 - 0s - loss: 3.8326 - mae: 1.3429\n",
      "Epoch 96/100\n",
      "303/303 - 0s - loss: 3.4852 - mae: 1.3224\n",
      "Epoch 97/100\n",
      "303/303 - 0s - loss: 3.6509 - mae: 1.3222\n",
      "Epoch 98/100\n",
      "303/303 - 0s - loss: 3.4051 - mae: 1.2348\n",
      "Epoch 99/100\n",
      "303/303 - 0s - loss: 3.7218 - mae: 1.3317\n",
      "Epoch 100/100\n",
      "303/303 - 0s - loss: 3.3148 - mae: 1.2867\n",
      "4/4 - 0s - loss: 9.6118 - mae: 2.2291\n",
      "processing fold # 1\n",
      "Epoch 1/100\n",
      "303/303 - 1s - loss: 226.3436 - mae: 11.6008\n",
      "Epoch 2/100\n",
      "303/303 - 0s - loss: 33.5865 - mae: 4.0301\n",
      "Epoch 3/100\n",
      "303/303 - 0s - loss: 22.5623 - mae: 3.2347\n",
      "Epoch 4/100\n",
      "303/303 - 0s - loss: 18.5362 - mae: 2.8248\n",
      "Epoch 5/100\n",
      "303/303 - 0s - loss: 15.8574 - mae: 2.5866\n",
      "Epoch 6/100\n",
      "303/303 - 0s - loss: 14.7005 - mae: 2.4645\n",
      "Epoch 7/100\n",
      "303/303 - 0s - loss: 13.4997 - mae: 2.4054\n",
      "Epoch 8/100\n",
      "303/303 - 0s - loss: 12.4640 - mae: 2.3471\n",
      "Epoch 9/100\n",
      "303/303 - 0s - loss: 11.9343 - mae: 2.2682\n",
      "Epoch 10/100\n",
      "303/303 - 0s - loss: 11.8508 - mae: 2.2346\n",
      "Epoch 11/100\n",
      "303/303 - 0s - loss: 11.1568 - mae: 2.1916\n",
      "Epoch 12/100\n",
      "303/303 - 0s - loss: 11.1944 - mae: 2.2436\n",
      "Epoch 13/100\n",
      "303/303 - 0s - loss: 10.3744 - mae: 2.1145\n",
      "Epoch 14/100\n",
      "303/303 - 0s - loss: 10.5179 - mae: 2.1230\n",
      "Epoch 15/100\n",
      "303/303 - 0s - loss: 10.2021 - mae: 2.0911\n",
      "Epoch 16/100\n",
      "303/303 - 0s - loss: 9.9751 - mae: 2.0808\n",
      "Epoch 17/100\n",
      "303/303 - 0s - loss: 9.8175 - mae: 2.0583\n",
      "Epoch 18/100\n",
      "303/303 - 0s - loss: 8.9917 - mae: 2.0000\n",
      "Epoch 19/100\n",
      "303/303 - 0s - loss: 9.6608 - mae: 2.0107\n",
      "Epoch 20/100\n",
      "303/303 - 0s - loss: 9.4391 - mae: 2.0350\n",
      "Epoch 21/100\n",
      "303/303 - 0s - loss: 8.6322 - mae: 1.9865\n",
      "Epoch 22/100\n",
      "303/303 - 0s - loss: 9.2707 - mae: 1.9323\n",
      "Epoch 23/100\n",
      "303/303 - 0s - loss: 8.8430 - mae: 1.9696\n",
      "Epoch 24/100\n",
      "303/303 - 0s - loss: 8.8333 - mae: 1.8777\n",
      "Epoch 25/100\n",
      "303/303 - 0s - loss: 9.0331 - mae: 1.9237\n",
      "Epoch 26/100\n",
      "303/303 - 0s - loss: 8.4866 - mae: 1.9267\n",
      "Epoch 27/100\n",
      "303/303 - 0s - loss: 8.8181 - mae: 1.9244\n",
      "Epoch 28/100\n",
      "303/303 - 0s - loss: 8.3258 - mae: 1.9196\n",
      "Epoch 29/100\n",
      "303/303 - 0s - loss: 7.9557 - mae: 1.8365\n",
      "Epoch 30/100\n",
      "303/303 - 0s - loss: 7.8665 - mae: 1.8873\n",
      "Epoch 31/100\n",
      "303/303 - 0s - loss: 8.2673 - mae: 1.8567\n",
      "Epoch 32/100\n",
      "303/303 - 0s - loss: 8.1186 - mae: 1.8264\n",
      "Epoch 33/100\n",
      "303/303 - 0s - loss: 8.0038 - mae: 1.7974\n",
      "Epoch 34/100\n",
      "303/303 - 0s - loss: 7.5330 - mae: 1.7961\n",
      "Epoch 35/100\n",
      "303/303 - 0s - loss: 7.5900 - mae: 1.8080\n",
      "Epoch 36/100\n",
      "303/303 - 0s - loss: 7.4678 - mae: 1.8099\n",
      "Epoch 37/100\n",
      "303/303 - 0s - loss: 7.1116 - mae: 1.7114\n",
      "Epoch 38/100\n",
      "303/303 - 0s - loss: 7.4766 - mae: 1.7410\n",
      "Epoch 39/100\n",
      "303/303 - 0s - loss: 7.1106 - mae: 1.7741\n",
      "Epoch 40/100\n",
      "303/303 - 0s - loss: 7.2806 - mae: 1.7571\n",
      "Epoch 41/100\n",
      "303/303 - 0s - loss: 7.3269 - mae: 1.7282\n",
      "Epoch 42/100\n",
      "303/303 - 0s - loss: 7.0650 - mae: 1.7252\n",
      "Epoch 43/100\n",
      "303/303 - 0s - loss: 7.0525 - mae: 1.7445\n",
      "Epoch 44/100\n",
      "303/303 - 0s - loss: 7.1045 - mae: 1.6684\n",
      "Epoch 45/100\n",
      "303/303 - 0s - loss: 6.7325 - mae: 1.6797\n",
      "Epoch 46/100\n",
      "303/303 - 0s - loss: 6.4311 - mae: 1.7171\n",
      "Epoch 47/100\n",
      "303/303 - 0s - loss: 6.5578 - mae: 1.6212\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 - 0s - loss: 6.3094 - mae: 1.7236\n",
      "Epoch 49/100\n",
      "303/303 - 0s - loss: 6.4050 - mae: 1.6614\n",
      "Epoch 50/100\n",
      "303/303 - 0s - loss: 6.2238 - mae: 1.6375\n",
      "Epoch 51/100\n",
      "303/303 - 0s - loss: 5.9982 - mae: 1.6029\n",
      "Epoch 52/100\n",
      "303/303 - 0s - loss: 5.8187 - mae: 1.6368\n",
      "Epoch 53/100\n",
      "303/303 - 0s - loss: 6.1310 - mae: 1.5819\n",
      "Epoch 54/100\n",
      "303/303 - 0s - loss: 6.1988 - mae: 1.5485\n",
      "Epoch 55/100\n",
      "303/303 - 0s - loss: 6.0945 - mae: 1.6233\n",
      "Epoch 56/100\n",
      "303/303 - 0s - loss: 5.9908 - mae: 1.5646\n",
      "Epoch 57/100\n",
      "303/303 - 0s - loss: 6.0199 - mae: 1.5936\n",
      "Epoch 58/100\n",
      "303/303 - 0s - loss: 5.5857 - mae: 1.5771\n",
      "Epoch 59/100\n",
      "303/303 - 0s - loss: 5.8378 - mae: 1.5699\n",
      "Epoch 60/100\n",
      "303/303 - 0s - loss: 5.8142 - mae: 1.5478\n",
      "Epoch 61/100\n",
      "303/303 - 0s - loss: 5.3527 - mae: 1.5299\n",
      "Epoch 62/100\n",
      "303/303 - 0s - loss: 5.7720 - mae: 1.5721\n",
      "Epoch 63/100\n",
      "303/303 - 0s - loss: 5.8040 - mae: 1.5334\n",
      "Epoch 64/100\n",
      "303/303 - 0s - loss: 5.5012 - mae: 1.4545\n",
      "Epoch 65/100\n",
      "303/303 - 0s - loss: 5.6168 - mae: 1.5530\n",
      "Epoch 66/100\n",
      "303/303 - 0s - loss: 5.5042 - mae: 1.4916\n",
      "Epoch 67/100\n",
      "303/303 - 0s - loss: 5.2783 - mae: 1.4984\n",
      "Epoch 68/100\n",
      "303/303 - 0s - loss: 5.3391 - mae: 1.5498\n",
      "Epoch 69/100\n",
      "303/303 - 0s - loss: 5.0599 - mae: 1.5221\n",
      "Epoch 70/100\n",
      "303/303 - 0s - loss: 5.4730 - mae: 1.4795\n",
      "Epoch 71/100\n",
      "303/303 - 0s - loss: 5.2978 - mae: 1.4757\n",
      "Epoch 72/100\n",
      "303/303 - 0s - loss: 4.9999 - mae: 1.4635\n",
      "Epoch 73/100\n",
      "303/303 - 0s - loss: 5.2057 - mae: 1.4644\n",
      "Epoch 74/100\n",
      "303/303 - 0s - loss: 5.0994 - mae: 1.4460\n",
      "Epoch 75/100\n",
      "303/303 - 0s - loss: 4.4180 - mae: 1.3801\n",
      "Epoch 76/100\n",
      "303/303 - 0s - loss: 4.8779 - mae: 1.4268\n",
      "Epoch 77/100\n",
      "303/303 - 0s - loss: 4.5425 - mae: 1.3780\n",
      "Epoch 78/100\n",
      "303/303 - 0s - loss: 4.8692 - mae: 1.4333\n",
      "Epoch 79/100\n",
      "303/303 - 0s - loss: 5.0019 - mae: 1.4211\n",
      "Epoch 80/100\n",
      "303/303 - 0s - loss: 4.7091 - mae: 1.3781\n",
      "Epoch 81/100\n",
      "303/303 - 0s - loss: 4.8811 - mae: 1.3584\n",
      "Epoch 82/100\n",
      "303/303 - 0s - loss: 4.8206 - mae: 1.4258\n",
      "Epoch 83/100\n",
      "303/303 - 0s - loss: 4.7703 - mae: 1.4291\n",
      "Epoch 84/100\n",
      "303/303 - 0s - loss: 4.3667 - mae: 1.4087\n",
      "Epoch 85/100\n",
      "303/303 - 0s - loss: 4.5101 - mae: 1.3841\n",
      "Epoch 86/100\n",
      "303/303 - 0s - loss: 4.5651 - mae: 1.3436\n",
      "Epoch 87/100\n",
      "303/303 - 0s - loss: 4.5436 - mae: 1.3954\n",
      "Epoch 88/100\n",
      "303/303 - 0s - loss: 4.6532 - mae: 1.3440\n",
      "Epoch 89/100\n",
      "303/303 - 0s - loss: 4.4914 - mae: 1.4145\n",
      "Epoch 90/100\n",
      "303/303 - 0s - loss: 4.6645 - mae: 1.3418\n",
      "Epoch 91/100\n",
      "303/303 - 0s - loss: 4.1472 - mae: 1.3268\n",
      "Epoch 92/100\n",
      "303/303 - 0s - loss: 3.9859 - mae: 1.3093\n",
      "Epoch 93/100\n",
      "303/303 - 0s - loss: 4.3307 - mae: 1.2395\n",
      "Epoch 94/100\n",
      "303/303 - 0s - loss: 4.4556 - mae: 1.2891\n",
      "Epoch 95/100\n",
      "303/303 - 0s - loss: 3.9004 - mae: 1.3292\n",
      "Epoch 96/100\n",
      "303/303 - 0s - loss: 4.0382 - mae: 1.3332\n",
      "Epoch 97/100\n",
      "303/303 - 0s - loss: 3.9405 - mae: 1.2966\n",
      "Epoch 98/100\n",
      "303/303 - 0s - loss: 3.7445 - mae: 1.3000\n",
      "Epoch 99/100\n",
      "303/303 - 0s - loss: 3.8798 - mae: 1.3035\n",
      "Epoch 100/100\n",
      "303/303 - 0s - loss: 3.5522 - mae: 1.2955\n",
      "4/4 - 0s - loss: 14.3711 - mae: 2.4194\n",
      "processing fold # 2\n",
      "Epoch 1/100\n",
      "303/303 - 0s - loss: 266.4455 - mae: 13.0968\n",
      "Epoch 2/100\n",
      "303/303 - 0s - loss: 37.2870 - mae: 4.0870\n",
      "Epoch 3/100\n",
      "303/303 - 0s - loss: 22.8286 - mae: 3.2253\n",
      "Epoch 4/100\n",
      "303/303 - 0s - loss: 18.5907 - mae: 2.8632\n",
      "Epoch 5/100\n",
      "303/303 - 0s - loss: 15.9439 - mae: 2.6675\n",
      "Epoch 6/100\n",
      "303/303 - 0s - loss: 13.4731 - mae: 2.5115\n",
      "Epoch 7/100\n",
      "303/303 - 0s - loss: 12.9064 - mae: 2.3934\n",
      "Epoch 8/100\n",
      "303/303 - 0s - loss: 12.1600 - mae: 2.3142\n",
      "Epoch 9/100\n",
      "303/303 - 0s - loss: 11.5002 - mae: 2.2540\n",
      "Epoch 10/100\n",
      "303/303 - 0s - loss: 10.2802 - mae: 2.1485\n",
      "Epoch 11/100\n",
      "303/303 - 0s - loss: 10.5202 - mae: 2.1885\n",
      "Epoch 12/100\n",
      "303/303 - 0s - loss: 10.0710 - mae: 2.1308\n",
      "Epoch 13/100\n",
      "303/303 - 0s - loss: 9.5028 - mae: 2.0806\n",
      "Epoch 14/100\n",
      "303/303 - 0s - loss: 9.2062 - mae: 2.0752\n",
      "Epoch 15/100\n",
      "303/303 - 0s - loss: 8.6684 - mae: 2.0196\n",
      "Epoch 16/100\n",
      "303/303 - 0s - loss: 8.8597 - mae: 1.9911\n",
      "Epoch 17/100\n",
      "303/303 - 0s - loss: 8.3137 - mae: 1.9737\n",
      "Epoch 18/100\n",
      "303/303 - 0s - loss: 8.3583 - mae: 1.9729\n",
      "Epoch 19/100\n",
      "303/303 - 0s - loss: 8.0525 - mae: 1.9493\n",
      "Epoch 20/100\n",
      "303/303 - 0s - loss: 7.8416 - mae: 1.9288\n",
      "Epoch 21/100\n",
      "303/303 - 0s - loss: 7.2933 - mae: 1.8273\n",
      "Epoch 22/100\n",
      "303/303 - 0s - loss: 7.7149 - mae: 1.8702\n",
      "Epoch 23/100\n",
      "303/303 - 0s - loss: 7.3544 - mae: 1.8068\n",
      "Epoch 24/100\n",
      "303/303 - 0s - loss: 7.1299 - mae: 1.8389\n",
      "Epoch 25/100\n",
      "303/303 - 0s - loss: 7.0899 - mae: 1.8458\n",
      "Epoch 26/100\n",
      "303/303 - 0s - loss: 6.7861 - mae: 1.8061\n",
      "Epoch 27/100\n",
      "303/303 - 0s - loss: 6.9125 - mae: 1.8187\n",
      "Epoch 28/100\n",
      "303/303 - 0s - loss: 6.7072 - mae: 1.7671\n",
      "Epoch 29/100\n",
      "303/303 - 0s - loss: 6.3850 - mae: 1.7591\n",
      "Epoch 30/100\n",
      "303/303 - 0s - loss: 6.7587 - mae: 1.7452\n",
      "Epoch 31/100\n",
      "303/303 - 0s - loss: 6.7205 - mae: 1.7426\n",
      "Epoch 32/100\n",
      "303/303 - 0s - loss: 6.4421 - mae: 1.6805\n",
      "Epoch 33/100\n",
      "303/303 - 0s - loss: 6.5269 - mae: 1.7200\n",
      "Epoch 34/100\n",
      "303/303 - 0s - loss: 6.1821 - mae: 1.7095\n",
      "Epoch 35/100\n",
      "303/303 - 0s - loss: 6.2810 - mae: 1.6995\n",
      "Epoch 36/100\n",
      "303/303 - 0s - loss: 6.0897 - mae: 1.6916\n",
      "Epoch 37/100\n",
      "303/303 - 0s - loss: 6.0792 - mae: 1.6537\n",
      "Epoch 38/100\n",
      "303/303 - 0s - loss: 5.8516 - mae: 1.6674\n",
      "Epoch 39/100\n",
      "303/303 - 0s - loss: 5.8421 - mae: 1.6317\n",
      "Epoch 40/100\n",
      "303/303 - 0s - loss: 5.9194 - mae: 1.6532\n",
      "Epoch 41/100\n",
      "303/303 - 0s - loss: 5.7305 - mae: 1.5742\n",
      "Epoch 42/100\n",
      "303/303 - 0s - loss: 5.5777 - mae: 1.5696\n",
      "Epoch 43/100\n",
      "303/303 - 0s - loss: 5.5203 - mae: 1.5438\n",
      "Epoch 44/100\n",
      "303/303 - 0s - loss: 5.6905 - mae: 1.6244\n",
      "Epoch 45/100\n",
      "303/303 - 0s - loss: 5.6806 - mae: 1.5873\n",
      "Epoch 46/100\n",
      "303/303 - 0s - loss: 5.3200 - mae: 1.5694\n",
      "Epoch 47/100\n",
      "303/303 - 0s - loss: 5.1637 - mae: 1.5820\n",
      "Epoch 48/100\n",
      "303/303 - 0s - loss: 5.2409 - mae: 1.5472\n",
      "Epoch 49/100\n",
      "303/303 - 0s - loss: 5.3081 - mae: 1.5445\n",
      "Epoch 50/100\n",
      "303/303 - 0s - loss: 5.3394 - mae: 1.5749\n",
      "Epoch 51/100\n",
      "303/303 - 0s - loss: 4.8764 - mae: 1.5550\n",
      "Epoch 52/100\n",
      "303/303 - 0s - loss: 4.8433 - mae: 1.5345\n",
      "Epoch 53/100\n",
      "303/303 - 0s - loss: 4.9320 - mae: 1.4656\n",
      "Epoch 54/100\n",
      "303/303 - 0s - loss: 5.0295 - mae: 1.5342\n",
      "Epoch 55/100\n",
      "303/303 - 0s - loss: 4.5155 - mae: 1.4853\n",
      "Epoch 56/100\n",
      "303/303 - 0s - loss: 4.5369 - mae: 1.4889\n",
      "Epoch 57/100\n",
      "303/303 - 0s - loss: 4.7160 - mae: 1.4852\n",
      "Epoch 58/100\n",
      "303/303 - 0s - loss: 4.4147 - mae: 1.5007\n",
      "Epoch 59/100\n",
      "303/303 - 0s - loss: 4.5673 - mae: 1.4825\n",
      "Epoch 60/100\n",
      "303/303 - 0s - loss: 4.6072 - mae: 1.4454\n",
      "Epoch 61/100\n",
      "303/303 - 0s - loss: 4.2882 - mae: 1.4488\n",
      "Epoch 62/100\n",
      "303/303 - 0s - loss: 4.3055 - mae: 1.5282\n",
      "Epoch 63/100\n",
      "303/303 - 0s - loss: 4.2820 - mae: 1.4250\n",
      "Epoch 64/100\n",
      "303/303 - 0s - loss: 4.5017 - mae: 1.4704\n",
      "Epoch 65/100\n",
      "303/303 - 0s - loss: 4.2813 - mae: 1.5000\n",
      "Epoch 66/100\n",
      "303/303 - 0s - loss: 4.4111 - mae: 1.4350\n",
      "Epoch 67/100\n",
      "303/303 - 0s - loss: 4.2556 - mae: 1.3928\n",
      "Epoch 68/100\n",
      "303/303 - 0s - loss: 4.2658 - mae: 1.4476\n",
      "Epoch 69/100\n",
      "303/303 - 0s - loss: 4.1772 - mae: 1.4208\n",
      "Epoch 70/100\n",
      "303/303 - 0s - loss: 3.8656 - mae: 1.3240\n",
      "Epoch 71/100\n",
      "303/303 - 0s - loss: 4.0970 - mae: 1.3470\n",
      "Epoch 72/100\n",
      "303/303 - 0s - loss: 4.0178 - mae: 1.4152\n",
      "Epoch 73/100\n",
      "303/303 - 0s - loss: 4.0093 - mae: 1.3364\n",
      "Epoch 74/100\n",
      "303/303 - 0s - loss: 3.6848 - mae: 1.3756\n",
      "Epoch 75/100\n",
      "303/303 - 0s - loss: 3.9087 - mae: 1.3920\n",
      "Epoch 76/100\n",
      "303/303 - 0s - loss: 3.7479 - mae: 1.3218\n",
      "Epoch 77/100\n",
      "303/303 - 0s - loss: 3.7634 - mae: 1.3579\n",
      "Epoch 78/100\n",
      "303/303 - 0s - loss: 3.3677 - mae: 1.3193\n",
      "Epoch 79/100\n",
      "303/303 - 0s - loss: 3.6293 - mae: 1.2829\n",
      "Epoch 80/100\n",
      "303/303 - 0s - loss: 3.7404 - mae: 1.3808\n",
      "Epoch 81/100\n",
      "303/303 - 0s - loss: 3.3670 - mae: 1.2937\n",
      "Epoch 82/100\n",
      "303/303 - 0s - loss: 3.6946 - mae: 1.3203\n",
      "Epoch 83/100\n",
      "303/303 - 0s - loss: 3.3505 - mae: 1.2604\n",
      "Epoch 84/100\n",
      "303/303 - 0s - loss: 3.4070 - mae: 1.2523\n",
      "Epoch 85/100\n",
      "303/303 - 0s - loss: 3.3086 - mae: 1.3000\n",
      "Epoch 86/100\n",
      "303/303 - 0s - loss: 3.2782 - mae: 1.2932\n",
      "Epoch 87/100\n",
      "303/303 - 0s - loss: 3.2166 - mae: 1.2636\n",
      "Epoch 88/100\n",
      "303/303 - 0s - loss: 2.9680 - mae: 1.2199\n",
      "Epoch 89/100\n",
      "303/303 - 0s - loss: 3.3310 - mae: 1.2977\n",
      "Epoch 90/100\n",
      "303/303 - 0s - loss: 3.2338 - mae: 1.2556\n",
      "Epoch 91/100\n",
      "303/303 - 0s - loss: 3.2020 - mae: 1.2513\n",
      "Epoch 92/100\n",
      "303/303 - 0s - loss: 2.8976 - mae: 1.2015\n",
      "Epoch 93/100\n",
      "303/303 - 0s - loss: 3.0866 - mae: 1.2325\n",
      "Epoch 94/100\n",
      "303/303 - 0s - loss: 2.8644 - mae: 1.1870\n",
      "Epoch 95/100\n",
      "303/303 - 0s - loss: 3.0356 - mae: 1.2148\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 - 0s - loss: 2.8307 - mae: 1.2076\n",
      "Epoch 97/100\n",
      "303/303 - 0s - loss: 2.8683 - mae: 1.2047\n",
      "Epoch 98/100\n",
      "303/303 - 0s - loss: 2.7992 - mae: 1.1425\n",
      "Epoch 99/100\n",
      "303/303 - 0s - loss: 2.9115 - mae: 1.2528\n",
      "Epoch 100/100\n",
      "303/303 - 0s - loss: 2.7362 - mae: 1.1752\n",
      "4/4 - 0s - loss: 15.1789 - mae: 2.6657\n",
      "processing fold # 3\n",
      "Epoch 1/100\n",
      "303/303 - 0s - loss: 212.6852 - mae: 11.0594\n",
      "Epoch 2/100\n",
      "303/303 - 0s - loss: 32.1947 - mae: 3.7689\n",
      "Epoch 3/100\n",
      "303/303 - 0s - loss: 21.4091 - mae: 3.0991\n",
      "Epoch 4/100\n",
      "303/303 - 0s - loss: 18.4126 - mae: 2.8268\n",
      "Epoch 5/100\n",
      "303/303 - 0s - loss: 15.5728 - mae: 2.5740\n",
      "Epoch 6/100\n",
      "303/303 - 0s - loss: 14.3995 - mae: 2.4382\n",
      "Epoch 7/100\n",
      "303/303 - 0s - loss: 13.1454 - mae: 2.3559\n",
      "Epoch 8/100\n",
      "303/303 - 0s - loss: 12.5458 - mae: 2.2639\n",
      "Epoch 9/100\n",
      "303/303 - 0s - loss: 12.3567 - mae: 2.2619\n",
      "Epoch 10/100\n",
      "303/303 - 0s - loss: 11.4326 - mae: 2.1793\n",
      "Epoch 11/100\n",
      "303/303 - 0s - loss: 11.1951 - mae: 2.1658\n",
      "Epoch 12/100\n",
      "303/303 - 0s - loss: 10.7991 - mae: 2.0515\n",
      "Epoch 13/100\n",
      "303/303 - 0s - loss: 10.5133 - mae: 2.1486\n",
      "Epoch 14/100\n",
      "303/303 - 0s - loss: 10.4438 - mae: 2.0999\n",
      "Epoch 15/100\n",
      "303/303 - 0s - loss: 10.0085 - mae: 1.9785\n",
      "Epoch 16/100\n",
      "303/303 - 0s - loss: 9.7142 - mae: 1.9636\n",
      "Epoch 17/100\n",
      "303/303 - 0s - loss: 8.7677 - mae: 1.9555\n",
      "Epoch 18/100\n",
      "303/303 - 0s - loss: 9.0843 - mae: 1.9824\n",
      "Epoch 19/100\n",
      "303/303 - 0s - loss: 9.2999 - mae: 1.9587\n",
      "Epoch 20/100\n",
      "303/303 - 0s - loss: 8.9643 - mae: 1.9374\n",
      "Epoch 21/100\n",
      "303/303 - 0s - loss: 8.0136 - mae: 1.8765\n",
      "Epoch 22/100\n",
      "303/303 - 0s - loss: 8.4234 - mae: 1.9183\n",
      "Epoch 23/100\n",
      "303/303 - 0s - loss: 8.1164 - mae: 1.8304\n",
      "Epoch 24/100\n",
      "303/303 - 0s - loss: 8.0596 - mae: 1.8521\n",
      "Epoch 25/100\n",
      "303/303 - 0s - loss: 8.0013 - mae: 1.8210\n",
      "Epoch 26/100\n",
      "303/303 - 0s - loss: 7.7363 - mae: 1.8705\n",
      "Epoch 27/100\n",
      "303/303 - 0s - loss: 7.4758 - mae: 1.8134\n",
      "Epoch 28/100\n",
      "303/303 - 0s - loss: 7.2515 - mae: 1.7381\n",
      "Epoch 29/100\n",
      "303/303 - 0s - loss: 7.2253 - mae: 1.7797\n",
      "Epoch 30/100\n",
      "303/303 - 0s - loss: 7.3280 - mae: 1.8009\n",
      "Epoch 31/100\n",
      "303/303 - 0s - loss: 7.5132 - mae: 1.7162\n",
      "Epoch 32/100\n",
      "303/303 - 0s - loss: 6.7826 - mae: 1.7378\n",
      "Epoch 33/100\n",
      "303/303 - 0s - loss: 6.6578 - mae: 1.7169\n",
      "Epoch 34/100\n",
      "303/303 - 0s - loss: 6.9887 - mae: 1.6709\n",
      "Epoch 35/100\n",
      "303/303 - 0s - loss: 6.6382 - mae: 1.7004\n",
      "Epoch 36/100\n",
      "303/303 - 0s - loss: 6.6206 - mae: 1.6374\n",
      "Epoch 37/100\n",
      "303/303 - 0s - loss: 6.5236 - mae: 1.6758\n",
      "Epoch 38/100\n",
      "303/303 - 0s - loss: 6.4756 - mae: 1.6430\n",
      "Epoch 39/100\n",
      "303/303 - 0s - loss: 6.2921 - mae: 1.6209\n",
      "Epoch 40/100\n",
      "303/303 - 0s - loss: 6.3507 - mae: 1.6608\n",
      "Epoch 41/100\n",
      "303/303 - 0s - loss: 6.3297 - mae: 1.6272\n",
      "Epoch 42/100\n",
      "303/303 - 0s - loss: 6.1061 - mae: 1.5880\n",
      "Epoch 43/100\n",
      "303/303 - 0s - loss: 6.0202 - mae: 1.6032\n",
      "Epoch 44/100\n",
      "303/303 - 0s - loss: 6.1208 - mae: 1.6472\n",
      "Epoch 45/100\n",
      "303/303 - 0s - loss: 6.0165 - mae: 1.5972\n",
      "Epoch 46/100\n",
      "303/303 - 0s - loss: 6.2474 - mae: 1.5840\n",
      "Epoch 47/100\n",
      "303/303 - 0s - loss: 5.8675 - mae: 1.5877\n",
      "Epoch 48/100\n",
      "303/303 - 0s - loss: 6.0770 - mae: 1.5670\n",
      "Epoch 49/100\n",
      "303/303 - 0s - loss: 5.8956 - mae: 1.5627\n",
      "Epoch 50/100\n",
      "303/303 - 0s - loss: 5.6843 - mae: 1.5510\n",
      "Epoch 51/100\n",
      "303/303 - 0s - loss: 5.4155 - mae: 1.4945\n",
      "Epoch 52/100\n",
      "303/303 - 0s - loss: 5.6817 - mae: 1.5800\n",
      "Epoch 53/100\n",
      "303/303 - 0s - loss: 5.4276 - mae: 1.4982\n",
      "Epoch 54/100\n",
      "303/303 - 0s - loss: 5.5131 - mae: 1.5342\n",
      "Epoch 55/100\n",
      "303/303 - 0s - loss: 5.4401 - mae: 1.4661\n",
      "Epoch 56/100\n",
      "303/303 - 0s - loss: 5.2892 - mae: 1.5034\n",
      "Epoch 57/100\n",
      "303/303 - 0s - loss: 5.5600 - mae: 1.4831\n",
      "Epoch 58/100\n",
      "303/303 - 0s - loss: 5.6055 - mae: 1.4679\n",
      "Epoch 59/100\n",
      "303/303 - 0s - loss: 5.2169 - mae: 1.4435\n",
      "Epoch 60/100\n",
      "303/303 - 0s - loss: 5.1771 - mae: 1.5203\n",
      "Epoch 61/100\n",
      "303/303 - 0s - loss: 5.4190 - mae: 1.4453\n",
      "Epoch 62/100\n",
      "303/303 - 0s - loss: 5.3231 - mae: 1.4805\n",
      "Epoch 63/100\n",
      "303/303 - 0s - loss: 4.9064 - mae: 1.4356\n",
      "Epoch 64/100\n",
      "303/303 - 0s - loss: 5.2426 - mae: 1.4300\n",
      "Epoch 65/100\n",
      "303/303 - 0s - loss: 4.8743 - mae: 1.4910\n",
      "Epoch 66/100\n",
      "303/303 - 0s - loss: 5.0372 - mae: 1.4394\n",
      "Epoch 67/100\n",
      "303/303 - 0s - loss: 5.1419 - mae: 1.4562\n",
      "Epoch 68/100\n",
      "303/303 - 0s - loss: 5.1614 - mae: 1.3866\n",
      "Epoch 69/100\n",
      "303/303 - 0s - loss: 4.7674 - mae: 1.4544\n",
      "Epoch 70/100\n",
      "303/303 - 0s - loss: 4.8687 - mae: 1.4132\n",
      "Epoch 71/100\n",
      "303/303 - 0s - loss: 4.7810 - mae: 1.4275\n",
      "Epoch 72/100\n",
      "303/303 - 0s - loss: 4.6505 - mae: 1.4201\n",
      "Epoch 73/100\n",
      "303/303 - 0s - loss: 4.6633 - mae: 1.4008\n",
      "Epoch 74/100\n",
      "303/303 - 0s - loss: 4.6303 - mae: 1.4075\n",
      "Epoch 75/100\n",
      "303/303 - 0s - loss: 4.8073 - mae: 1.4013\n",
      "Epoch 76/100\n",
      "303/303 - 0s - loss: 4.4646 - mae: 1.3883\n",
      "Epoch 77/100\n",
      "303/303 - 0s - loss: 4.3040 - mae: 1.3627\n",
      "Epoch 78/100\n",
      "303/303 - 0s - loss: 4.3036 - mae: 1.3377\n",
      "Epoch 79/100\n",
      "303/303 - 0s - loss: 4.3078 - mae: 1.3866\n",
      "Epoch 80/100\n",
      "303/303 - 0s - loss: 4.2292 - mae: 1.3162\n",
      "Epoch 81/100\n",
      "303/303 - 0s - loss: 4.4494 - mae: 1.3569\n",
      "Epoch 82/100\n",
      "303/303 - 0s - loss: 4.3190 - mae: 1.3106\n",
      "Epoch 83/100\n",
      "303/303 - 0s - loss: 4.1481 - mae: 1.3557\n",
      "Epoch 84/100\n",
      "303/303 - 0s - loss: 4.3737 - mae: 1.3230\n",
      "Epoch 85/100\n",
      "303/303 - 0s - loss: 4.4294 - mae: 1.2853\n",
      "Epoch 86/100\n",
      "303/303 - 0s - loss: 4.1803 - mae: 1.3263\n",
      "Epoch 87/100\n",
      "303/303 - 0s - loss: 4.1319 - mae: 1.3202\n",
      "Epoch 88/100\n",
      "303/303 - 0s - loss: 4.3030 - mae: 1.3158\n",
      "Epoch 89/100\n",
      "303/303 - 0s - loss: 4.1533 - mae: 1.2497\n",
      "Epoch 90/100\n",
      "303/303 - 0s - loss: 3.9520 - mae: 1.3330\n",
      "Epoch 91/100\n",
      "303/303 - 0s - loss: 4.1514 - mae: 1.3139\n",
      "Epoch 92/100\n",
      "303/303 - 0s - loss: 3.8363 - mae: 1.3024\n",
      "Epoch 93/100\n",
      "303/303 - 0s - loss: 3.8428 - mae: 1.2286\n",
      "Epoch 94/100\n",
      "303/303 - 0s - loss: 3.8507 - mae: 1.2446\n",
      "Epoch 95/100\n",
      "303/303 - 0s - loss: 3.8723 - mae: 1.2674\n",
      "Epoch 96/100\n",
      "303/303 - 0s - loss: 4.0304 - mae: 1.2805\n",
      "Epoch 97/100\n",
      "303/303 - 0s - loss: 3.6510 - mae: 1.2505\n",
      "Epoch 98/100\n",
      "303/303 - 0s - loss: 3.9113 - mae: 1.2847\n",
      "Epoch 99/100\n",
      "303/303 - 0s - loss: 3.8276 - mae: 1.2154\n",
      "Epoch 100/100\n",
      "303/303 - 0s - loss: 3.6678 - mae: 1.2018\n",
      "4/4 - 0s - loss: 14.3579 - mae: 2.6473\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 4\n",
    "num_val_samples = len(train_data) // k #取商，不取余数\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "for i in range(k): #range(k):[0,1,2,3]\n",
    "    print('processing fold #', i)\n",
    "    # Prepare the validation data: data from partition # k\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    # Prepare the training data: data from all other partitions\n",
    "    #准备训练数据：其他所有分区的数据\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "         train_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    # Build the Keras model (already compiled)\n",
    "    model = build_model()\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    model.fit(partial_train_data, partial_train_targets,\n",
    "              epochs=num_epochs, batch_size=1, verbose=2) #verbose=2有个详细的进度条\n",
    "    # Evaluate the model on the validation data\n",
    "    #在验证数据上评估模型\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=2)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.3048720359802246,\n",
       " 2.8682219982147217,\n",
       " 2.9376931190490723,\n",
       " 2.4940178394317627]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6512012481689453"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As you can notice, the different runs do indeed show rather different validation scores, from 2.1 to 2.9. Their average (2.4) is a much more \n",
    "reliable metric than any single of these scores -- that's the entire point of K-fold cross-validation. In this case, we are off by \\$2,400 on \n",
    "average, which is still significant considering that the prices range from \\$10,000 to \\$50,000. \n",
    "\n",
    "Let's try training the network for a bit longer: 500 epochs. To keep a record of how well the model did at each epoch, we will modify our training loop \n",
    "to save the per-epoch validation score log:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每次运行模型得到的验证分数有很大差异，从 2.6 到 3.2 不等。平均分数（3.0）是比单一\n",
    "分数更可靠的指标——这就是 K 折交叉验证的关键。在这个例子中，预测的房价与实际价格平\n",
    "均相差 3000 美元，考虑到实际价格范围在 10 000~50 000 美元，这一差别还是很大的。  \n",
    "\n",
    "我们让训练时间更长一点，达到 500 个轮次。为了记录模型在每轮的表现，我们需要修改\n",
    "训练循环，以保存每轮的验证分数记录。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./images/3-6-k折过拟合.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# Some memory clean-up\n",
    "#清空memory\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "Epoch 1/500\n",
      "303/303 - 1s - loss: 182.1284 - mae: 10.4269 - val_loss: 37.5010 - val_mae: 4.3407\n",
      "Epoch 2/500\n",
      "303/303 - 0s - loss: 28.2725 - mae: 3.7356 - val_loss: 21.7619 - val_mae: 2.9673\n",
      "Epoch 3/500\n",
      "303/303 - 0s - loss: 19.5603 - mae: 3.0267 - val_loss: 17.0062 - val_mae: 2.7651\n",
      "Epoch 4/500\n",
      "303/303 - 0s - loss: 16.3355 - mae: 2.7504 - val_loss: 15.5895 - val_mae: 2.6792\n",
      "Epoch 5/500\n",
      "303/303 - 0s - loss: 15.3614 - mae: 2.6664 - val_loss: 13.7184 - val_mae: 2.3203\n",
      "Epoch 6/500\n",
      "303/303 - 0s - loss: 14.3024 - mae: 2.5025 - val_loss: 12.8157 - val_mae: 2.3405\n",
      "Epoch 7/500\n",
      "303/303 - 0s - loss: 13.1547 - mae: 2.4397 - val_loss: 12.6011 - val_mae: 2.4622\n",
      "Epoch 8/500\n",
      "303/303 - 0s - loss: 12.7764 - mae: 2.3607 - val_loss: 12.3023 - val_mae: 2.3548\n",
      "Epoch 9/500\n",
      "303/303 - 0s - loss: 11.6162 - mae: 2.2936 - val_loss: 13.6168 - val_mae: 2.8013\n",
      "Epoch 10/500\n",
      "303/303 - 0s - loss: 12.1588 - mae: 2.3328 - val_loss: 10.2824 - val_mae: 2.0079\n",
      "Epoch 11/500\n",
      "303/303 - 0s - loss: 11.8029 - mae: 2.2173 - val_loss: 10.7523 - val_mae: 2.0932\n",
      "Epoch 12/500\n",
      "303/303 - 0s - loss: 11.0007 - mae: 2.1981 - val_loss: 10.3573 - val_mae: 1.9811\n",
      "Epoch 13/500\n",
      "303/303 - 0s - loss: 10.3239 - mae: 2.1755 - val_loss: 10.7068 - val_mae: 2.1007\n",
      "Epoch 14/500\n",
      "303/303 - 0s - loss: 10.9565 - mae: 2.2137 - val_loss: 10.0313 - val_mae: 2.1457\n",
      "Epoch 15/500\n",
      "303/303 - 0s - loss: 10.6846 - mae: 2.1894 - val_loss: 8.8968 - val_mae: 1.9017\n",
      "Epoch 16/500\n",
      "303/303 - 0s - loss: 10.2266 - mae: 2.0802 - val_loss: 9.3283 - val_mae: 2.1307\n",
      "Epoch 17/500\n",
      "303/303 - 0s - loss: 9.5819 - mae: 1.9856 - val_loss: 9.0114 - val_mae: 2.0190\n",
      "Epoch 18/500\n",
      "303/303 - 0s - loss: 9.6132 - mae: 2.0160 - val_loss: 10.8713 - val_mae: 2.4471\n",
      "Epoch 19/500\n",
      "303/303 - 0s - loss: 9.4120 - mae: 2.0134 - val_loss: 10.4473 - val_mae: 2.0007\n",
      "Epoch 20/500\n",
      "303/303 - 0s - loss: 9.7764 - mae: 2.0093 - val_loss: 10.1500 - val_mae: 2.1148\n",
      "Epoch 21/500\n",
      "303/303 - 0s - loss: 9.7078 - mae: 2.0364 - val_loss: 8.9539 - val_mae: 1.8910\n",
      "Epoch 22/500\n",
      "303/303 - 0s - loss: 8.7871 - mae: 1.9902 - val_loss: 9.4251 - val_mae: 1.9310\n",
      "Epoch 23/500\n",
      "303/303 - 0s - loss: 9.1147 - mae: 1.9764 - val_loss: 8.6239 - val_mae: 2.0102\n",
      "Epoch 24/500\n",
      "303/303 - 0s - loss: 8.9254 - mae: 1.9402 - val_loss: 8.2556 - val_mae: 1.9582\n",
      "Epoch 25/500\n",
      "303/303 - 0s - loss: 8.3226 - mae: 1.9633 - val_loss: 8.9044 - val_mae: 2.0435\n",
      "Epoch 26/500\n",
      "303/303 - 0s - loss: 8.1245 - mae: 1.8807 - val_loss: 9.2962 - val_mae: 1.9282\n",
      "Epoch 27/500\n",
      "303/303 - 0s - loss: 8.8144 - mae: 1.8878 - val_loss: 7.4714 - val_mae: 1.9102\n",
      "Epoch 28/500\n",
      "303/303 - 0s - loss: 8.0232 - mae: 1.9187 - val_loss: 7.4965 - val_mae: 1.8347\n",
      "Epoch 29/500\n",
      "303/303 - 0s - loss: 7.8030 - mae: 1.8142 - val_loss: 7.5386 - val_mae: 1.9426\n",
      "Epoch 30/500\n",
      "303/303 - 0s - loss: 8.5392 - mae: 1.9110 - val_loss: 8.3068 - val_mae: 2.1337\n",
      "Epoch 31/500\n",
      "303/303 - 0s - loss: 7.9603 - mae: 1.8555 - val_loss: 7.7072 - val_mae: 1.9686\n",
      "Epoch 32/500\n",
      "303/303 - 0s - loss: 7.8219 - mae: 1.8562 - val_loss: 7.4268 - val_mae: 1.7718\n",
      "Epoch 33/500\n",
      "303/303 - 0s - loss: 7.3661 - mae: 1.7905 - val_loss: 9.3916 - val_mae: 2.0223\n",
      "Epoch 34/500\n",
      "303/303 - 0s - loss: 7.5648 - mae: 1.8331 - val_loss: 7.1589 - val_mae: 1.9088\n",
      "Epoch 35/500\n",
      "303/303 - 0s - loss: 7.6832 - mae: 1.8432 - val_loss: 7.5338 - val_mae: 1.8486\n",
      "Epoch 36/500\n",
      "303/303 - 0s - loss: 7.1780 - mae: 1.7295 - val_loss: 8.2640 - val_mae: 2.1104\n",
      "Epoch 37/500\n",
      "303/303 - 0s - loss: 7.2372 - mae: 1.7907 - val_loss: 7.0397 - val_mae: 1.7407\n",
      "Epoch 38/500\n",
      "303/303 - 0s - loss: 6.9744 - mae: 1.8217 - val_loss: 7.1002 - val_mae: 1.8182\n",
      "Epoch 39/500\n",
      "303/303 - 0s - loss: 7.1895 - mae: 1.7753 - val_loss: 8.7765 - val_mae: 2.1872\n",
      "Epoch 40/500\n",
      "303/303 - 0s - loss: 6.9836 - mae: 1.7506 - val_loss: 7.5353 - val_mae: 1.8970\n",
      "Epoch 41/500\n",
      "303/303 - 0s - loss: 7.1249 - mae: 1.7721 - val_loss: 8.7412 - val_mae: 2.1882\n",
      "Epoch 42/500\n",
      "303/303 - 0s - loss: 6.5558 - mae: 1.6818 - val_loss: 7.6030 - val_mae: 1.9859\n",
      "Epoch 43/500\n",
      "303/303 - 0s - loss: 7.1218 - mae: 1.7529 - val_loss: 7.3216 - val_mae: 1.9212\n",
      "Epoch 44/500\n",
      "303/303 - 0s - loss: 6.7263 - mae: 1.7400 - val_loss: 8.6288 - val_mae: 2.1719\n",
      "Epoch 45/500\n",
      "303/303 - 0s - loss: 6.7123 - mae: 1.7210 - val_loss: 6.9071 - val_mae: 1.8899\n",
      "Epoch 46/500\n",
      "303/303 - 0s - loss: 6.8565 - mae: 1.7512 - val_loss: 6.9288 - val_mae: 1.7924\n",
      "Epoch 47/500\n",
      "303/303 - 0s - loss: 6.1986 - mae: 1.7023 - val_loss: 7.9511 - val_mae: 2.1528\n",
      "Epoch 48/500\n",
      "303/303 - 0s - loss: 6.4314 - mae: 1.6383 - val_loss: 7.2896 - val_mae: 1.8925\n",
      "Epoch 49/500\n",
      "303/303 - 0s - loss: 6.6362 - mae: 1.7119 - val_loss: 8.1679 - val_mae: 1.9373\n",
      "Epoch 50/500\n",
      "303/303 - 0s - loss: 6.6800 - mae: 1.7091 - val_loss: 6.8910 - val_mae: 1.7536\n",
      "Epoch 51/500\n",
      "303/303 - 0s - loss: 6.4258 - mae: 1.7157 - val_loss: 8.2197 - val_mae: 1.9513\n",
      "Epoch 52/500\n",
      "303/303 - 0s - loss: 6.6999 - mae: 1.6871 - val_loss: 7.0520 - val_mae: 1.7093\n",
      "Epoch 53/500\n",
      "303/303 - 0s - loss: 5.8364 - mae: 1.6167 - val_loss: 7.0270 - val_mae: 1.9080\n",
      "Epoch 54/500\n",
      "303/303 - 0s - loss: 6.1270 - mae: 1.7200 - val_loss: 8.5571 - val_mae: 2.0815\n",
      "Epoch 55/500\n",
      "303/303 - 0s - loss: 6.3504 - mae: 1.6694 - val_loss: 7.4652 - val_mae: 1.9723\n",
      "Epoch 56/500\n",
      "303/303 - 0s - loss: 6.5172 - mae: 1.6792 - val_loss: 7.0132 - val_mae: 1.9348\n",
      "Epoch 57/500\n",
      "303/303 - 0s - loss: 6.1400 - mae: 1.6390 - val_loss: 6.9475 - val_mae: 1.8953\n",
      "Epoch 58/500\n",
      "303/303 - 0s - loss: 5.8037 - mae: 1.5721 - val_loss: 8.0958 - val_mae: 2.1075\n",
      "Epoch 59/500\n",
      "303/303 - 0s - loss: 6.0825 - mae: 1.6549 - val_loss: 6.8513 - val_mae: 1.6940\n",
      "Epoch 60/500\n",
      "303/303 - 0s - loss: 5.9387 - mae: 1.6011 - val_loss: 6.7859 - val_mae: 1.9009\n",
      "Epoch 61/500\n",
      "303/303 - 0s - loss: 5.8864 - mae: 1.5917 - val_loss: 6.9254 - val_mae: 1.8034\n",
      "Epoch 62/500\n",
      "303/303 - 0s - loss: 5.6538 - mae: 1.6522 - val_loss: 7.5559 - val_mae: 1.9492\n",
      "Epoch 63/500\n",
      "303/303 - 0s - loss: 5.5369 - mae: 1.5633 - val_loss: 8.0727 - val_mae: 1.9956\n",
      "Epoch 64/500\n",
      "303/303 - 0s - loss: 5.7375 - mae: 1.5388 - val_loss: 7.4561 - val_mae: 1.8822\n",
      "Epoch 65/500\n",
      "303/303 - 0s - loss: 5.3456 - mae: 1.5689 - val_loss: 9.3946 - val_mae: 2.3756\n",
      "Epoch 66/500\n",
      "303/303 - 0s - loss: 5.8073 - mae: 1.6023 - val_loss: 7.6424 - val_mae: 1.9273\n",
      "Epoch 67/500\n",
      "303/303 - 0s - loss: 5.3834 - mae: 1.5972 - val_loss: 6.9835 - val_mae: 1.9646\n",
      "Epoch 68/500\n",
      "303/303 - 0s - loss: 5.3990 - mae: 1.5351 - val_loss: 6.8137 - val_mae: 1.8909\n",
      "Epoch 69/500\n",
      "303/303 - 0s - loss: 5.2293 - mae: 1.5210 - val_loss: 6.7798 - val_mae: 1.8654\n",
      "Epoch 70/500\n",
      "303/303 - 0s - loss: 5.4013 - mae: 1.5765 - val_loss: 7.6253 - val_mae: 2.0180\n",
      "Epoch 71/500\n",
      "303/303 - 0s - loss: 5.7036 - mae: 1.5040 - val_loss: 9.6273 - val_mae: 2.3414\n",
      "Epoch 72/500\n",
      "303/303 - 0s - loss: 5.4378 - mae: 1.5706 - val_loss: 7.0153 - val_mae: 1.7751\n",
      "Epoch 73/500\n",
      "303/303 - 0s - loss: 5.1437 - mae: 1.5513 - val_loss: 6.9395 - val_mae: 1.8297\n",
      "Epoch 74/500\n",
      "303/303 - 0s - loss: 5.3333 - mae: 1.4983 - val_loss: 7.1793 - val_mae: 1.8620\n",
      "Epoch 75/500\n",
      "303/303 - 0s - loss: 5.0262 - mae: 1.4491 - val_loss: 7.2093 - val_mae: 2.0010\n",
      "Epoch 76/500\n",
      "303/303 - 0s - loss: 5.0925 - mae: 1.6031 - val_loss: 6.3723 - val_mae: 1.7631\n",
      "Epoch 77/500\n",
      "303/303 - 0s - loss: 5.0041 - mae: 1.5286 - val_loss: 7.7565 - val_mae: 2.1440\n",
      "Epoch 78/500\n",
      "303/303 - 0s - loss: 4.8654 - mae: 1.5099 - val_loss: 8.2745 - val_mae: 2.1085\n",
      "Epoch 79/500\n",
      "303/303 - 0s - loss: 4.5448 - mae: 1.4651 - val_loss: 6.9246 - val_mae: 1.7801\n",
      "Epoch 80/500\n",
      "303/303 - 0s - loss: 4.6411 - mae: 1.4275 - val_loss: 8.1295 - val_mae: 2.1063\n",
      "Epoch 81/500\n",
      "303/303 - 0s - loss: 4.9112 - mae: 1.4732 - val_loss: 6.4817 - val_mae: 1.7813\n",
      "Epoch 82/500\n",
      "303/303 - 0s - loss: 4.8184 - mae: 1.4698 - val_loss: 6.7131 - val_mae: 1.7514\n",
      "Epoch 83/500\n",
      "303/303 - 0s - loss: 4.7862 - mae: 1.4907 - val_loss: 6.8399 - val_mae: 1.7310\n",
      "Epoch 84/500\n",
      "303/303 - 0s - loss: 4.8871 - mae: 1.4757 - val_loss: 8.2816 - val_mae: 2.0790\n",
      "Epoch 85/500\n",
      "303/303 - 0s - loss: 4.7639 - mae: 1.4497 - val_loss: 6.8399 - val_mae: 1.8452\n",
      "Epoch 86/500\n",
      "303/303 - 0s - loss: 4.5284 - mae: 1.4073 - val_loss: 7.6884 - val_mae: 2.0409\n",
      "Epoch 87/500\n",
      "303/303 - 0s - loss: 4.5469 - mae: 1.4302 - val_loss: 6.8049 - val_mae: 1.9059\n",
      "Epoch 88/500\n",
      "303/303 - 0s - loss: 4.4072 - mae: 1.3648 - val_loss: 7.0795 - val_mae: 1.7931\n",
      "Epoch 89/500\n",
      "303/303 - 0s - loss: 4.5211 - mae: 1.4130 - val_loss: 8.5844 - val_mae: 2.2056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/500\n",
      "303/303 - 0s - loss: 4.2894 - mae: 1.3916 - val_loss: 9.5701 - val_mae: 2.4378\n",
      "Epoch 91/500\n",
      "303/303 - 0s - loss: 4.2127 - mae: 1.4291 - val_loss: 7.1010 - val_mae: 1.8706\n",
      "Epoch 92/500\n",
      "303/303 - 0s - loss: 4.0995 - mae: 1.4076 - val_loss: 7.7030 - val_mae: 2.1047\n",
      "Epoch 93/500\n",
      "303/303 - 0s - loss: 4.0795 - mae: 1.3773 - val_loss: 6.6955 - val_mae: 1.8631\n",
      "Epoch 94/500\n",
      "303/303 - 0s - loss: 4.0420 - mae: 1.3765 - val_loss: 7.3838 - val_mae: 1.9405\n",
      "Epoch 95/500\n",
      "303/303 - 0s - loss: 4.1920 - mae: 1.3873 - val_loss: 6.9488 - val_mae: 1.8888\n",
      "Epoch 96/500\n",
      "303/303 - 0s - loss: 4.1191 - mae: 1.4306 - val_loss: 6.3775 - val_mae: 1.7797\n",
      "Epoch 97/500\n",
      "303/303 - 0s - loss: 3.9170 - mae: 1.3590 - val_loss: 7.1605 - val_mae: 1.9270\n",
      "Epoch 98/500\n",
      "303/303 - 0s - loss: 4.0861 - mae: 1.3653 - val_loss: 8.6352 - val_mae: 2.2892\n",
      "Epoch 99/500\n",
      "303/303 - 0s - loss: 4.0821 - mae: 1.3767 - val_loss: 7.2440 - val_mae: 1.9576\n",
      "Epoch 100/500\n",
      "303/303 - 0s - loss: 3.8883 - mae: 1.3953 - val_loss: 8.2196 - val_mae: 2.0378\n",
      "Epoch 101/500\n",
      "303/303 - 0s - loss: 3.7478 - mae: 1.3831 - val_loss: 12.0681 - val_mae: 2.6240\n",
      "Epoch 102/500\n",
      "303/303 - 0s - loss: 3.9838 - mae: 1.3409 - val_loss: 7.4373 - val_mae: 2.0091\n",
      "Epoch 103/500\n",
      "303/303 - 0s - loss: 3.9453 - mae: 1.3931 - val_loss: 7.2530 - val_mae: 2.0106\n",
      "Epoch 104/500\n",
      "303/303 - 0s - loss: 4.0401 - mae: 1.3868 - val_loss: 8.8903 - val_mae: 2.1535\n",
      "Epoch 105/500\n",
      "303/303 - 0s - loss: 3.9428 - mae: 1.3470 - val_loss: 7.8463 - val_mae: 2.0634\n",
      "Epoch 106/500\n",
      "303/303 - 0s - loss: 4.0355 - mae: 1.3696 - val_loss: 6.8120 - val_mae: 1.8283\n",
      "Epoch 107/500\n",
      "303/303 - 0s - loss: 3.9231 - mae: 1.3389 - val_loss: 7.6319 - val_mae: 1.9401\n",
      "Epoch 108/500\n",
      "303/303 - 0s - loss: 3.5000 - mae: 1.3312 - val_loss: 7.8120 - val_mae: 2.0320\n",
      "Epoch 109/500\n",
      "303/303 - 0s - loss: 3.5872 - mae: 1.3222 - val_loss: 7.6676 - val_mae: 2.0161\n",
      "Epoch 110/500\n",
      "303/303 - 0s - loss: 3.6419 - mae: 1.3153 - val_loss: 6.5629 - val_mae: 1.7610\n",
      "Epoch 111/500\n",
      "303/303 - 0s - loss: 3.6506 - mae: 1.3357 - val_loss: 9.1237 - val_mae: 2.1937\n",
      "Epoch 112/500\n",
      "303/303 - 0s - loss: 3.6696 - mae: 1.3451 - val_loss: 6.8193 - val_mae: 1.8582\n",
      "Epoch 113/500\n",
      "303/303 - 0s - loss: 3.5266 - mae: 1.3182 - val_loss: 8.1635 - val_mae: 1.9991\n",
      "Epoch 114/500\n",
      "303/303 - 0s - loss: 3.8058 - mae: 1.3128 - val_loss: 7.6193 - val_mae: 1.9830\n",
      "Epoch 115/500\n",
      "303/303 - 0s - loss: 3.7736 - mae: 1.3586 - val_loss: 7.3227 - val_mae: 1.8814\n",
      "Epoch 116/500\n",
      "303/303 - 0s - loss: 3.3904 - mae: 1.3227 - val_loss: 7.4429 - val_mae: 1.9501\n",
      "Epoch 117/500\n",
      "303/303 - 0s - loss: 3.5575 - mae: 1.2753 - val_loss: 6.7784 - val_mae: 1.8374\n",
      "Epoch 118/500\n",
      "303/303 - 0s - loss: 3.4334 - mae: 1.3047 - val_loss: 7.6830 - val_mae: 2.0010\n",
      "Epoch 119/500\n",
      "303/303 - 0s - loss: 3.5326 - mae: 1.2971 - val_loss: 7.4322 - val_mae: 1.9757\n",
      "Epoch 120/500\n",
      "303/303 - 0s - loss: 3.4979 - mae: 1.3191 - val_loss: 7.0929 - val_mae: 1.8535\n",
      "Epoch 121/500\n",
      "303/303 - 0s - loss: 3.4059 - mae: 1.3040 - val_loss: 7.8558 - val_mae: 1.9948\n",
      "Epoch 122/500\n",
      "303/303 - 0s - loss: 3.2672 - mae: 1.2945 - val_loss: 7.0946 - val_mae: 1.8909\n",
      "Epoch 123/500\n",
      "303/303 - 0s - loss: 3.2270 - mae: 1.2739 - val_loss: 7.4900 - val_mae: 1.9488\n",
      "Epoch 124/500\n",
      "303/303 - 0s - loss: 3.3061 - mae: 1.2739 - val_loss: 8.9656 - val_mae: 2.1914\n",
      "Epoch 125/500\n",
      "303/303 - 0s - loss: 3.1171 - mae: 1.3030 - val_loss: 8.0611 - val_mae: 2.0291\n",
      "Epoch 126/500\n",
      "303/303 - 0s - loss: 3.4189 - mae: 1.3093 - val_loss: 9.8330 - val_mae: 2.3463\n",
      "Epoch 127/500\n",
      "303/303 - 0s - loss: 3.1324 - mae: 1.2699 - val_loss: 6.9077 - val_mae: 1.8845\n",
      "Epoch 128/500\n",
      "303/303 - 0s - loss: 2.8583 - mae: 1.2349 - val_loss: 8.8391 - val_mae: 2.0290\n",
      "Epoch 129/500\n",
      "303/303 - 0s - loss: 2.9003 - mae: 1.1729 - val_loss: 9.8117 - val_mae: 2.3830\n",
      "Epoch 130/500\n",
      "303/303 - 0s - loss: 3.0075 - mae: 1.1846 - val_loss: 10.2005 - val_mae: 2.2402\n",
      "Epoch 131/500\n",
      "303/303 - 0s - loss: 3.0920 - mae: 1.2566 - val_loss: 7.6502 - val_mae: 1.9250\n",
      "Epoch 132/500\n",
      "303/303 - 0s - loss: 3.1978 - mae: 1.2187 - val_loss: 8.7590 - val_mae: 2.1606\n",
      "Epoch 133/500\n",
      "303/303 - 0s - loss: 3.2962 - mae: 1.2721 - val_loss: 8.3199 - val_mae: 2.0194\n",
      "Epoch 134/500\n",
      "303/303 - 0s - loss: 2.8317 - mae: 1.1943 - val_loss: 7.5127 - val_mae: 1.9404\n",
      "Epoch 135/500\n",
      "303/303 - 0s - loss: 3.0882 - mae: 1.1751 - val_loss: 8.2652 - val_mae: 2.0651\n",
      "Epoch 136/500\n",
      "303/303 - 0s - loss: 3.0512 - mae: 1.2634 - val_loss: 8.1305 - val_mae: 2.0775\n",
      "Epoch 137/500\n",
      "303/303 - 0s - loss: 3.0585 - mae: 1.2168 - val_loss: 8.3215 - val_mae: 1.9906\n",
      "Epoch 138/500\n",
      "303/303 - 0s - loss: 3.0308 - mae: 1.2001 - val_loss: 8.4472 - val_mae: 2.0243\n",
      "Epoch 139/500\n",
      "303/303 - 0s - loss: 3.1422 - mae: 1.2435 - val_loss: 8.0113 - val_mae: 1.9552\n",
      "Epoch 140/500\n",
      "303/303 - 0s - loss: 3.0145 - mae: 1.2043 - val_loss: 8.2944 - val_mae: 1.9830\n",
      "Epoch 141/500\n",
      "303/303 - 0s - loss: 2.8469 - mae: 1.2112 - val_loss: 8.3116 - val_mae: 1.9914\n",
      "Epoch 142/500\n",
      "303/303 - 0s - loss: 2.7303 - mae: 1.2158 - val_loss: 7.6327 - val_mae: 1.8781\n",
      "Epoch 143/500\n",
      "303/303 - 0s - loss: 2.8235 - mae: 1.2214 - val_loss: 9.2012 - val_mae: 2.0159\n",
      "Epoch 144/500\n",
      "303/303 - 0s - loss: 2.6504 - mae: 1.1654 - val_loss: 9.2809 - val_mae: 2.1296\n",
      "Epoch 145/500\n",
      "303/303 - 0s - loss: 2.8161 - mae: 1.1907 - val_loss: 8.2360 - val_mae: 1.9594\n",
      "Epoch 146/500\n",
      "303/303 - 0s - loss: 2.5930 - mae: 1.1808 - val_loss: 8.9962 - val_mae: 2.1258\n",
      "Epoch 147/500\n",
      "303/303 - 0s - loss: 2.9689 - mae: 1.2471 - val_loss: 8.0988 - val_mae: 2.0274\n",
      "Epoch 148/500\n",
      "303/303 - 0s - loss: 2.8821 - mae: 1.2091 - val_loss: 9.2517 - val_mae: 2.1692\n",
      "Epoch 149/500\n",
      "303/303 - 0s - loss: 2.6525 - mae: 1.1666 - val_loss: 13.8195 - val_mae: 2.7446\n",
      "Epoch 150/500\n",
      "303/303 - 0s - loss: 2.7830 - mae: 1.1588 - val_loss: 7.8462 - val_mae: 1.9650\n",
      "Epoch 151/500\n",
      "303/303 - 0s - loss: 2.4717 - mae: 1.1270 - val_loss: 8.8018 - val_mae: 2.0802\n",
      "Epoch 152/500\n",
      "303/303 - 0s - loss: 2.7708 - mae: 1.1914 - val_loss: 9.1904 - val_mae: 2.1873\n",
      "Epoch 153/500\n",
      "303/303 - 0s - loss: 2.6449 - mae: 1.1604 - val_loss: 7.3337 - val_mae: 1.8871\n",
      "Epoch 154/500\n",
      "303/303 - 0s - loss: 2.6723 - mae: 1.1418 - val_loss: 7.6244 - val_mae: 1.9330\n",
      "Epoch 155/500\n",
      "303/303 - 0s - loss: 2.5952 - mae: 1.1823 - val_loss: 8.1928 - val_mae: 1.9637\n",
      "Epoch 156/500\n",
      "303/303 - 0s - loss: 2.3408 - mae: 1.1049 - val_loss: 9.4726 - val_mae: 2.2063\n",
      "Epoch 157/500\n",
      "303/303 - 0s - loss: 2.6482 - mae: 1.1821 - val_loss: 8.5092 - val_mae: 1.9560\n",
      "Epoch 158/500\n",
      "303/303 - 0s - loss: 2.5630 - mae: 1.1728 - val_loss: 9.6308 - val_mae: 2.1767\n",
      "Epoch 159/500\n",
      "303/303 - 0s - loss: 2.5127 - mae: 1.1646 - val_loss: 7.8127 - val_mae: 1.9774\n",
      "Epoch 160/500\n",
      "303/303 - 0s - loss: 2.3183 - mae: 1.1128 - val_loss: 7.9074 - val_mae: 1.9892\n",
      "Epoch 161/500\n",
      "303/303 - 0s - loss: 2.6402 - mae: 1.1033 - val_loss: 8.2551 - val_mae: 2.0010\n",
      "Epoch 162/500\n",
      "303/303 - 0s - loss: 2.2061 - mae: 1.0883 - val_loss: 7.6111 - val_mae: 1.9053\n",
      "Epoch 163/500\n",
      "303/303 - 0s - loss: 2.4726 - mae: 1.1622 - val_loss: 9.9950 - val_mae: 2.2790\n",
      "Epoch 164/500\n",
      "303/303 - 0s - loss: 2.5270 - mae: 1.1194 - val_loss: 8.0864 - val_mae: 1.9570\n",
      "Epoch 165/500\n",
      "303/303 - 0s - loss: 2.2513 - mae: 1.0721 - val_loss: 8.1965 - val_mae: 2.0118\n",
      "Epoch 166/500\n",
      "303/303 - 0s - loss: 2.5401 - mae: 1.1069 - val_loss: 10.0787 - val_mae: 2.2368\n",
      "Epoch 167/500\n",
      "303/303 - 0s - loss: 2.3532 - mae: 1.1429 - val_loss: 10.6628 - val_mae: 2.3525\n",
      "Epoch 168/500\n",
      "303/303 - 0s - loss: 2.6273 - mae: 1.1783 - val_loss: 8.8145 - val_mae: 2.0791\n",
      "Epoch 169/500\n",
      "303/303 - 0s - loss: 2.4662 - mae: 1.1446 - val_loss: 11.9623 - val_mae: 2.4825\n",
      "Epoch 170/500\n",
      "303/303 - 0s - loss: 2.4553 - mae: 1.1278 - val_loss: 7.7059 - val_mae: 1.9237\n",
      "Epoch 171/500\n",
      "303/303 - 0s - loss: 2.3093 - mae: 1.1023 - val_loss: 11.2840 - val_mae: 2.3807\n",
      "Epoch 172/500\n",
      "303/303 - 0s - loss: 2.5232 - mae: 1.1156 - val_loss: 8.4106 - val_mae: 2.0226\n",
      "Epoch 173/500\n",
      "303/303 - 0s - loss: 2.2013 - mae: 1.0755 - val_loss: 9.2143 - val_mae: 2.0659\n",
      "Epoch 174/500\n",
      "303/303 - 0s - loss: 2.1997 - mae: 1.1234 - val_loss: 10.9990 - val_mae: 2.3989\n",
      "Epoch 175/500\n",
      "303/303 - 0s - loss: 2.3972 - mae: 1.1222 - val_loss: 8.5874 - val_mae: 2.0722\n",
      "Epoch 176/500\n",
      "303/303 - 0s - loss: 2.2020 - mae: 1.0823 - val_loss: 8.6427 - val_mae: 2.0489\n",
      "Epoch 177/500\n",
      "303/303 - 0s - loss: 2.2905 - mae: 1.1142 - val_loss: 8.0990 - val_mae: 1.9902\n",
      "Epoch 178/500\n",
      "303/303 - 0s - loss: 2.2626 - mae: 1.0911 - val_loss: 8.2586 - val_mae: 1.9710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/500\n",
      "303/303 - 0s - loss: 2.1654 - mae: 1.1052 - val_loss: 9.6425 - val_mae: 2.2346\n",
      "Epoch 180/500\n",
      "303/303 - 0s - loss: 2.0852 - mae: 1.0329 - val_loss: 9.5029 - val_mae: 2.2440\n",
      "Epoch 181/500\n",
      "303/303 - 0s - loss: 2.0780 - mae: 1.0591 - val_loss: 8.0719 - val_mae: 1.9191\n",
      "Epoch 182/500\n",
      "303/303 - 0s - loss: 2.0760 - mae: 1.0561 - val_loss: 9.9699 - val_mae: 2.1620\n",
      "Epoch 183/500\n",
      "303/303 - 0s - loss: 2.2051 - mae: 1.1231 - val_loss: 10.1903 - val_mae: 2.2234\n",
      "Epoch 184/500\n",
      "303/303 - 0s - loss: 2.2861 - mae: 1.1034 - val_loss: 8.7176 - val_mae: 1.9772\n",
      "Epoch 185/500\n",
      "303/303 - 0s - loss: 2.3032 - mae: 1.0905 - val_loss: 8.7416 - val_mae: 2.0513\n",
      "Epoch 186/500\n",
      "303/303 - 0s - loss: 2.0447 - mae: 1.0485 - val_loss: 8.2119 - val_mae: 1.9729\n",
      "Epoch 187/500\n",
      "303/303 - 0s - loss: 2.0861 - mae: 1.0579 - val_loss: 8.4457 - val_mae: 1.9597\n",
      "Epoch 188/500\n",
      "303/303 - 0s - loss: 2.0332 - mae: 1.0703 - val_loss: 8.8489 - val_mae: 2.1184\n",
      "Epoch 189/500\n",
      "303/303 - 0s - loss: 1.9386 - mae: 1.0672 - val_loss: 8.1567 - val_mae: 1.8960\n",
      "Epoch 190/500\n",
      "303/303 - 0s - loss: 2.0895 - mae: 1.0645 - val_loss: 10.4283 - val_mae: 2.3837\n",
      "Epoch 191/500\n",
      "303/303 - 0s - loss: 2.1505 - mae: 1.0743 - val_loss: 9.0876 - val_mae: 2.0148\n",
      "Epoch 192/500\n",
      "303/303 - 0s - loss: 2.1042 - mae: 1.0393 - val_loss: 9.1132 - val_mae: 2.0019\n",
      "Epoch 193/500\n",
      "303/303 - 0s - loss: 2.3137 - mae: 1.0612 - val_loss: 8.4692 - val_mae: 1.9699\n",
      "Epoch 194/500\n",
      "303/303 - 0s - loss: 1.8747 - mae: 0.9927 - val_loss: 10.5508 - val_mae: 2.2954\n",
      "Epoch 195/500\n",
      "303/303 - 0s - loss: 2.2748 - mae: 1.1128 - val_loss: 9.3228 - val_mae: 1.9672\n",
      "Epoch 196/500\n",
      "303/303 - 0s - loss: 2.0284 - mae: 1.0635 - val_loss: 8.8486 - val_mae: 2.0874\n",
      "Epoch 197/500\n",
      "303/303 - 0s - loss: 2.0548 - mae: 1.0347 - val_loss: 9.6345 - val_mae: 2.0937\n",
      "Epoch 198/500\n",
      "303/303 - 0s - loss: 1.9913 - mae: 1.0649 - val_loss: 8.8098 - val_mae: 1.9609\n",
      "Epoch 199/500\n",
      "303/303 - 0s - loss: 2.0020 - mae: 1.0046 - val_loss: 9.7251 - val_mae: 2.1165\n",
      "Epoch 200/500\n",
      "303/303 - 0s - loss: 2.0271 - mae: 1.0731 - val_loss: 10.5880 - val_mae: 2.3616\n",
      "Epoch 201/500\n",
      "303/303 - 0s - loss: 2.0957 - mae: 1.0833 - val_loss: 8.7038 - val_mae: 2.1122\n",
      "Epoch 202/500\n",
      "303/303 - 0s - loss: 1.8629 - mae: 0.9977 - val_loss: 9.3626 - val_mae: 2.1694\n",
      "Epoch 203/500\n",
      "303/303 - 0s - loss: 1.9032 - mae: 1.0021 - val_loss: 9.3801 - val_mae: 2.1115\n",
      "Epoch 204/500\n",
      "303/303 - 0s - loss: 2.0170 - mae: 1.0147 - val_loss: 7.9378 - val_mae: 1.9206\n",
      "Epoch 205/500\n",
      "303/303 - 0s - loss: 2.1448 - mae: 0.9963 - val_loss: 11.1925 - val_mae: 2.3522\n",
      "Epoch 206/500\n",
      "303/303 - 0s - loss: 1.8397 - mae: 0.9975 - val_loss: 9.9112 - val_mae: 2.1211\n",
      "Epoch 207/500\n",
      "303/303 - 0s - loss: 1.8352 - mae: 1.0100 - val_loss: 9.7044 - val_mae: 2.1466\n",
      "Epoch 208/500\n",
      "303/303 - 0s - loss: 1.6783 - mae: 0.9514 - val_loss: 9.8916 - val_mae: 2.1211\n",
      "Epoch 209/500\n",
      "303/303 - 0s - loss: 1.8909 - mae: 1.0025 - val_loss: 9.0199 - val_mae: 2.0105\n",
      "Epoch 210/500\n",
      "303/303 - 0s - loss: 1.8233 - mae: 1.0101 - val_loss: 12.2135 - val_mae: 2.5300\n",
      "Epoch 211/500\n",
      "303/303 - 0s - loss: 1.9217 - mae: 1.0237 - val_loss: 9.2705 - val_mae: 2.0437\n",
      "Epoch 212/500\n",
      "303/303 - 0s - loss: 1.9035 - mae: 0.9981 - val_loss: 9.2010 - val_mae: 2.1098\n",
      "Epoch 213/500\n",
      "303/303 - 0s - loss: 1.9722 - mae: 1.0587 - val_loss: 8.6618 - val_mae: 1.9840\n",
      "Epoch 214/500\n",
      "303/303 - 0s - loss: 1.9610 - mae: 1.0142 - val_loss: 9.4190 - val_mae: 2.1947\n",
      "Epoch 215/500\n",
      "303/303 - 0s - loss: 1.8180 - mae: 1.0316 - val_loss: 9.3155 - val_mae: 2.0588\n",
      "Epoch 216/500\n",
      "303/303 - 0s - loss: 1.9379 - mae: 1.0179 - val_loss: 9.6209 - val_mae: 2.1157\n",
      "Epoch 217/500\n",
      "303/303 - 0s - loss: 1.9696 - mae: 1.0305 - val_loss: 8.6591 - val_mae: 2.0374\n",
      "Epoch 218/500\n",
      "303/303 - 0s - loss: 1.7230 - mae: 0.9571 - val_loss: 9.4404 - val_mae: 2.0432\n",
      "Epoch 219/500\n",
      "303/303 - 0s - loss: 1.8354 - mae: 1.0609 - val_loss: 8.8316 - val_mae: 2.0740\n",
      "Epoch 220/500\n",
      "303/303 - 0s - loss: 1.8758 - mae: 0.9878 - val_loss: 9.0508 - val_mae: 2.0077\n",
      "Epoch 221/500\n",
      "303/303 - 0s - loss: 1.8026 - mae: 0.9930 - val_loss: 10.3817 - val_mae: 2.2206\n",
      "Epoch 222/500\n",
      "303/303 - 0s - loss: 1.6648 - mae: 0.9550 - val_loss: 9.9037 - val_mae: 2.1873\n",
      "Epoch 223/500\n",
      "303/303 - 0s - loss: 1.6319 - mae: 0.9511 - val_loss: 9.3358 - val_mae: 2.0316\n",
      "Epoch 224/500\n",
      "303/303 - 0s - loss: 1.8706 - mae: 0.9690 - val_loss: 8.5413 - val_mae: 2.0105\n",
      "Epoch 225/500\n",
      "303/303 - 0s - loss: 1.6365 - mae: 0.9490 - val_loss: 10.0271 - val_mae: 2.1331\n",
      "Epoch 226/500\n",
      "303/303 - 0s - loss: 1.8003 - mae: 0.9708 - val_loss: 9.3846 - val_mae: 2.0416\n",
      "Epoch 227/500\n",
      "303/303 - 0s - loss: 1.9155 - mae: 1.0067 - val_loss: 8.8801 - val_mae: 2.0427\n",
      "Epoch 228/500\n",
      "303/303 - 0s - loss: 1.5457 - mae: 0.9268 - val_loss: 8.6371 - val_mae: 1.9206\n",
      "Epoch 229/500\n",
      "303/303 - 0s - loss: 1.7286 - mae: 0.9627 - val_loss: 9.3890 - val_mae: 2.0894\n",
      "Epoch 230/500\n",
      "303/303 - 0s - loss: 1.7691 - mae: 0.9867 - val_loss: 9.3584 - val_mae: 2.0256\n",
      "Epoch 231/500\n",
      "303/303 - 0s - loss: 1.5237 - mae: 0.9254 - val_loss: 9.3069 - val_mae: 2.0370\n",
      "Epoch 232/500\n",
      "303/303 - 0s - loss: 1.8129 - mae: 0.9885 - val_loss: 9.9905 - val_mae: 2.2563\n",
      "Epoch 233/500\n",
      "303/303 - 0s - loss: 1.6960 - mae: 0.9554 - val_loss: 9.7508 - val_mae: 2.1929\n",
      "Epoch 234/500\n",
      "303/303 - 0s - loss: 1.6731 - mae: 0.9818 - val_loss: 8.5131 - val_mae: 1.9535\n",
      "Epoch 235/500\n",
      "303/303 - 0s - loss: 1.6367 - mae: 0.9345 - val_loss: 8.5930 - val_mae: 2.0624\n",
      "Epoch 236/500\n",
      "303/303 - 0s - loss: 1.8300 - mae: 0.9757 - val_loss: 9.2288 - val_mae: 2.0775\n",
      "Epoch 237/500\n",
      "303/303 - 0s - loss: 1.7543 - mae: 0.9587 - val_loss: 7.3959 - val_mae: 1.8155\n",
      "Epoch 238/500\n",
      "303/303 - 0s - loss: 1.6187 - mae: 0.9175 - val_loss: 8.6877 - val_mae: 1.9259\n",
      "Epoch 239/500\n",
      "303/303 - 0s - loss: 1.6789 - mae: 0.9188 - val_loss: 8.4212 - val_mae: 1.9547\n",
      "Epoch 240/500\n",
      "303/303 - 0s - loss: 1.8377 - mae: 0.9922 - val_loss: 8.7320 - val_mae: 2.0130\n",
      "Epoch 241/500\n",
      "303/303 - 0s - loss: 1.6921 - mae: 0.9251 - val_loss: 9.8064 - val_mae: 2.0862\n",
      "Epoch 242/500\n",
      "303/303 - 0s - loss: 1.5900 - mae: 0.9267 - val_loss: 7.6578 - val_mae: 1.9039\n",
      "Epoch 243/500\n",
      "303/303 - 0s - loss: 1.5704 - mae: 0.9106 - val_loss: 9.2189 - val_mae: 2.0711\n",
      "Epoch 244/500\n",
      "303/303 - 0s - loss: 1.6849 - mae: 0.9452 - val_loss: 8.8707 - val_mae: 2.0562\n",
      "Epoch 245/500\n",
      "303/303 - 0s - loss: 1.6335 - mae: 0.9333 - val_loss: 8.8339 - val_mae: 2.0111\n",
      "Epoch 246/500\n",
      "303/303 - 0s - loss: 1.5729 - mae: 0.9327 - val_loss: 9.6875 - val_mae: 2.1614\n",
      "Epoch 247/500\n",
      "303/303 - 0s - loss: 1.6592 - mae: 0.9138 - val_loss: 9.9305 - val_mae: 2.2362\n",
      "Epoch 248/500\n",
      "303/303 - 0s - loss: 1.5976 - mae: 0.9446 - val_loss: 8.6455 - val_mae: 1.9798\n",
      "Epoch 249/500\n",
      "303/303 - 0s - loss: 1.5332 - mae: 0.8963 - val_loss: 9.2759 - val_mae: 2.0621\n",
      "Epoch 250/500\n",
      "303/303 - 0s - loss: 1.7535 - mae: 0.9245 - val_loss: 9.8891 - val_mae: 2.1449\n",
      "Epoch 251/500\n",
      "303/303 - 0s - loss: 1.6790 - mae: 0.9272 - val_loss: 9.8162 - val_mae: 2.1053\n",
      "Epoch 252/500\n",
      "303/303 - 0s - loss: 1.5876 - mae: 0.8834 - val_loss: 10.6559 - val_mae: 2.1258\n",
      "Epoch 253/500\n",
      "303/303 - 0s - loss: 1.6718 - mae: 0.9577 - val_loss: 8.9436 - val_mae: 2.1758\n",
      "Epoch 254/500\n",
      "303/303 - 0s - loss: 1.4836 - mae: 0.8653 - val_loss: 9.7807 - val_mae: 2.0813\n",
      "Epoch 255/500\n",
      "303/303 - 0s - loss: 1.5440 - mae: 0.8893 - val_loss: 9.5644 - val_mae: 2.1137\n",
      "Epoch 256/500\n",
      "303/303 - 0s - loss: 1.7014 - mae: 0.9432 - val_loss: 9.2646 - val_mae: 2.1718\n",
      "Epoch 257/500\n",
      "303/303 - 0s - loss: 1.6292 - mae: 0.9363 - val_loss: 9.8580 - val_mae: 2.0650\n",
      "Epoch 258/500\n",
      "303/303 - 0s - loss: 1.6707 - mae: 0.9161 - val_loss: 10.4239 - val_mae: 2.1958\n",
      "Epoch 259/500\n",
      "303/303 - 0s - loss: 1.5217 - mae: 0.9044 - val_loss: 8.7603 - val_mae: 1.9920\n",
      "Epoch 260/500\n",
      "303/303 - 0s - loss: 1.4776 - mae: 0.9033 - val_loss: 9.7657 - val_mae: 2.1600\n",
      "Epoch 261/500\n",
      "303/303 - 0s - loss: 1.5781 - mae: 0.9022 - val_loss: 8.6969 - val_mae: 1.9644\n",
      "Epoch 262/500\n",
      "303/303 - 0s - loss: 1.5764 - mae: 0.9296 - val_loss: 9.2508 - val_mae: 2.0873\n",
      "Epoch 263/500\n",
      "303/303 - 0s - loss: 1.7041 - mae: 0.9304 - val_loss: 9.0949 - val_mae: 2.0341\n",
      "Epoch 264/500\n",
      "303/303 - 0s - loss: 1.4380 - mae: 0.8744 - val_loss: 9.5565 - val_mae: 2.0637\n",
      "Epoch 265/500\n",
      "303/303 - 0s - loss: 1.7406 - mae: 0.9708 - val_loss: 10.2001 - val_mae: 2.1424\n",
      "Epoch 266/500\n",
      "303/303 - 0s - loss: 1.3781 - mae: 0.8733 - val_loss: 9.8165 - val_mae: 2.0309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267/500\n",
      "303/303 - 0s - loss: 1.5386 - mae: 0.9095 - val_loss: 8.8486 - val_mae: 2.0559\n",
      "Epoch 268/500\n",
      "303/303 - 0s - loss: 1.5640 - mae: 0.9300 - val_loss: 11.6088 - val_mae: 2.3192\n",
      "Epoch 269/500\n",
      "303/303 - 0s - loss: 1.4659 - mae: 0.8954 - val_loss: 9.1329 - val_mae: 2.1003\n",
      "Epoch 270/500\n",
      "303/303 - 0s - loss: 1.5882 - mae: 0.8853 - val_loss: 9.0920 - val_mae: 2.0407\n",
      "Epoch 271/500\n",
      "303/303 - 0s - loss: 1.3610 - mae: 0.8450 - val_loss: 9.3089 - val_mae: 1.9539\n",
      "Epoch 272/500\n",
      "303/303 - 0s - loss: 1.6335 - mae: 0.9160 - val_loss: 9.3096 - val_mae: 2.0301\n",
      "Epoch 273/500\n",
      "303/303 - 0s - loss: 1.4569 - mae: 0.8806 - val_loss: 8.8805 - val_mae: 1.9538\n",
      "Epoch 274/500\n",
      "303/303 - 0s - loss: 1.4196 - mae: 0.8589 - val_loss: 9.0023 - val_mae: 1.9304\n",
      "Epoch 275/500\n",
      "303/303 - 0s - loss: 1.5224 - mae: 0.8947 - val_loss: 9.7253 - val_mae: 2.1146\n",
      "Epoch 276/500\n",
      "303/303 - 0s - loss: 1.5122 - mae: 0.8631 - val_loss: 10.5267 - val_mae: 2.1802\n",
      "Epoch 277/500\n",
      "303/303 - 0s - loss: 1.3421 - mae: 0.8600 - val_loss: 9.5500 - val_mae: 2.1189\n",
      "Epoch 278/500\n",
      "303/303 - 0s - loss: 1.4490 - mae: 0.8889 - val_loss: 9.4506 - val_mae: 2.0647\n",
      "Epoch 279/500\n",
      "303/303 - 0s - loss: 1.5972 - mae: 0.9002 - val_loss: 10.0370 - val_mae: 2.2004\n",
      "Epoch 280/500\n",
      "303/303 - 0s - loss: 1.4660 - mae: 0.9059 - val_loss: 8.7723 - val_mae: 2.0458\n",
      "Epoch 281/500\n",
      "303/303 - 0s - loss: 1.3783 - mae: 0.8526 - val_loss: 9.8121 - val_mae: 2.1607\n",
      "Epoch 282/500\n",
      "303/303 - 0s - loss: 1.3221 - mae: 0.8211 - val_loss: 9.3497 - val_mae: 1.9867\n",
      "Epoch 283/500\n",
      "303/303 - 0s - loss: 1.5395 - mae: 0.8871 - val_loss: 9.4803 - val_mae: 2.0354\n",
      "Epoch 284/500\n",
      "303/303 - 0s - loss: 1.3925 - mae: 0.8883 - val_loss: 8.9345 - val_mae: 2.0966\n",
      "Epoch 285/500\n",
      "303/303 - 0s - loss: 1.3803 - mae: 0.8581 - val_loss: 9.1211 - val_mae: 2.0694\n",
      "Epoch 286/500\n",
      "303/303 - 0s - loss: 1.4647 - mae: 0.8791 - val_loss: 9.2438 - val_mae: 2.0017\n",
      "Epoch 287/500\n",
      "303/303 - 0s - loss: 1.4344 - mae: 0.9060 - val_loss: 10.9144 - val_mae: 2.2164\n",
      "Epoch 288/500\n",
      "303/303 - 0s - loss: 1.4083 - mae: 0.8902 - val_loss: 9.4555 - val_mae: 2.0529\n",
      "Epoch 289/500\n",
      "303/303 - 0s - loss: 1.4220 - mae: 0.8460 - val_loss: 11.0178 - val_mae: 2.1447\n",
      "Epoch 290/500\n",
      "303/303 - 0s - loss: 1.3813 - mae: 0.8819 - val_loss: 10.0170 - val_mae: 2.0602\n",
      "Epoch 291/500\n",
      "303/303 - 0s - loss: 1.4138 - mae: 0.8857 - val_loss: 10.0924 - val_mae: 2.0476\n",
      "Epoch 292/500\n",
      "303/303 - 0s - loss: 1.3909 - mae: 0.8766 - val_loss: 10.3514 - val_mae: 2.1300\n",
      "Epoch 293/500\n",
      "303/303 - 0s - loss: 1.3674 - mae: 0.8942 - val_loss: 10.7516 - val_mae: 2.2016\n",
      "Epoch 294/500\n",
      "303/303 - 0s - loss: 1.2564 - mae: 0.8323 - val_loss: 10.4599 - val_mae: 2.2651\n",
      "Epoch 295/500\n",
      "303/303 - 0s - loss: 1.5176 - mae: 0.8787 - val_loss: 11.1465 - val_mae: 2.3726\n",
      "Epoch 296/500\n",
      "303/303 - 0s - loss: 1.3910 - mae: 0.8384 - val_loss: 10.7817 - val_mae: 2.1193\n",
      "Epoch 297/500\n",
      "303/303 - 0s - loss: 1.2938 - mae: 0.8348 - val_loss: 11.6549 - val_mae: 2.2702\n",
      "Epoch 298/500\n",
      "303/303 - 0s - loss: 1.4472 - mae: 0.8932 - val_loss: 11.5659 - val_mae: 2.2915\n",
      "Epoch 299/500\n",
      "303/303 - 0s - loss: 1.2924 - mae: 0.8495 - val_loss: 10.1116 - val_mae: 2.2337\n",
      "Epoch 300/500\n",
      "303/303 - 0s - loss: 1.4260 - mae: 0.8741 - val_loss: 11.7279 - val_mae: 2.2268\n",
      "Epoch 301/500\n",
      "303/303 - 0s - loss: 1.2758 - mae: 0.8736 - val_loss: 11.5850 - val_mae: 2.2770\n",
      "Epoch 302/500\n",
      "303/303 - 0s - loss: 1.3767 - mae: 0.8934 - val_loss: 10.9492 - val_mae: 2.1645\n",
      "Epoch 303/500\n",
      "303/303 - 0s - loss: 1.2408 - mae: 0.8300 - val_loss: 9.9949 - val_mae: 2.0828\n",
      "Epoch 304/500\n",
      "303/303 - 0s - loss: 1.4563 - mae: 0.8746 - val_loss: 10.6177 - val_mae: 2.0272\n",
      "Epoch 305/500\n",
      "303/303 - 0s - loss: 1.4561 - mae: 0.8837 - val_loss: 10.3169 - val_mae: 2.1489\n",
      "Epoch 306/500\n",
      "303/303 - 0s - loss: 1.2936 - mae: 0.8390 - val_loss: 10.5804 - val_mae: 2.0675\n",
      "Epoch 307/500\n",
      "303/303 - 0s - loss: 1.3354 - mae: 0.8283 - val_loss: 10.7669 - val_mae: 2.1667\n",
      "Epoch 308/500\n",
      "303/303 - 0s - loss: 1.3606 - mae: 0.8600 - val_loss: 11.0606 - val_mae: 2.1999\n",
      "Epoch 309/500\n",
      "303/303 - 0s - loss: 1.2508 - mae: 0.8525 - val_loss: 10.5171 - val_mae: 2.1329\n",
      "Epoch 310/500\n",
      "303/303 - 0s - loss: 1.2171 - mae: 0.8011 - val_loss: 10.4061 - val_mae: 2.1020\n",
      "Epoch 311/500\n",
      "303/303 - 0s - loss: 1.3229 - mae: 0.8430 - val_loss: 9.2632 - val_mae: 2.0459\n",
      "Epoch 312/500\n",
      "303/303 - 0s - loss: 1.4455 - mae: 0.8555 - val_loss: 9.6417 - val_mae: 2.0540\n",
      "Epoch 313/500\n",
      "303/303 - 0s - loss: 1.2789 - mae: 0.8516 - val_loss: 11.1749 - val_mae: 2.2751\n",
      "Epoch 314/500\n",
      "303/303 - 0s - loss: 1.2236 - mae: 0.8250 - val_loss: 11.6666 - val_mae: 2.2924\n",
      "Epoch 315/500\n",
      "303/303 - 0s - loss: 1.2208 - mae: 0.8016 - val_loss: 10.8035 - val_mae: 2.1351\n",
      "Epoch 316/500\n",
      "303/303 - 0s - loss: 1.1722 - mae: 0.8053 - val_loss: 11.0532 - val_mae: 2.1898\n",
      "Epoch 317/500\n",
      "303/303 - 0s - loss: 1.3235 - mae: 0.8690 - val_loss: 10.6066 - val_mae: 2.1453\n",
      "Epoch 318/500\n",
      "303/303 - 0s - loss: 1.3168 - mae: 0.8727 - val_loss: 11.3002 - val_mae: 2.1468\n",
      "Epoch 319/500\n",
      "303/303 - 0s - loss: 1.3636 - mae: 0.8393 - val_loss: 11.3488 - val_mae: 2.0876\n",
      "Epoch 320/500\n",
      "303/303 - 0s - loss: 1.1020 - mae: 0.7530 - val_loss: 9.9689 - val_mae: 2.1430\n",
      "Epoch 321/500\n",
      "303/303 - 0s - loss: 1.2364 - mae: 0.8344 - val_loss: 10.2372 - val_mae: 2.1141\n",
      "Epoch 322/500\n",
      "303/303 - 0s - loss: 1.2382 - mae: 0.8121 - val_loss: 10.0592 - val_mae: 2.1250\n",
      "Epoch 323/500\n",
      "303/303 - 0s - loss: 1.3153 - mae: 0.8009 - val_loss: 10.4606 - val_mae: 2.1160\n",
      "Epoch 324/500\n",
      "303/303 - 0s - loss: 1.1581 - mae: 0.7955 - val_loss: 10.3472 - val_mae: 2.0575\n",
      "Epoch 325/500\n",
      "303/303 - 0s - loss: 1.2438 - mae: 0.8190 - val_loss: 10.5664 - val_mae: 2.2069\n",
      "Epoch 326/500\n",
      "303/303 - 0s - loss: 1.1463 - mae: 0.7683 - val_loss: 12.2045 - val_mae: 2.4175\n",
      "Epoch 327/500\n",
      "303/303 - 0s - loss: 1.2797 - mae: 0.7919 - val_loss: 10.1077 - val_mae: 2.0496\n",
      "Epoch 328/500\n",
      "303/303 - 0s - loss: 1.0963 - mae: 0.7609 - val_loss: 11.4263 - val_mae: 2.3213\n",
      "Epoch 329/500\n",
      "303/303 - 0s - loss: 1.3722 - mae: 0.8657 - val_loss: 10.0034 - val_mae: 2.1214\n",
      "Epoch 330/500\n",
      "303/303 - 0s - loss: 1.3185 - mae: 0.8138 - val_loss: 10.1555 - val_mae: 2.0313\n",
      "Epoch 331/500\n",
      "303/303 - 0s - loss: 1.1408 - mae: 0.7724 - val_loss: 10.2711 - val_mae: 2.0900\n",
      "Epoch 332/500\n",
      "303/303 - 0s - loss: 1.2271 - mae: 0.8224 - val_loss: 10.1742 - val_mae: 2.1082\n",
      "Epoch 333/500\n",
      "303/303 - 0s - loss: 1.1440 - mae: 0.7867 - val_loss: 10.4907 - val_mae: 2.1036\n",
      "Epoch 334/500\n",
      "303/303 - 0s - loss: 1.3268 - mae: 0.8144 - val_loss: 13.0633 - val_mae: 2.3632\n",
      "Epoch 335/500\n",
      "303/303 - 0s - loss: 1.1405 - mae: 0.8080 - val_loss: 10.5538 - val_mae: 2.1842\n",
      "Epoch 336/500\n",
      "303/303 - 0s - loss: 1.1305 - mae: 0.7677 - val_loss: 10.8200 - val_mae: 2.1793\n",
      "Epoch 337/500\n",
      "303/303 - 0s - loss: 1.1811 - mae: 0.7724 - val_loss: 10.7526 - val_mae: 2.1796\n",
      "Epoch 338/500\n",
      "303/303 - 0s - loss: 1.1947 - mae: 0.8021 - val_loss: 10.8685 - val_mae: 2.2033\n",
      "Epoch 339/500\n",
      "303/303 - 0s - loss: 1.2188 - mae: 0.8420 - val_loss: 10.5395 - val_mae: 2.0635\n",
      "Epoch 340/500\n",
      "303/303 - 0s - loss: 1.3287 - mae: 0.7945 - val_loss: 10.0120 - val_mae: 2.2080\n",
      "Epoch 341/500\n",
      "303/303 - 0s - loss: 1.2834 - mae: 0.8069 - val_loss: 10.9919 - val_mae: 2.1201\n",
      "Epoch 342/500\n",
      "303/303 - 0s - loss: 1.2210 - mae: 0.8203 - val_loss: 11.3157 - val_mae: 2.2285\n",
      "Epoch 343/500\n",
      "303/303 - 0s - loss: 1.1755 - mae: 0.7597 - val_loss: 9.9722 - val_mae: 2.0685\n",
      "Epoch 344/500\n",
      "303/303 - 0s - loss: 1.1406 - mae: 0.7553 - val_loss: 11.2922 - val_mae: 2.1910\n",
      "Epoch 345/500\n",
      "303/303 - 0s - loss: 1.2230 - mae: 0.7946 - val_loss: 12.0552 - val_mae: 2.3493\n",
      "Epoch 346/500\n",
      "303/303 - 0s - loss: 1.1264 - mae: 0.7732 - val_loss: 10.9302 - val_mae: 2.1872\n",
      "Epoch 347/500\n",
      "303/303 - 0s - loss: 1.0697 - mae: 0.7822 - val_loss: 10.5117 - val_mae: 2.1077\n",
      "Epoch 348/500\n",
      "303/303 - 0s - loss: 1.1176 - mae: 0.7555 - val_loss: 10.4611 - val_mae: 2.0673\n",
      "Epoch 349/500\n",
      "303/303 - 0s - loss: 1.1601 - mae: 0.7956 - val_loss: 11.8700 - val_mae: 2.2926\n",
      "Epoch 350/500\n",
      "303/303 - 0s - loss: 1.1444 - mae: 0.7795 - val_loss: 10.4209 - val_mae: 2.0682\n",
      "Epoch 351/500\n",
      "303/303 - 0s - loss: 1.1510 - mae: 0.7775 - val_loss: 11.5899 - val_mae: 2.2701\n",
      "Epoch 352/500\n",
      "303/303 - 0s - loss: 1.1463 - mae: 0.7851 - val_loss: 11.4090 - val_mae: 2.2936\n",
      "Epoch 353/500\n",
      "303/303 - 0s - loss: 1.0952 - mae: 0.7822 - val_loss: 11.3816 - val_mae: 2.3173\n",
      "Epoch 354/500\n",
      "303/303 - 0s - loss: 1.0339 - mae: 0.7515 - val_loss: 10.1961 - val_mae: 2.1688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/500\n",
      "303/303 - 0s - loss: 1.1021 - mae: 0.7722 - val_loss: 10.6391 - val_mae: 2.1765\n",
      "Epoch 356/500\n",
      "303/303 - 0s - loss: 1.0123 - mae: 0.7503 - val_loss: 11.4348 - val_mae: 2.2705\n",
      "Epoch 357/500\n",
      "303/303 - 0s - loss: 1.2109 - mae: 0.7970 - val_loss: 10.1634 - val_mae: 2.1283\n",
      "Epoch 358/500\n",
      "303/303 - 0s - loss: 1.0603 - mae: 0.7318 - val_loss: 11.2602 - val_mae: 2.2533\n",
      "Epoch 359/500\n",
      "303/303 - 0s - loss: 1.0578 - mae: 0.7532 - val_loss: 10.2558 - val_mae: 2.1892\n",
      "Epoch 360/500\n",
      "303/303 - 0s - loss: 1.1030 - mae: 0.7605 - val_loss: 10.3964 - val_mae: 2.0861\n",
      "Epoch 361/500\n",
      "303/303 - 0s - loss: 1.0545 - mae: 0.7626 - val_loss: 10.8949 - val_mae: 2.1861\n",
      "Epoch 362/500\n",
      "303/303 - 0s - loss: 1.0749 - mae: 0.7554 - val_loss: 10.6929 - val_mae: 2.1959\n",
      "Epoch 363/500\n",
      "303/303 - 0s - loss: 1.0723 - mae: 0.7383 - val_loss: 10.9398 - val_mae: 2.2618\n",
      "Epoch 364/500\n",
      "303/303 - 0s - loss: 1.0851 - mae: 0.7316 - val_loss: 10.7687 - val_mae: 2.1506\n",
      "Epoch 365/500\n",
      "303/303 - 0s - loss: 1.1343 - mae: 0.7587 - val_loss: 11.0680 - val_mae: 2.2395\n",
      "Epoch 366/500\n",
      "303/303 - 0s - loss: 1.2199 - mae: 0.7609 - val_loss: 11.7361 - val_mae: 2.2616\n",
      "Epoch 367/500\n",
      "303/303 - 0s - loss: 1.0886 - mae: 0.7579 - val_loss: 11.2689 - val_mae: 2.1946\n",
      "Epoch 368/500\n",
      "303/303 - 0s - loss: 1.1170 - mae: 0.7228 - val_loss: 10.5735 - val_mae: 2.1107\n",
      "Epoch 369/500\n",
      "303/303 - 0s - loss: 0.9391 - mae: 0.7291 - val_loss: 12.2309 - val_mae: 2.3133\n",
      "Epoch 370/500\n",
      "303/303 - 0s - loss: 1.0075 - mae: 0.7233 - val_loss: 11.3726 - val_mae: 2.1589\n",
      "Epoch 371/500\n",
      "303/303 - 0s - loss: 1.0649 - mae: 0.7488 - val_loss: 10.9640 - val_mae: 2.2206\n",
      "Epoch 372/500\n",
      "303/303 - 0s - loss: 1.1190 - mae: 0.7846 - val_loss: 11.6397 - val_mae: 2.2978\n",
      "Epoch 373/500\n",
      "303/303 - 0s - loss: 1.0124 - mae: 0.7673 - val_loss: 10.8277 - val_mae: 2.1820\n",
      "Epoch 374/500\n",
      "303/303 - 0s - loss: 0.9866 - mae: 0.7410 - val_loss: 10.4013 - val_mae: 2.1393\n",
      "Epoch 375/500\n",
      "303/303 - 0s - loss: 1.0902 - mae: 0.7526 - val_loss: 12.4260 - val_mae: 2.4544\n",
      "Epoch 376/500\n",
      "303/303 - 0s - loss: 0.9351 - mae: 0.7133 - val_loss: 11.6036 - val_mae: 2.3711\n",
      "Epoch 377/500\n",
      "303/303 - 0s - loss: 1.0873 - mae: 0.7914 - val_loss: 11.0301 - val_mae: 2.2251\n",
      "Epoch 378/500\n",
      "303/303 - 0s - loss: 1.1201 - mae: 0.7807 - val_loss: 11.5530 - val_mae: 2.1638\n",
      "Epoch 379/500\n",
      "303/303 - 0s - loss: 0.9904 - mae: 0.7429 - val_loss: 11.8841 - val_mae: 2.3109\n",
      "Epoch 380/500\n",
      "303/303 - 0s - loss: 1.0804 - mae: 0.7520 - val_loss: 10.9372 - val_mae: 2.2142\n",
      "Epoch 381/500\n",
      "303/303 - 0s - loss: 1.0134 - mae: 0.7357 - val_loss: 12.0866 - val_mae: 2.3965\n",
      "Epoch 382/500\n",
      "303/303 - 0s - loss: 1.0630 - mae: 0.7386 - val_loss: 10.5364 - val_mae: 2.1437\n",
      "Epoch 383/500\n",
      "303/303 - 0s - loss: 0.9268 - mae: 0.7163 - val_loss: 10.6176 - val_mae: 2.1646\n",
      "Epoch 384/500\n",
      "303/303 - 0s - loss: 0.9682 - mae: 0.7386 - val_loss: 11.6453 - val_mae: 2.2345\n",
      "Epoch 385/500\n",
      "303/303 - 0s - loss: 0.9358 - mae: 0.7276 - val_loss: 11.3222 - val_mae: 2.3454\n",
      "Epoch 386/500\n",
      "303/303 - 0s - loss: 1.0449 - mae: 0.7381 - val_loss: 11.2013 - val_mae: 2.2336\n",
      "Epoch 387/500\n",
      "303/303 - 0s - loss: 1.0180 - mae: 0.7506 - val_loss: 12.6392 - val_mae: 2.3424\n",
      "Epoch 388/500\n",
      "303/303 - 0s - loss: 1.0056 - mae: 0.7412 - val_loss: 13.7785 - val_mae: 2.6438\n",
      "Epoch 389/500\n",
      "303/303 - 0s - loss: 1.0852 - mae: 0.7459 - val_loss: 11.0854 - val_mae: 2.3284\n",
      "Epoch 390/500\n",
      "303/303 - 0s - loss: 1.0571 - mae: 0.7506 - val_loss: 10.3234 - val_mae: 2.1177\n",
      "Epoch 391/500\n",
      "303/303 - 0s - loss: 1.0319 - mae: 0.7390 - val_loss: 11.7203 - val_mae: 2.2750\n",
      "Epoch 392/500\n",
      "303/303 - 0s - loss: 1.0895 - mae: 0.7356 - val_loss: 11.0050 - val_mae: 2.1900\n",
      "Epoch 393/500\n",
      "303/303 - 0s - loss: 0.9065 - mae: 0.7193 - val_loss: 11.8930 - val_mae: 2.3741\n",
      "Epoch 394/500\n",
      "303/303 - 0s - loss: 1.0121 - mae: 0.7213 - val_loss: 13.0058 - val_mae: 2.5160\n",
      "Epoch 395/500\n",
      "303/303 - 0s - loss: 1.0932 - mae: 0.7499 - val_loss: 11.6303 - val_mae: 2.2281\n",
      "Epoch 396/500\n",
      "303/303 - 0s - loss: 0.9567 - mae: 0.6799 - val_loss: 12.4442 - val_mae: 2.3821\n",
      "Epoch 397/500\n",
      "303/303 - 0s - loss: 0.9169 - mae: 0.7031 - val_loss: 11.5813 - val_mae: 2.2911\n",
      "Epoch 398/500\n",
      "303/303 - 0s - loss: 0.9447 - mae: 0.6947 - val_loss: 11.8571 - val_mae: 2.2654\n",
      "Epoch 399/500\n",
      "303/303 - 0s - loss: 0.9207 - mae: 0.7300 - val_loss: 11.5492 - val_mae: 2.2312\n",
      "Epoch 400/500\n",
      "303/303 - 0s - loss: 0.9889 - mae: 0.7209 - val_loss: 11.7746 - val_mae: 2.2266\n",
      "Epoch 401/500\n",
      "303/303 - 0s - loss: 0.9678 - mae: 0.7238 - val_loss: 10.7671 - val_mae: 2.1768\n",
      "Epoch 402/500\n",
      "303/303 - 0s - loss: 0.9707 - mae: 0.7204 - val_loss: 12.2264 - val_mae: 2.4172\n",
      "Epoch 403/500\n",
      "303/303 - 0s - loss: 0.8998 - mae: 0.7065 - val_loss: 11.4846 - val_mae: 2.2740\n",
      "Epoch 404/500\n",
      "303/303 - 0s - loss: 0.9110 - mae: 0.7038 - val_loss: 10.8783 - val_mae: 2.2354\n",
      "Epoch 405/500\n",
      "303/303 - 0s - loss: 1.0990 - mae: 0.7633 - val_loss: 10.8596 - val_mae: 2.1789\n",
      "Epoch 406/500\n",
      "303/303 - 0s - loss: 0.8480 - mae: 0.6924 - val_loss: 13.0973 - val_mae: 2.3682\n",
      "Epoch 407/500\n",
      "303/303 - 0s - loss: 1.0225 - mae: 0.7416 - val_loss: 11.4869 - val_mae: 2.2454\n",
      "Epoch 408/500\n",
      "303/303 - 0s - loss: 1.0652 - mae: 0.7476 - val_loss: 11.1871 - val_mae: 2.2174\n",
      "Epoch 409/500\n",
      "303/303 - 0s - loss: 0.9503 - mae: 0.7203 - val_loss: 11.8284 - val_mae: 2.3340\n",
      "Epoch 410/500\n",
      "303/303 - 0s - loss: 0.8707 - mae: 0.6874 - val_loss: 11.7036 - val_mae: 2.2060\n",
      "Epoch 411/500\n",
      "303/303 - 0s - loss: 0.9333 - mae: 0.6917 - val_loss: 11.3863 - val_mae: 2.2416\n",
      "Epoch 412/500\n",
      "303/303 - 0s - loss: 1.0347 - mae: 0.7346 - val_loss: 12.1172 - val_mae: 2.3124\n",
      "Epoch 413/500\n",
      "303/303 - 0s - loss: 0.8366 - mae: 0.6953 - val_loss: 10.7563 - val_mae: 2.0689\n",
      "Epoch 414/500\n",
      "303/303 - 0s - loss: 0.9164 - mae: 0.6879 - val_loss: 10.9925 - val_mae: 2.2130\n",
      "Epoch 415/500\n",
      "303/303 - 0s - loss: 0.9958 - mae: 0.7389 - val_loss: 11.5036 - val_mae: 2.1218\n",
      "Epoch 416/500\n",
      "303/303 - 0s - loss: 0.9526 - mae: 0.7111 - val_loss: 11.0741 - val_mae: 2.2765\n",
      "Epoch 417/500\n",
      "303/303 - 0s - loss: 0.9042 - mae: 0.6723 - val_loss: 11.9539 - val_mae: 2.3227\n",
      "Epoch 418/500\n",
      "303/303 - 0s - loss: 1.0221 - mae: 0.7500 - val_loss: 10.7746 - val_mae: 2.2223\n",
      "Epoch 419/500\n",
      "303/303 - 0s - loss: 0.9078 - mae: 0.6847 - val_loss: 11.9394 - val_mae: 2.4202\n",
      "Epoch 420/500\n",
      "303/303 - 0s - loss: 0.9331 - mae: 0.7277 - val_loss: 11.9349 - val_mae: 2.2741\n",
      "Epoch 421/500\n",
      "303/303 - 0s - loss: 0.9873 - mae: 0.7093 - val_loss: 11.9628 - val_mae: 2.1929\n",
      "Epoch 422/500\n",
      "303/303 - 0s - loss: 0.9159 - mae: 0.7100 - val_loss: 11.4525 - val_mae: 2.2564\n",
      "Epoch 423/500\n",
      "303/303 - 0s - loss: 0.8100 - mae: 0.6596 - val_loss: 11.3869 - val_mae: 2.2499\n",
      "Epoch 424/500\n",
      "303/303 - 0s - loss: 0.8816 - mae: 0.7000 - val_loss: 11.5267 - val_mae: 2.2834\n",
      "Epoch 425/500\n",
      "303/303 - 0s - loss: 0.9851 - mae: 0.7245 - val_loss: 11.2707 - val_mae: 2.1657\n",
      "Epoch 426/500\n",
      "303/303 - 0s - loss: 0.9157 - mae: 0.7089 - val_loss: 10.8642 - val_mae: 2.1234\n",
      "Epoch 427/500\n",
      "303/303 - 0s - loss: 1.0598 - mae: 0.7091 - val_loss: 11.4979 - val_mae: 2.2478\n",
      "Epoch 428/500\n",
      "303/303 - 0s - loss: 0.9083 - mae: 0.6969 - val_loss: 11.4449 - val_mae: 2.2564\n",
      "Epoch 429/500\n",
      "303/303 - 0s - loss: 0.9720 - mae: 0.7281 - val_loss: 11.9967 - val_mae: 2.2912\n",
      "Epoch 430/500\n",
      "303/303 - 0s - loss: 0.9197 - mae: 0.6935 - val_loss: 11.7905 - val_mae: 2.3249\n",
      "Epoch 431/500\n",
      "303/303 - 0s - loss: 0.8938 - mae: 0.6814 - val_loss: 11.2301 - val_mae: 2.2479\n",
      "Epoch 432/500\n",
      "303/303 - 0s - loss: 0.9585 - mae: 0.7224 - val_loss: 12.1218 - val_mae: 2.3267\n",
      "Epoch 433/500\n",
      "303/303 - 0s - loss: 1.0917 - mae: 0.6914 - val_loss: 11.7351 - val_mae: 2.2188\n",
      "Epoch 434/500\n",
      "303/303 - 0s - loss: 0.9297 - mae: 0.7002 - val_loss: 12.1513 - val_mae: 2.3062\n",
      "Epoch 435/500\n",
      "303/303 - 0s - loss: 0.9338 - mae: 0.7028 - val_loss: 12.1114 - val_mae: 2.2583\n",
      "Epoch 436/500\n",
      "303/303 - 0s - loss: 0.8595 - mae: 0.6971 - val_loss: 12.2573 - val_mae: 2.1755\n",
      "Epoch 437/500\n",
      "303/303 - 0s - loss: 0.9138 - mae: 0.7012 - val_loss: 11.3183 - val_mae: 2.1729\n",
      "Epoch 438/500\n",
      "303/303 - 0s - loss: 0.8656 - mae: 0.6681 - val_loss: 11.5141 - val_mae: 2.1903\n",
      "Epoch 439/500\n",
      "303/303 - 0s - loss: 0.7673 - mae: 0.6766 - val_loss: 13.3187 - val_mae: 2.5753\n",
      "Epoch 440/500\n",
      "303/303 - 0s - loss: 1.0424 - mae: 0.7072 - val_loss: 11.8583 - val_mae: 2.2976\n",
      "Epoch 441/500\n",
      "303/303 - 0s - loss: 0.9979 - mae: 0.7508 - val_loss: 12.4744 - val_mae: 2.2622\n",
      "Epoch 442/500\n",
      "303/303 - 0s - loss: 0.9110 - mae: 0.6856 - val_loss: 11.6569 - val_mae: 2.2307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443/500\n",
      "303/303 - 0s - loss: 0.9615 - mae: 0.7158 - val_loss: 12.3769 - val_mae: 2.3441\n",
      "Epoch 444/500\n",
      "303/303 - 0s - loss: 0.8870 - mae: 0.6699 - val_loss: 12.2005 - val_mae: 2.1907\n",
      "Epoch 445/500\n",
      "303/303 - 0s - loss: 0.9167 - mae: 0.6886 - val_loss: 13.2205 - val_mae: 2.4616\n",
      "Epoch 446/500\n",
      "303/303 - 0s - loss: 0.8661 - mae: 0.6829 - val_loss: 12.1430 - val_mae: 2.3349\n",
      "Epoch 447/500\n",
      "303/303 - 0s - loss: 0.8041 - mae: 0.6721 - val_loss: 12.8779 - val_mae: 2.3581\n",
      "Epoch 448/500\n",
      "303/303 - 0s - loss: 0.9654 - mae: 0.7237 - val_loss: 12.1008 - val_mae: 2.2931\n",
      "Epoch 449/500\n",
      "303/303 - 0s - loss: 0.8293 - mae: 0.6818 - val_loss: 13.0384 - val_mae: 2.4229\n",
      "Epoch 450/500\n",
      "303/303 - 0s - loss: 0.8856 - mae: 0.6980 - val_loss: 12.1942 - val_mae: 2.4047\n",
      "Epoch 451/500\n",
      "303/303 - 0s - loss: 0.8346 - mae: 0.6738 - val_loss: 12.5369 - val_mae: 2.2800\n",
      "Epoch 452/500\n",
      "303/303 - 0s - loss: 0.8658 - mae: 0.6717 - val_loss: 11.7177 - val_mae: 2.2276\n",
      "Epoch 453/500\n",
      "303/303 - 0s - loss: 0.9718 - mae: 0.6791 - val_loss: 12.4932 - val_mae: 2.3457\n",
      "Epoch 454/500\n",
      "303/303 - 0s - loss: 0.8861 - mae: 0.6923 - val_loss: 12.3768 - val_mae: 2.1365\n",
      "Epoch 455/500\n",
      "303/303 - 0s - loss: 0.8387 - mae: 0.6949 - val_loss: 11.9107 - val_mae: 2.1482\n",
      "Epoch 456/500\n",
      "303/303 - 0s - loss: 1.0122 - mae: 0.7153 - val_loss: 12.2796 - val_mae: 2.1599\n",
      "Epoch 457/500\n",
      "303/303 - 0s - loss: 0.8914 - mae: 0.6990 - val_loss: 13.0753 - val_mae: 2.4416\n",
      "Epoch 458/500\n",
      "303/303 - 0s - loss: 0.9542 - mae: 0.7010 - val_loss: 11.2575 - val_mae: 2.2156\n",
      "Epoch 459/500\n",
      "303/303 - 0s - loss: 0.8379 - mae: 0.6906 - val_loss: 12.3912 - val_mae: 2.2642\n",
      "Epoch 460/500\n",
      "303/303 - 0s - loss: 0.8618 - mae: 0.6637 - val_loss: 12.3727 - val_mae: 2.2766\n",
      "Epoch 461/500\n",
      "303/303 - 0s - loss: 0.9968 - mae: 0.7273 - val_loss: 12.5944 - val_mae: 2.3433\n",
      "Epoch 462/500\n",
      "303/303 - 0s - loss: 0.8347 - mae: 0.6712 - val_loss: 11.8118 - val_mae: 2.2739\n",
      "Epoch 463/500\n",
      "303/303 - 0s - loss: 0.9063 - mae: 0.6923 - val_loss: 13.0610 - val_mae: 2.4207\n",
      "Epoch 464/500\n",
      "303/303 - 0s - loss: 0.8366 - mae: 0.6547 - val_loss: 11.9950 - val_mae: 2.2869\n",
      "Epoch 465/500\n",
      "303/303 - 0s - loss: 0.8906 - mae: 0.6918 - val_loss: 12.0365 - val_mae: 2.2879\n",
      "Epoch 466/500\n",
      "303/303 - 0s - loss: 0.8359 - mae: 0.6628 - val_loss: 12.6576 - val_mae: 2.2745\n",
      "Epoch 467/500\n",
      "303/303 - 0s - loss: 0.7314 - mae: 0.6443 - val_loss: 11.7623 - val_mae: 2.1391\n",
      "Epoch 468/500\n",
      "303/303 - 0s - loss: 0.8982 - mae: 0.6877 - val_loss: 12.8305 - val_mae: 2.2980\n",
      "Epoch 469/500\n",
      "303/303 - 0s - loss: 0.6837 - mae: 0.6282 - val_loss: 12.2400 - val_mae: 2.2664\n",
      "Epoch 470/500\n",
      "303/303 - 0s - loss: 0.8923 - mae: 0.6874 - val_loss: 13.2290 - val_mae: 2.3964\n",
      "Epoch 471/500\n",
      "303/303 - 0s - loss: 0.7924 - mae: 0.6794 - val_loss: 12.2860 - val_mae: 2.2905\n",
      "Epoch 472/500\n",
      "303/303 - 0s - loss: 0.8211 - mae: 0.6664 - val_loss: 12.2747 - val_mae: 2.3468\n",
      "Epoch 473/500\n",
      "303/303 - 0s - loss: 0.8438 - mae: 0.6946 - val_loss: 12.0923 - val_mae: 2.1949\n",
      "Epoch 474/500\n",
      "303/303 - 0s - loss: 0.8104 - mae: 0.6637 - val_loss: 12.5089 - val_mae: 2.2904\n",
      "Epoch 475/500\n",
      "303/303 - 0s - loss: 0.7909 - mae: 0.6435 - val_loss: 12.7005 - val_mae: 2.3652\n",
      "Epoch 476/500\n",
      "303/303 - 0s - loss: 0.8412 - mae: 0.6558 - val_loss: 12.1870 - val_mae: 2.2594\n",
      "Epoch 477/500\n",
      "303/303 - 0s - loss: 0.8393 - mae: 0.6705 - val_loss: 11.9425 - val_mae: 2.2186\n",
      "Epoch 478/500\n",
      "303/303 - 0s - loss: 0.8126 - mae: 0.6298 - val_loss: 13.1659 - val_mae: 2.4242\n",
      "Epoch 479/500\n",
      "303/303 - 0s - loss: 0.8207 - mae: 0.6603 - val_loss: 12.3796 - val_mae: 2.1776\n",
      "Epoch 480/500\n",
      "303/303 - 0s - loss: 0.8448 - mae: 0.6712 - val_loss: 12.2671 - val_mae: 2.3078\n",
      "Epoch 481/500\n",
      "303/303 - 0s - loss: 0.8611 - mae: 0.6970 - val_loss: 13.0860 - val_mae: 2.3321\n",
      "Epoch 482/500\n",
      "303/303 - 0s - loss: 0.7970 - mae: 0.6148 - val_loss: 11.4397 - val_mae: 2.1914\n",
      "Epoch 483/500\n",
      "303/303 - 0s - loss: 0.6720 - mae: 0.6000 - val_loss: 12.7710 - val_mae: 2.4097\n",
      "Epoch 484/500\n",
      "303/303 - 0s - loss: 0.8329 - mae: 0.6399 - val_loss: 13.0916 - val_mae: 2.4203\n",
      "Epoch 485/500\n",
      "303/303 - 0s - loss: 0.8275 - mae: 0.6725 - val_loss: 13.1601 - val_mae: 2.3404\n",
      "Epoch 486/500\n",
      "303/303 - 0s - loss: 0.7537 - mae: 0.6515 - val_loss: 13.0712 - val_mae: 2.3856\n",
      "Epoch 487/500\n",
      "303/303 - 0s - loss: 0.7393 - mae: 0.6475 - val_loss: 12.6088 - val_mae: 2.3488\n",
      "Epoch 488/500\n",
      "303/303 - 0s - loss: 0.7898 - mae: 0.6457 - val_loss: 11.9753 - val_mae: 2.2631\n",
      "Epoch 489/500\n",
      "303/303 - 0s - loss: 0.7462 - mae: 0.6332 - val_loss: 13.7457 - val_mae: 2.5306\n",
      "Epoch 490/500\n",
      "303/303 - 0s - loss: 0.8694 - mae: 0.6864 - val_loss: 11.7543 - val_mae: 2.2125\n",
      "Epoch 491/500\n",
      "303/303 - 0s - loss: 0.7735 - mae: 0.6467 - val_loss: 12.3539 - val_mae: 2.3065\n",
      "Epoch 492/500\n",
      "303/303 - 0s - loss: 0.9049 - mae: 0.6763 - val_loss: 12.2147 - val_mae: 2.1492\n",
      "Epoch 493/500\n",
      "303/303 - 0s - loss: 0.7793 - mae: 0.6762 - val_loss: 11.3645 - val_mae: 2.2220\n",
      "Epoch 494/500\n",
      "303/303 - 0s - loss: 0.8615 - mae: 0.6641 - val_loss: 12.2905 - val_mae: 2.3303\n",
      "Epoch 495/500\n",
      "303/303 - 0s - loss: 0.8453 - mae: 0.6466 - val_loss: 12.9077 - val_mae: 2.4150\n",
      "Epoch 496/500\n",
      "303/303 - 0s - loss: 0.7838 - mae: 0.6352 - val_loss: 13.3534 - val_mae: 2.4225\n",
      "Epoch 497/500\n",
      "303/303 - 0s - loss: 0.8725 - mae: 0.6556 - val_loss: 11.8246 - val_mae: 2.1956\n",
      "Epoch 498/500\n",
      "303/303 - 0s - loss: 0.7918 - mae: 0.6590 - val_loss: 12.5415 - val_mae: 2.2827\n",
      "Epoch 499/500\n",
      "303/303 - 0s - loss: 0.7509 - mae: 0.6161 - val_loss: 13.5044 - val_mae: 2.4017\n",
      "Epoch 500/500\n",
      "303/303 - 0s - loss: 0.9043 - mae: 0.6845 - val_loss: 12.8232 - val_mae: 2.2704\n",
      "processing fold # 1\n",
      "Epoch 1/500\n",
      "303/303 - 1s - loss: 209.1045 - mae: 10.9457 - val_loss: 29.1180 - val_mae: 4.0298\n",
      "Epoch 2/500\n",
      "303/303 - 0s - loss: 32.6546 - mae: 3.6772 - val_loss: 19.2379 - val_mae: 3.2589\n",
      "Epoch 3/500\n",
      "303/303 - 0s - loss: 20.2130 - mae: 3.0717 - val_loss: 16.0156 - val_mae: 2.9209\n",
      "Epoch 4/500\n",
      "303/303 - 0s - loss: 16.8581 - mae: 2.7919 - val_loss: 13.9097 - val_mae: 2.7571\n",
      "Epoch 5/500\n",
      "303/303 - 0s - loss: 14.5300 - mae: 2.5649 - val_loss: 14.0870 - val_mae: 2.8744\n",
      "Epoch 6/500\n",
      "303/303 - 0s - loss: 13.7159 - mae: 2.4270 - val_loss: 12.8757 - val_mae: 2.7061\n",
      "Epoch 7/500\n",
      "303/303 - 0s - loss: 12.8487 - mae: 2.3398 - val_loss: 14.8874 - val_mae: 2.9839\n",
      "Epoch 8/500\n",
      "303/303 - 0s - loss: 12.2811 - mae: 2.3249 - val_loss: 13.9599 - val_mae: 2.9203\n",
      "Epoch 9/500\n",
      "303/303 - 0s - loss: 11.7028 - mae: 2.2604 - val_loss: 11.9295 - val_mae: 2.6189\n",
      "Epoch 10/500\n",
      "303/303 - 0s - loss: 11.1397 - mae: 2.1474 - val_loss: 11.5370 - val_mae: 2.5700\n",
      "Epoch 11/500\n",
      "303/303 - 0s - loss: 10.8205 - mae: 2.2247 - val_loss: 12.8372 - val_mae: 2.7902\n",
      "Epoch 12/500\n",
      "303/303 - 0s - loss: 11.1126 - mae: 2.1739 - val_loss: 11.5853 - val_mae: 2.6036\n",
      "Epoch 13/500\n",
      "303/303 - 0s - loss: 10.3226 - mae: 2.1233 - val_loss: 11.4391 - val_mae: 2.5882\n",
      "Epoch 14/500\n",
      "303/303 - 0s - loss: 9.8735 - mae: 2.1122 - val_loss: 11.1028 - val_mae: 2.5665\n",
      "Epoch 15/500\n",
      "303/303 - 0s - loss: 9.9941 - mae: 2.1378 - val_loss: 11.9084 - val_mae: 2.6291\n",
      "Epoch 16/500\n",
      "303/303 - 0s - loss: 9.7576 - mae: 2.0810 - val_loss: 10.8366 - val_mae: 2.5081\n",
      "Epoch 17/500\n",
      "303/303 - 0s - loss: 9.2015 - mae: 1.9965 - val_loss: 10.6656 - val_mae: 2.5277\n",
      "Epoch 18/500\n",
      "303/303 - 0s - loss: 9.8689 - mae: 2.0246 - val_loss: 11.8703 - val_mae: 2.6535\n",
      "Epoch 19/500\n",
      "303/303 - 0s - loss: 9.2066 - mae: 1.9729 - val_loss: 12.1944 - val_mae: 2.7064\n",
      "Epoch 20/500\n",
      "303/303 - 0s - loss: 9.3019 - mae: 1.9847 - val_loss: 11.8280 - val_mae: 2.6379\n",
      "Epoch 21/500\n",
      "303/303 - 0s - loss: 8.8968 - mae: 1.9964 - val_loss: 11.5317 - val_mae: 2.6253\n",
      "Epoch 22/500\n",
      "303/303 - 0s - loss: 8.7532 - mae: 1.9984 - val_loss: 12.4148 - val_mae: 2.6807\n",
      "Epoch 23/500\n",
      "303/303 - 0s - loss: 8.6138 - mae: 1.9450 - val_loss: 10.8012 - val_mae: 2.5362\n",
      "Epoch 24/500\n",
      "303/303 - 0s - loss: 8.6251 - mae: 1.9663 - val_loss: 10.9034 - val_mae: 2.5416\n",
      "Epoch 25/500\n",
      "303/303 - 0s - loss: 8.5555 - mae: 1.9107 - val_loss: 10.4599 - val_mae: 2.4696\n",
      "Epoch 26/500\n",
      "303/303 - 0s - loss: 7.7214 - mae: 1.8172 - val_loss: 10.2907 - val_mae: 2.4451\n",
      "Epoch 27/500\n",
      "303/303 - 0s - loss: 8.2221 - mae: 1.8643 - val_loss: 10.3264 - val_mae: 2.4628\n",
      "Epoch 28/500\n",
      "303/303 - 0s - loss: 7.9975 - mae: 1.8704 - val_loss: 11.1640 - val_mae: 2.6288\n",
      "Epoch 29/500\n",
      "303/303 - 0s - loss: 7.9815 - mae: 1.8995 - val_loss: 10.1258 - val_mae: 2.3780\n",
      "Epoch 30/500\n",
      "303/303 - 0s - loss: 7.8002 - mae: 1.8480 - val_loss: 8.9895 - val_mae: 2.2735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/500\n",
      "303/303 - 0s - loss: 7.5548 - mae: 1.7805 - val_loss: 11.7189 - val_mae: 2.6777\n",
      "Epoch 32/500\n",
      "303/303 - 0s - loss: 7.6570 - mae: 1.8477 - val_loss: 10.4384 - val_mae: 2.4521\n",
      "Epoch 33/500\n",
      "303/303 - 0s - loss: 7.4987 - mae: 1.8091 - val_loss: 8.9441 - val_mae: 2.2879\n",
      "Epoch 34/500\n",
      "303/303 - 0s - loss: 7.3253 - mae: 1.8096 - val_loss: 10.3308 - val_mae: 2.5018\n",
      "Epoch 35/500\n",
      "303/303 - 0s - loss: 7.3047 - mae: 1.7978 - val_loss: 8.7962 - val_mae: 2.2767\n",
      "Epoch 36/500\n",
      "303/303 - 0s - loss: 7.1469 - mae: 1.7534 - val_loss: 9.4673 - val_mae: 2.3536\n",
      "Epoch 37/500\n",
      "303/303 - 0s - loss: 7.3470 - mae: 1.7283 - val_loss: 9.1175 - val_mae: 2.3114\n",
      "Epoch 38/500\n",
      "303/303 - 0s - loss: 6.9783 - mae: 1.7753 - val_loss: 12.3560 - val_mae: 2.6853\n",
      "Epoch 39/500\n",
      "303/303 - 0s - loss: 6.8703 - mae: 1.7352 - val_loss: 9.7262 - val_mae: 2.4280\n",
      "Epoch 40/500\n",
      "303/303 - 0s - loss: 6.9254 - mae: 1.7255 - val_loss: 9.3073 - val_mae: 2.3668\n",
      "Epoch 41/500\n",
      "303/303 - 0s - loss: 6.4478 - mae: 1.6409 - val_loss: 11.6149 - val_mae: 2.6215\n",
      "Epoch 42/500\n",
      "303/303 - 0s - loss: 6.7263 - mae: 1.7605 - val_loss: 8.4692 - val_mae: 2.1852\n",
      "Epoch 43/500\n",
      "303/303 - 0s - loss: 6.4276 - mae: 1.6450 - val_loss: 10.8384 - val_mae: 2.5782\n",
      "Epoch 44/500\n",
      "303/303 - 0s - loss: 6.7381 - mae: 1.6589 - val_loss: 9.4292 - val_mae: 2.3517\n",
      "Epoch 45/500\n",
      "303/303 - 0s - loss: 6.2998 - mae: 1.6609 - val_loss: 11.5408 - val_mae: 2.6517\n",
      "Epoch 46/500\n",
      "303/303 - 0s - loss: 6.5338 - mae: 1.7570 - val_loss: 9.6547 - val_mae: 2.3900\n",
      "Epoch 47/500\n",
      "303/303 - 0s - loss: 6.5208 - mae: 1.6731 - val_loss: 11.4622 - val_mae: 2.5775\n",
      "Epoch 48/500\n",
      "303/303 - 0s - loss: 6.0052 - mae: 1.6715 - val_loss: 10.8459 - val_mae: 2.4786\n",
      "Epoch 49/500\n",
      "303/303 - 0s - loss: 6.4294 - mae: 1.6277 - val_loss: 9.3206 - val_mae: 2.3249\n",
      "Epoch 50/500\n",
      "303/303 - 0s - loss: 6.4236 - mae: 1.6705 - val_loss: 12.0915 - val_mae: 2.6827\n",
      "Epoch 51/500\n",
      "303/303 - 0s - loss: 5.8237 - mae: 1.5980 - val_loss: 11.9806 - val_mae: 2.6290\n",
      "Epoch 52/500\n",
      "303/303 - 0s - loss: 5.8384 - mae: 1.5901 - val_loss: 11.5977 - val_mae: 2.5852\n",
      "Epoch 53/500\n",
      "303/303 - 0s - loss: 6.1501 - mae: 1.6546 - val_loss: 9.9017 - val_mae: 2.3905\n",
      "Epoch 54/500\n",
      "303/303 - 0s - loss: 5.8882 - mae: 1.6098 - val_loss: 8.8966 - val_mae: 2.2603\n",
      "Epoch 55/500\n",
      "303/303 - 0s - loss: 6.0031 - mae: 1.6170 - val_loss: 10.7747 - val_mae: 2.5187\n",
      "Epoch 56/500\n",
      "303/303 - 0s - loss: 6.0447 - mae: 1.5985 - val_loss: 10.3190 - val_mae: 2.4370\n",
      "Epoch 57/500\n",
      "303/303 - 0s - loss: 5.7455 - mae: 1.5669 - val_loss: 9.7882 - val_mae: 2.3399\n",
      "Epoch 58/500\n",
      "303/303 - 0s - loss: 5.7130 - mae: 1.5395 - val_loss: 14.7362 - val_mae: 2.9539\n",
      "Epoch 59/500\n",
      "303/303 - 0s - loss: 5.6122 - mae: 1.5572 - val_loss: 9.2782 - val_mae: 2.2600\n",
      "Epoch 60/500\n",
      "303/303 - 0s - loss: 5.4643 - mae: 1.5269 - val_loss: 8.5131 - val_mae: 2.2016\n",
      "Epoch 61/500\n",
      "303/303 - 0s - loss: 5.5654 - mae: 1.5671 - val_loss: 9.4557 - val_mae: 2.3595\n",
      "Epoch 62/500\n",
      "303/303 - 0s - loss: 5.1913 - mae: 1.5581 - val_loss: 9.4966 - val_mae: 2.2702\n",
      "Epoch 63/500\n",
      "303/303 - 0s - loss: 5.1924 - mae: 1.5304 - val_loss: 12.3196 - val_mae: 2.6627\n",
      "Epoch 64/500\n",
      "303/303 - 0s - loss: 5.3928 - mae: 1.5156 - val_loss: 9.7977 - val_mae: 2.3482\n",
      "Epoch 65/500\n",
      "303/303 - 0s - loss: 5.5054 - mae: 1.5508 - val_loss: 11.8072 - val_mae: 2.6386\n",
      "Epoch 66/500\n",
      "303/303 - 0s - loss: 5.1499 - mae: 1.4667 - val_loss: 8.3331 - val_mae: 2.1934\n",
      "Epoch 67/500\n",
      "303/303 - 0s - loss: 4.9186 - mae: 1.4078 - val_loss: 9.5378 - val_mae: 2.2372\n",
      "Epoch 68/500\n",
      "303/303 - 0s - loss: 5.1954 - mae: 1.4457 - val_loss: 9.1794 - val_mae: 2.2858\n",
      "Epoch 69/500\n",
      "303/303 - 0s - loss: 4.7944 - mae: 1.4517 - val_loss: 10.9997 - val_mae: 2.4854\n",
      "Epoch 70/500\n",
      "303/303 - 0s - loss: 5.1697 - mae: 1.4898 - val_loss: 9.2224 - val_mae: 2.2667\n",
      "Epoch 71/500\n",
      "303/303 - 0s - loss: 5.0327 - mae: 1.4796 - val_loss: 11.2291 - val_mae: 2.4135\n",
      "Epoch 72/500\n",
      "303/303 - 0s - loss: 5.0051 - mae: 1.4756 - val_loss: 9.5860 - val_mae: 2.2732\n",
      "Epoch 73/500\n",
      "303/303 - 0s - loss: 4.7471 - mae: 1.4333 - val_loss: 10.2606 - val_mae: 2.3665\n",
      "Epoch 74/500\n",
      "303/303 - 0s - loss: 4.9245 - mae: 1.4775 - val_loss: 11.3355 - val_mae: 2.4212\n",
      "Epoch 75/500\n",
      "303/303 - 0s - loss: 4.4746 - mae: 1.4136 - val_loss: 11.1450 - val_mae: 2.3990\n",
      "Epoch 76/500\n",
      "303/303 - 0s - loss: 4.6187 - mae: 1.4070 - val_loss: 14.7660 - val_mae: 2.8397\n",
      "Epoch 77/500\n",
      "303/303 - 0s - loss: 4.5724 - mae: 1.4658 - val_loss: 10.1627 - val_mae: 2.3166\n",
      "Epoch 78/500\n",
      "303/303 - 0s - loss: 4.7755 - mae: 1.3723 - val_loss: 12.5538 - val_mae: 2.6353\n",
      "Epoch 79/500\n",
      "303/303 - 0s - loss: 4.4498 - mae: 1.4289 - val_loss: 11.1714 - val_mae: 2.4307\n",
      "Epoch 80/500\n",
      "303/303 - 0s - loss: 4.5898 - mae: 1.3814 - val_loss: 17.2493 - val_mae: 2.9379\n",
      "Epoch 81/500\n",
      "303/303 - 0s - loss: 4.4378 - mae: 1.4223 - val_loss: 13.6928 - val_mae: 2.6651\n",
      "Epoch 82/500\n",
      "303/303 - 0s - loss: 4.4794 - mae: 1.4010 - val_loss: 12.1846 - val_mae: 2.4458\n",
      "Epoch 83/500\n",
      "303/303 - 0s - loss: 4.2738 - mae: 1.3504 - val_loss: 12.1421 - val_mae: 2.4914\n",
      "Epoch 84/500\n",
      "303/303 - 0s - loss: 4.2379 - mae: 1.3915 - val_loss: 15.8253 - val_mae: 2.7690\n",
      "Epoch 85/500\n",
      "303/303 - 0s - loss: 4.0487 - mae: 1.3745 - val_loss: 10.7220 - val_mae: 2.3500\n",
      "Epoch 86/500\n",
      "303/303 - 0s - loss: 4.2793 - mae: 1.3805 - val_loss: 13.0216 - val_mae: 2.5022\n",
      "Epoch 87/500\n",
      "303/303 - 0s - loss: 3.7860 - mae: 1.3884 - val_loss: 13.9774 - val_mae: 2.6009\n",
      "Epoch 88/500\n",
      "303/303 - 0s - loss: 3.9707 - mae: 1.3660 - val_loss: 12.5188 - val_mae: 2.4800\n",
      "Epoch 89/500\n",
      "303/303 - 0s - loss: 4.3297 - mae: 1.4106 - val_loss: 12.1160 - val_mae: 2.4744\n",
      "Epoch 90/500\n",
      "303/303 - 0s - loss: 3.9725 - mae: 1.3664 - val_loss: 10.7831 - val_mae: 2.4515\n",
      "Epoch 91/500\n",
      "303/303 - 0s - loss: 4.0077 - mae: 1.3896 - val_loss: 12.4665 - val_mae: 2.5116\n",
      "Epoch 92/500\n",
      "303/303 - 0s - loss: 3.6327 - mae: 1.2425 - val_loss: 13.4324 - val_mae: 2.7714\n",
      "Epoch 93/500\n",
      "303/303 - 0s - loss: 4.0536 - mae: 1.3746 - val_loss: 16.1186 - val_mae: 2.6540\n",
      "Epoch 94/500\n",
      "303/303 - 0s - loss: 3.6579 - mae: 1.3140 - val_loss: 13.7633 - val_mae: 2.8017\n",
      "Epoch 95/500\n",
      "303/303 - 0s - loss: 3.7729 - mae: 1.3137 - val_loss: 17.4774 - val_mae: 2.7621\n",
      "Epoch 96/500\n",
      "303/303 - 0s - loss: 3.7065 - mae: 1.2653 - val_loss: 15.8155 - val_mae: 2.6649\n",
      "Epoch 97/500\n",
      "303/303 - 0s - loss: 3.8890 - mae: 1.3286 - val_loss: 21.4598 - val_mae: 2.9116\n",
      "Epoch 98/500\n",
      "303/303 - 0s - loss: 4.0768 - mae: 1.3149 - val_loss: 16.7467 - val_mae: 2.7775\n",
      "Epoch 99/500\n",
      "303/303 - 0s - loss: 3.8738 - mae: 1.3340 - val_loss: 13.4265 - val_mae: 2.4990\n",
      "Epoch 100/500\n",
      "303/303 - 0s - loss: 3.6568 - mae: 1.2909 - val_loss: 13.3500 - val_mae: 2.4702\n",
      "Epoch 101/500\n",
      "303/303 - 0s - loss: 3.8776 - mae: 1.3274 - val_loss: 14.3578 - val_mae: 2.5204\n",
      "Epoch 102/500\n",
      "303/303 - 0s - loss: 3.3738 - mae: 1.2397 - val_loss: 14.2258 - val_mae: 2.4390\n",
      "Epoch 103/500\n",
      "303/303 - 0s - loss: 3.4022 - mae: 1.3007 - val_loss: 21.2967 - val_mae: 2.8229\n",
      "Epoch 104/500\n",
      "303/303 - 0s - loss: 3.2697 - mae: 1.2827 - val_loss: 16.9469 - val_mae: 2.9321\n",
      "Epoch 105/500\n",
      "303/303 - 0s - loss: 3.4475 - mae: 1.2938 - val_loss: 11.8054 - val_mae: 2.4317\n",
      "Epoch 106/500\n",
      "303/303 - 0s - loss: 3.2484 - mae: 1.2507 - val_loss: 16.6312 - val_mae: 2.6054\n",
      "Epoch 107/500\n",
      "303/303 - 0s - loss: 3.3626 - mae: 1.2878 - val_loss: 18.6329 - val_mae: 2.7957\n",
      "Epoch 108/500\n",
      "303/303 - 0s - loss: 3.5395 - mae: 1.2501 - val_loss: 17.2366 - val_mae: 2.7772\n",
      "Epoch 109/500\n",
      "303/303 - 0s - loss: 3.4137 - mae: 1.2824 - val_loss: 23.4857 - val_mae: 2.9140\n",
      "Epoch 110/500\n",
      "303/303 - 0s - loss: 3.4634 - mae: 1.2143 - val_loss: 18.3765 - val_mae: 2.9283\n",
      "Epoch 111/500\n",
      "303/303 - 0s - loss: 3.2465 - mae: 1.2205 - val_loss: 18.7996 - val_mae: 2.8123\n",
      "Epoch 112/500\n",
      "303/303 - 0s - loss: 3.3886 - mae: 1.2554 - val_loss: 17.6855 - val_mae: 2.7501\n",
      "Epoch 113/500\n",
      "303/303 - 0s - loss: 3.3383 - mae: 1.2604 - val_loss: 18.7716 - val_mae: 2.9067\n",
      "Epoch 114/500\n",
      "303/303 - 0s - loss: 3.1464 - mae: 1.2005 - val_loss: 20.1435 - val_mae: 2.7724\n",
      "Epoch 115/500\n",
      "303/303 - 0s - loss: 3.3111 - mae: 1.2495 - val_loss: 25.8035 - val_mae: 3.1563\n",
      "Epoch 116/500\n",
      "303/303 - 0s - loss: 2.9855 - mae: 1.2568 - val_loss: 18.7866 - val_mae: 2.8098\n",
      "Epoch 117/500\n",
      "303/303 - 0s - loss: 3.2894 - mae: 1.2084 - val_loss: 21.6195 - val_mae: 2.9590\n",
      "Epoch 118/500\n",
      "303/303 - 0s - loss: 2.8103 - mae: 1.1818 - val_loss: 16.8671 - val_mae: 2.6781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/500\n",
      "303/303 - 0s - loss: 2.9877 - mae: 1.2111 - val_loss: 22.4207 - val_mae: 2.8408\n",
      "Epoch 120/500\n",
      "303/303 - 0s - loss: 3.0250 - mae: 1.2206 - val_loss: 22.6454 - val_mae: 2.9300\n",
      "Epoch 121/500\n",
      "303/303 - 0s - loss: 3.0223 - mae: 1.2333 - val_loss: 23.6517 - val_mae: 2.8791\n",
      "Epoch 122/500\n",
      "303/303 - 0s - loss: 3.0343 - mae: 1.1972 - val_loss: 25.6551 - val_mae: 2.9559\n",
      "Epoch 123/500\n",
      "303/303 - 0s - loss: 2.9029 - mae: 1.2330 - val_loss: 22.0694 - val_mae: 2.7574\n",
      "Epoch 124/500\n",
      "303/303 - 0s - loss: 3.0647 - mae: 1.2067 - val_loss: 29.0497 - val_mae: 3.0395\n",
      "Epoch 125/500\n",
      "303/303 - 0s - loss: 2.8753 - mae: 1.2200 - val_loss: 20.7951 - val_mae: 2.9097\n",
      "Epoch 126/500\n",
      "303/303 - 0s - loss: 3.1291 - mae: 1.1969 - val_loss: 21.8894 - val_mae: 2.8577\n",
      "Epoch 127/500\n",
      "303/303 - 0s - loss: 2.8463 - mae: 1.1558 - val_loss: 22.5308 - val_mae: 2.7261\n",
      "Epoch 128/500\n",
      "303/303 - 0s - loss: 2.8912 - mae: 1.1821 - val_loss: 23.3734 - val_mae: 3.0885\n",
      "Epoch 129/500\n",
      "303/303 - 0s - loss: 2.8258 - mae: 1.1680 - val_loss: 24.0141 - val_mae: 2.8958\n",
      "Epoch 130/500\n",
      "303/303 - 0s - loss: 2.6795 - mae: 1.1485 - val_loss: 25.8700 - val_mae: 2.8394\n",
      "Epoch 131/500\n",
      "303/303 - 0s - loss: 2.9033 - mae: 1.2067 - val_loss: 23.2646 - val_mae: 3.0183\n",
      "Epoch 132/500\n",
      "303/303 - 0s - loss: 2.7229 - mae: 1.1574 - val_loss: 22.6643 - val_mae: 2.9400\n",
      "Epoch 133/500\n",
      "303/303 - 0s - loss: 2.6338 - mae: 1.1489 - val_loss: 23.7589 - val_mae: 2.8490\n",
      "Epoch 134/500\n",
      "303/303 - 0s - loss: 2.9024 - mae: 1.1755 - val_loss: 25.9406 - val_mae: 2.9832\n",
      "Epoch 135/500\n",
      "303/303 - 0s - loss: 2.6563 - mae: 1.1841 - val_loss: 20.2240 - val_mae: 2.7018\n",
      "Epoch 136/500\n",
      "303/303 - 0s - loss: 2.7246 - mae: 1.1789 - val_loss: 28.8053 - val_mae: 3.0678\n",
      "Epoch 137/500\n",
      "303/303 - 0s - loss: 2.7152 - mae: 1.0751 - val_loss: 27.0525 - val_mae: 2.9212\n",
      "Epoch 138/500\n",
      "303/303 - 0s - loss: 2.5544 - mae: 1.0815 - val_loss: 23.9262 - val_mae: 2.9879\n",
      "Epoch 139/500\n",
      "303/303 - 0s - loss: 2.7427 - mae: 1.1290 - val_loss: 22.4788 - val_mae: 2.9426\n",
      "Epoch 140/500\n",
      "303/303 - 0s - loss: 2.6616 - mae: 1.1799 - val_loss: 25.3171 - val_mae: 3.0452\n",
      "Epoch 141/500\n",
      "303/303 - 0s - loss: 2.4088 - mae: 1.1080 - val_loss: 31.8928 - val_mae: 3.1479\n",
      "Epoch 142/500\n",
      "303/303 - 0s - loss: 2.5889 - mae: 1.1995 - val_loss: 30.3394 - val_mae: 3.2558\n",
      "Epoch 143/500\n",
      "303/303 - 0s - loss: 2.5135 - mae: 1.0883 - val_loss: 24.8008 - val_mae: 2.8850\n",
      "Epoch 144/500\n",
      "303/303 - 0s - loss: 2.6409 - mae: 1.1543 - val_loss: 32.0836 - val_mae: 3.2978\n",
      "Epoch 145/500\n",
      "303/303 - 0s - loss: 2.4341 - mae: 1.1665 - val_loss: 20.8657 - val_mae: 2.9269\n",
      "Epoch 146/500\n",
      "303/303 - 0s - loss: 2.3685 - mae: 1.1107 - val_loss: 23.1044 - val_mae: 2.8661\n",
      "Epoch 147/500\n",
      "303/303 - 0s - loss: 2.7204 - mae: 1.1163 - val_loss: 33.5976 - val_mae: 3.1318\n",
      "Epoch 148/500\n",
      "303/303 - 0s - loss: 2.3177 - mae: 1.0747 - val_loss: 32.4107 - val_mae: 3.1257\n",
      "Epoch 149/500\n",
      "303/303 - 0s - loss: 2.2602 - mae: 1.0888 - val_loss: 23.5110 - val_mae: 2.9007\n",
      "Epoch 150/500\n",
      "303/303 - 0s - loss: 2.2327 - mae: 1.0453 - val_loss: 25.0800 - val_mae: 2.8769\n",
      "Epoch 151/500\n",
      "303/303 - 0s - loss: 2.0558 - mae: 1.0655 - val_loss: 30.5903 - val_mae: 3.2230\n",
      "Epoch 152/500\n",
      "303/303 - 0s - loss: 2.3731 - mae: 1.1013 - val_loss: 26.4179 - val_mae: 3.0595\n",
      "Epoch 153/500\n",
      "303/303 - 0s - loss: 2.2723 - mae: 1.0801 - val_loss: 26.1054 - val_mae: 2.9838\n",
      "Epoch 154/500\n",
      "303/303 - 0s - loss: 2.2166 - mae: 1.0495 - val_loss: 25.9577 - val_mae: 3.3123\n",
      "Epoch 155/500\n",
      "303/303 - 0s - loss: 2.1180 - mae: 1.0614 - val_loss: 28.9472 - val_mae: 3.0871\n",
      "Epoch 156/500\n",
      "303/303 - 0s - loss: 2.2198 - mae: 1.0663 - val_loss: 33.3918 - val_mae: 3.2424\n",
      "Epoch 157/500\n",
      "303/303 - 0s - loss: 2.2401 - mae: 1.0716 - val_loss: 27.6980 - val_mae: 2.9148\n",
      "Epoch 158/500\n",
      "303/303 - 0s - loss: 2.1054 - mae: 1.0247 - val_loss: 33.9726 - val_mae: 3.3236\n",
      "Epoch 159/500\n",
      "303/303 - 0s - loss: 2.0252 - mae: 1.0571 - val_loss: 32.5087 - val_mae: 3.0977\n",
      "Epoch 160/500\n",
      "303/303 - 0s - loss: 2.1825 - mae: 1.0558 - val_loss: 34.5389 - val_mae: 3.1453\n",
      "Epoch 161/500\n",
      "303/303 - 0s - loss: 2.0913 - mae: 1.0656 - val_loss: 34.3604 - val_mae: 3.6552\n",
      "Epoch 162/500\n",
      "303/303 - 0s - loss: 2.2399 - mae: 1.0949 - val_loss: 29.2059 - val_mae: 3.1486\n",
      "Epoch 163/500\n",
      "303/303 - 0s - loss: 2.2333 - mae: 1.0587 - val_loss: 31.4085 - val_mae: 3.0109\n",
      "Epoch 164/500\n",
      "303/303 - 0s - loss: 2.1526 - mae: 1.0326 - val_loss: 31.1585 - val_mae: 3.1304\n",
      "Epoch 165/500\n",
      "303/303 - 0s - loss: 2.1923 - mae: 1.0277 - val_loss: 27.4219 - val_mae: 2.9736\n",
      "Epoch 166/500\n",
      "303/303 - 0s - loss: 1.8030 - mae: 0.9562 - val_loss: 28.7713 - val_mae: 2.9347\n",
      "Epoch 167/500\n",
      "303/303 - 0s - loss: 2.0428 - mae: 1.0835 - val_loss: 31.1202 - val_mae: 3.0646\n",
      "Epoch 168/500\n",
      "303/303 - 0s - loss: 1.9466 - mae: 0.9967 - val_loss: 24.6067 - val_mae: 3.0290\n",
      "Epoch 169/500\n",
      "303/303 - 0s - loss: 2.1829 - mae: 1.0518 - val_loss: 33.6542 - val_mae: 3.2343\n",
      "Epoch 170/500\n",
      "303/303 - 0s - loss: 1.9800 - mae: 1.0230 - val_loss: 27.6697 - val_mae: 3.0625\n",
      "Epoch 171/500\n",
      "303/303 - 0s - loss: 1.9574 - mae: 0.9931 - val_loss: 31.9373 - val_mae: 3.2978\n",
      "Epoch 172/500\n",
      "303/303 - 0s - loss: 1.8352 - mae: 0.9962 - val_loss: 36.4741 - val_mae: 3.3371\n",
      "Epoch 173/500\n",
      "303/303 - 0s - loss: 1.9200 - mae: 1.0282 - val_loss: 27.0574 - val_mae: 3.0214\n",
      "Epoch 174/500\n",
      "303/303 - 0s - loss: 1.9180 - mae: 0.9863 - val_loss: 30.2564 - val_mae: 3.0753\n",
      "Epoch 175/500\n",
      "303/303 - 0s - loss: 2.0426 - mae: 1.0106 - val_loss: 27.0196 - val_mae: 3.0093\n",
      "Epoch 176/500\n",
      "303/303 - 0s - loss: 2.0987 - mae: 1.0479 - val_loss: 33.4451 - val_mae: 3.3638\n",
      "Epoch 177/500\n",
      "303/303 - 0s - loss: 1.9994 - mae: 1.0378 - val_loss: 28.7910 - val_mae: 3.0533\n",
      "Epoch 178/500\n",
      "303/303 - 0s - loss: 1.7645 - mae: 0.9589 - val_loss: 35.8843 - val_mae: 3.5128\n",
      "Epoch 179/500\n",
      "303/303 - 0s - loss: 1.8785 - mae: 1.0200 - val_loss: 30.7817 - val_mae: 3.2681\n",
      "Epoch 180/500\n",
      "303/303 - 0s - loss: 2.0897 - mae: 1.0857 - val_loss: 36.6993 - val_mae: 3.2826\n",
      "Epoch 181/500\n",
      "303/303 - 0s - loss: 1.6685 - mae: 0.9459 - val_loss: 31.8413 - val_mae: 3.6749\n",
      "Epoch 182/500\n",
      "303/303 - 0s - loss: 1.8918 - mae: 1.0110 - val_loss: 36.9319 - val_mae: 3.4080\n",
      "Epoch 183/500\n",
      "303/303 - 0s - loss: 1.9351 - mae: 1.0082 - val_loss: 27.3941 - val_mae: 3.1005\n",
      "Epoch 184/500\n",
      "303/303 - 0s - loss: 1.6491 - mae: 0.9488 - val_loss: 28.7607 - val_mae: 2.9819\n",
      "Epoch 185/500\n",
      "303/303 - 0s - loss: 1.7193 - mae: 0.9673 - val_loss: 38.0519 - val_mae: 3.4276\n",
      "Epoch 186/500\n",
      "303/303 - 0s - loss: 1.7404 - mae: 0.9625 - val_loss: 24.8786 - val_mae: 2.9764\n",
      "Epoch 187/500\n",
      "303/303 - 0s - loss: 1.7707 - mae: 0.9976 - val_loss: 23.6946 - val_mae: 3.0526\n",
      "Epoch 188/500\n",
      "303/303 - 0s - loss: 1.7804 - mae: 0.9694 - val_loss: 23.3142 - val_mae: 2.9875\n",
      "Epoch 189/500\n",
      "303/303 - 0s - loss: 1.6541 - mae: 0.9573 - val_loss: 34.3108 - val_mae: 3.3331\n",
      "Epoch 190/500\n",
      "303/303 - 0s - loss: 1.7410 - mae: 1.0032 - val_loss: 35.6727 - val_mae: 3.4241\n",
      "Epoch 191/500\n",
      "303/303 - 0s - loss: 1.5656 - mae: 0.9093 - val_loss: 25.9515 - val_mae: 3.0761\n",
      "Epoch 192/500\n",
      "303/303 - 0s - loss: 1.6939 - mae: 0.9779 - val_loss: 30.9284 - val_mae: 3.1371\n",
      "Epoch 193/500\n",
      "303/303 - 0s - loss: 1.7735 - mae: 0.9867 - val_loss: 30.3472 - val_mae: 3.1526\n",
      "Epoch 194/500\n",
      "303/303 - 0s - loss: 1.5278 - mae: 0.9134 - val_loss: 38.6738 - val_mae: 3.6436\n",
      "Epoch 195/500\n",
      "303/303 - 0s - loss: 1.7499 - mae: 0.9611 - val_loss: 31.3756 - val_mae: 3.3035\n",
      "Epoch 196/500\n",
      "303/303 - 0s - loss: 1.8905 - mae: 0.9635 - val_loss: 30.5841 - val_mae: 3.1383\n",
      "Epoch 197/500\n",
      "303/303 - 0s - loss: 1.6731 - mae: 0.9306 - val_loss: 31.0576 - val_mae: 3.1115\n",
      "Epoch 198/500\n",
      "303/303 - 0s - loss: 1.6575 - mae: 0.9523 - val_loss: 33.2158 - val_mae: 3.3551\n",
      "Epoch 199/500\n",
      "303/303 - 0s - loss: 1.5546 - mae: 0.9259 - val_loss: 35.4963 - val_mae: 3.5417\n",
      "Epoch 200/500\n",
      "303/303 - 0s - loss: 1.7251 - mae: 0.9485 - val_loss: 36.0989 - val_mae: 3.4516\n",
      "Epoch 201/500\n",
      "303/303 - 0s - loss: 1.6751 - mae: 0.9722 - val_loss: 32.8982 - val_mae: 3.3251\n",
      "Epoch 202/500\n",
      "303/303 - 0s - loss: 1.6801 - mae: 0.9388 - val_loss: 28.1814 - val_mae: 3.2417\n",
      "Epoch 203/500\n",
      "303/303 - 0s - loss: 1.7067 - mae: 0.9670 - val_loss: 28.1696 - val_mae: 3.1714\n",
      "Epoch 204/500\n",
      "303/303 - 0s - loss: 1.7365 - mae: 0.9650 - val_loss: 33.0342 - val_mae: 3.3372\n",
      "Epoch 205/500\n",
      "303/303 - 0s - loss: 1.7222 - mae: 0.9486 - val_loss: 33.3237 - val_mae: 3.1702\n",
      "Epoch 206/500\n",
      "303/303 - 0s - loss: 1.5472 - mae: 0.9287 - val_loss: 42.4311 - val_mae: 3.4702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207/500\n",
      "303/303 - 0s - loss: 1.5577 - mae: 0.9237 - val_loss: 30.8094 - val_mae: 3.1102\n",
      "Epoch 208/500\n",
      "303/303 - 0s - loss: 1.6667 - mae: 0.9163 - val_loss: 28.6533 - val_mae: 3.1361\n",
      "Epoch 209/500\n",
      "303/303 - 0s - loss: 1.5692 - mae: 0.8894 - val_loss: 39.0072 - val_mae: 3.3500\n",
      "Epoch 210/500\n",
      "303/303 - 0s - loss: 1.5194 - mae: 0.9685 - val_loss: 24.4328 - val_mae: 2.9461\n",
      "Epoch 211/500\n",
      "303/303 - 0s - loss: 1.5199 - mae: 0.9309 - val_loss: 25.6744 - val_mae: 2.9853\n",
      "Epoch 212/500\n",
      "303/303 - 0s - loss: 1.5254 - mae: 0.9175 - val_loss: 33.0626 - val_mae: 3.3037\n",
      "Epoch 213/500\n",
      "303/303 - 0s - loss: 1.5370 - mae: 0.9341 - val_loss: 25.8435 - val_mae: 3.0175\n",
      "Epoch 214/500\n",
      "303/303 - 0s - loss: 1.4039 - mae: 0.8907 - val_loss: 26.9707 - val_mae: 3.0963\n",
      "Epoch 215/500\n",
      "303/303 - 0s - loss: 1.4535 - mae: 0.9074 - val_loss: 31.0409 - val_mae: 3.3036\n",
      "Epoch 216/500\n",
      "303/303 - 0s - loss: 1.6374 - mae: 0.9383 - val_loss: 28.7676 - val_mae: 3.2193\n",
      "Epoch 217/500\n",
      "303/303 - 0s - loss: 1.4199 - mae: 0.8372 - val_loss: 35.2950 - val_mae: 3.4049\n",
      "Epoch 218/500\n",
      "303/303 - 0s - loss: 1.5656 - mae: 0.9079 - val_loss: 32.0038 - val_mae: 3.2724\n",
      "Epoch 219/500\n",
      "303/303 - 0s - loss: 1.3203 - mae: 0.8440 - val_loss: 29.4818 - val_mae: 3.1805\n",
      "Epoch 220/500\n",
      "303/303 - 0s - loss: 1.4385 - mae: 0.8924 - val_loss: 29.7494 - val_mae: 3.0024\n",
      "Epoch 221/500\n",
      "303/303 - 0s - loss: 1.3618 - mae: 0.8547 - val_loss: 24.2689 - val_mae: 2.9103\n",
      "Epoch 222/500\n",
      "303/303 - 0s - loss: 1.4224 - mae: 0.9242 - val_loss: 27.3275 - val_mae: 2.9837\n",
      "Epoch 223/500\n",
      "303/303 - 0s - loss: 1.4119 - mae: 0.8798 - val_loss: 32.1323 - val_mae: 3.1738\n",
      "Epoch 224/500\n",
      "303/303 - 0s - loss: 1.3790 - mae: 0.8718 - val_loss: 28.7230 - val_mae: 2.9881\n",
      "Epoch 225/500\n",
      "303/303 - 0s - loss: 1.6866 - mae: 0.9228 - val_loss: 33.3181 - val_mae: 3.1953\n",
      "Epoch 226/500\n",
      "303/303 - 0s - loss: 1.4868 - mae: 0.8565 - val_loss: 21.6889 - val_mae: 2.8175\n",
      "Epoch 227/500\n",
      "303/303 - 0s - loss: 1.2744 - mae: 0.8240 - val_loss: 37.5756 - val_mae: 3.2416\n",
      "Epoch 228/500\n",
      "303/303 - 0s - loss: 1.4718 - mae: 0.8978 - val_loss: 27.2010 - val_mae: 3.0868\n",
      "Epoch 229/500\n",
      "303/303 - 0s - loss: 1.2341 - mae: 0.8061 - val_loss: 32.0053 - val_mae: 3.2843\n",
      "Epoch 230/500\n",
      "303/303 - 0s - loss: 1.3945 - mae: 0.8661 - val_loss: 32.0912 - val_mae: 3.1358\n",
      "Epoch 231/500\n",
      "303/303 - 0s - loss: 1.5049 - mae: 0.8739 - val_loss: 32.6767 - val_mae: 3.3346\n",
      "Epoch 232/500\n",
      "303/303 - 0s - loss: 1.4531 - mae: 0.8612 - val_loss: 26.0819 - val_mae: 2.8808\n",
      "Epoch 233/500\n",
      "303/303 - 0s - loss: 1.3303 - mae: 0.8430 - val_loss: 36.9334 - val_mae: 3.2436\n",
      "Epoch 234/500\n",
      "303/303 - 0s - loss: 1.3519 - mae: 0.8668 - val_loss: 26.6670 - val_mae: 2.9736\n",
      "Epoch 235/500\n",
      "303/303 - 0s - loss: 1.2232 - mae: 0.7824 - val_loss: 33.6919 - val_mae: 3.2908\n",
      "Epoch 236/500\n",
      "303/303 - 0s - loss: 1.4464 - mae: 0.8522 - val_loss: 35.1581 - val_mae: 3.1612\n",
      "Epoch 237/500\n",
      "303/303 - 0s - loss: 1.3124 - mae: 0.8704 - val_loss: 35.0332 - val_mae: 3.1584\n",
      "Epoch 238/500\n",
      "303/303 - 0s - loss: 1.3668 - mae: 0.8867 - val_loss: 31.2863 - val_mae: 3.1876\n",
      "Epoch 239/500\n",
      "303/303 - 0s - loss: 1.4740 - mae: 0.8771 - val_loss: 36.5586 - val_mae: 3.3044\n",
      "Epoch 240/500\n",
      "303/303 - 0s - loss: 1.2112 - mae: 0.8261 - val_loss: 29.4287 - val_mae: 3.0463\n",
      "Epoch 241/500\n",
      "303/303 - 0s - loss: 1.5019 - mae: 0.9077 - val_loss: 32.8262 - val_mae: 3.1683\n",
      "Epoch 242/500\n",
      "303/303 - 0s - loss: 1.4022 - mae: 0.8464 - val_loss: 26.8530 - val_mae: 2.9785\n",
      "Epoch 243/500\n",
      "303/303 - 0s - loss: 1.3817 - mae: 0.8776 - val_loss: 30.4550 - val_mae: 3.0908\n",
      "Epoch 244/500\n",
      "303/303 - 0s - loss: 1.2894 - mae: 0.8322 - val_loss: 35.2992 - val_mae: 3.2137\n",
      "Epoch 245/500\n",
      "303/303 - 0s - loss: 1.2264 - mae: 0.8102 - val_loss: 20.1065 - val_mae: 2.8453\n",
      "Epoch 246/500\n",
      "303/303 - 0s - loss: 1.1942 - mae: 0.8186 - val_loss: 39.2225 - val_mae: 3.2730\n",
      "Epoch 247/500\n",
      "303/303 - 0s - loss: 1.1324 - mae: 0.8020 - val_loss: 28.8389 - val_mae: 3.0838\n",
      "Epoch 248/500\n",
      "303/303 - 0s - loss: 1.4553 - mae: 0.8900 - val_loss: 28.9937 - val_mae: 3.3251\n",
      "Epoch 249/500\n",
      "303/303 - 0s - loss: 1.1790 - mae: 0.8368 - val_loss: 19.8635 - val_mae: 2.7870\n",
      "Epoch 250/500\n",
      "303/303 - 0s - loss: 1.2174 - mae: 0.7981 - val_loss: 36.0637 - val_mae: 3.1420\n",
      "Epoch 251/500\n",
      "303/303 - 0s - loss: 1.3093 - mae: 0.8558 - val_loss: 27.5397 - val_mae: 3.0487\n",
      "Epoch 252/500\n",
      "303/303 - 0s - loss: 1.0842 - mae: 0.7759 - val_loss: 37.6550 - val_mae: 3.2012\n",
      "Epoch 253/500\n",
      "303/303 - 0s - loss: 1.4732 - mae: 0.8634 - val_loss: 36.6257 - val_mae: 3.3592\n",
      "Epoch 254/500\n",
      "303/303 - 0s - loss: 1.2507 - mae: 0.8048 - val_loss: 37.6030 - val_mae: 3.4827\n",
      "Epoch 255/500\n",
      "303/303 - 0s - loss: 1.3222 - mae: 0.8615 - val_loss: 26.3121 - val_mae: 2.9184\n",
      "Epoch 256/500\n",
      "303/303 - 0s - loss: 1.3770 - mae: 0.7987 - val_loss: 32.5878 - val_mae: 3.0857\n",
      "Epoch 257/500\n",
      "303/303 - 0s - loss: 1.3221 - mae: 0.8625 - val_loss: 30.3949 - val_mae: 3.1698\n",
      "Epoch 258/500\n",
      "303/303 - 0s - loss: 1.2549 - mae: 0.8132 - val_loss: 26.9782 - val_mae: 2.9764\n",
      "Epoch 259/500\n",
      "303/303 - 0s - loss: 1.2091 - mae: 0.8041 - val_loss: 29.5090 - val_mae: 3.1706\n",
      "Epoch 260/500\n",
      "303/303 - 0s - loss: 1.2883 - mae: 0.8577 - val_loss: 38.1962 - val_mae: 3.3977\n",
      "Epoch 261/500\n",
      "303/303 - 0s - loss: 1.2130 - mae: 0.8029 - val_loss: 23.8115 - val_mae: 2.9267\n",
      "Epoch 262/500\n",
      "303/303 - 0s - loss: 1.1498 - mae: 0.8099 - val_loss: 33.7388 - val_mae: 3.2336\n",
      "Epoch 263/500\n",
      "303/303 - 0s - loss: 1.3213 - mae: 0.8517 - val_loss: 31.9996 - val_mae: 3.0800\n",
      "Epoch 264/500\n",
      "303/303 - 0s - loss: 1.0135 - mae: 0.7586 - val_loss: 34.4164 - val_mae: 3.2517\n",
      "Epoch 265/500\n",
      "303/303 - 0s - loss: 1.1475 - mae: 0.7762 - val_loss: 34.9184 - val_mae: 3.2734\n",
      "Epoch 266/500\n",
      "303/303 - 0s - loss: 1.1985 - mae: 0.8174 - val_loss: 28.0349 - val_mae: 3.0775\n",
      "Epoch 267/500\n",
      "303/303 - 0s - loss: 1.2006 - mae: 0.8183 - val_loss: 32.0631 - val_mae: 3.2227\n",
      "Epoch 268/500\n",
      "303/303 - 0s - loss: 1.2218 - mae: 0.7781 - val_loss: 26.9134 - val_mae: 3.1861\n",
      "Epoch 269/500\n",
      "303/303 - 0s - loss: 1.1951 - mae: 0.8055 - val_loss: 21.8847 - val_mae: 2.9512\n",
      "Epoch 270/500\n",
      "303/303 - 0s - loss: 1.1630 - mae: 0.7996 - val_loss: 27.4668 - val_mae: 3.1339\n",
      "Epoch 271/500\n",
      "303/303 - 0s - loss: 1.1641 - mae: 0.8124 - val_loss: 25.5502 - val_mae: 2.9946\n",
      "Epoch 272/500\n",
      "303/303 - 0s - loss: 1.1838 - mae: 0.7814 - val_loss: 30.2681 - val_mae: 3.1238\n",
      "Epoch 273/500\n",
      "303/303 - 0s - loss: 1.3208 - mae: 0.8231 - val_loss: 27.9537 - val_mae: 3.0498\n",
      "Epoch 274/500\n",
      "303/303 - 0s - loss: 1.0962 - mae: 0.7804 - val_loss: 26.4412 - val_mae: 3.0259\n",
      "Epoch 275/500\n",
      "303/303 - 0s - loss: 1.1695 - mae: 0.7967 - val_loss: 36.1498 - val_mae: 3.3695\n",
      "Epoch 276/500\n",
      "303/303 - 0s - loss: 1.1225 - mae: 0.8169 - val_loss: 33.7754 - val_mae: 3.3021\n",
      "Epoch 277/500\n",
      "303/303 - 0s - loss: 1.1614 - mae: 0.8024 - val_loss: 30.9980 - val_mae: 3.0982\n",
      "Epoch 278/500\n",
      "303/303 - 0s - loss: 1.2351 - mae: 0.7940 - val_loss: 19.7459 - val_mae: 2.7245\n",
      "Epoch 279/500\n",
      "303/303 - 0s - loss: 1.0840 - mae: 0.7978 - val_loss: 36.1702 - val_mae: 3.3254\n",
      "Epoch 280/500\n",
      "303/303 - 0s - loss: 1.1430 - mae: 0.8054 - val_loss: 19.0948 - val_mae: 2.8554\n",
      "Epoch 281/500\n",
      "303/303 - 0s - loss: 1.0943 - mae: 0.7451 - val_loss: 31.1671 - val_mae: 3.1559\n",
      "Epoch 282/500\n",
      "303/303 - 0s - loss: 1.3214 - mae: 0.8124 - val_loss: 23.4564 - val_mae: 2.9530\n",
      "Epoch 283/500\n",
      "303/303 - 0s - loss: 1.0017 - mae: 0.7295 - val_loss: 29.7082 - val_mae: 3.0914\n",
      "Epoch 284/500\n",
      "303/303 - 0s - loss: 1.3201 - mae: 0.8314 - val_loss: 23.3075 - val_mae: 2.9315\n",
      "Epoch 285/500\n",
      "303/303 - 0s - loss: 1.0659 - mae: 0.7800 - val_loss: 23.8949 - val_mae: 3.0099\n",
      "Epoch 286/500\n",
      "303/303 - 0s - loss: 1.1302 - mae: 0.7835 - val_loss: 30.6257 - val_mae: 3.3591\n",
      "Epoch 287/500\n",
      "303/303 - 0s - loss: 1.2291 - mae: 0.7838 - val_loss: 26.2931 - val_mae: 3.0088\n",
      "Epoch 288/500\n",
      "303/303 - 0s - loss: 1.0729 - mae: 0.7906 - val_loss: 24.7820 - val_mae: 3.0066\n",
      "Epoch 289/500\n",
      "303/303 - 0s - loss: 1.1571 - mae: 0.7873 - val_loss: 26.0566 - val_mae: 3.0640\n",
      "Epoch 290/500\n",
      "303/303 - 0s - loss: 1.1242 - mae: 0.7684 - val_loss: 24.9232 - val_mae: 3.0421\n",
      "Epoch 291/500\n",
      "303/303 - 0s - loss: 1.0317 - mae: 0.7485 - val_loss: 25.2109 - val_mae: 3.1407\n",
      "Epoch 292/500\n",
      "303/303 - 0s - loss: 1.1515 - mae: 0.7997 - val_loss: 24.5831 - val_mae: 3.1209\n",
      "Epoch 293/500\n",
      "303/303 - 0s - loss: 1.2196 - mae: 0.8246 - val_loss: 31.4224 - val_mae: 3.1742\n",
      "Epoch 294/500\n",
      "303/303 - 0s - loss: 1.0295 - mae: 0.7367 - val_loss: 22.3712 - val_mae: 2.9651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/500\n",
      "303/303 - 0s - loss: 1.1585 - mae: 0.7952 - val_loss: 23.9489 - val_mae: 2.9036\n",
      "Epoch 296/500\n",
      "303/303 - 0s - loss: 1.0489 - mae: 0.7642 - val_loss: 24.9768 - val_mae: 3.0832\n",
      "Epoch 297/500\n",
      "303/303 - 0s - loss: 1.1071 - mae: 0.7593 - val_loss: 29.7290 - val_mae: 3.2006\n",
      "Epoch 298/500\n",
      "303/303 - 0s - loss: 1.1474 - mae: 0.7980 - val_loss: 26.1790 - val_mae: 2.9991\n",
      "Epoch 299/500\n",
      "303/303 - 0s - loss: 1.0742 - mae: 0.7531 - val_loss: 25.8666 - val_mae: 2.9969\n",
      "Epoch 300/500\n",
      "303/303 - 0s - loss: 1.0476 - mae: 0.7679 - val_loss: 23.4811 - val_mae: 2.9518\n",
      "Epoch 301/500\n",
      "303/303 - 0s - loss: 1.0457 - mae: 0.7713 - val_loss: 22.6339 - val_mae: 2.9998\n",
      "Epoch 302/500\n",
      "303/303 - 0s - loss: 1.0310 - mae: 0.7617 - val_loss: 23.3996 - val_mae: 2.9584\n",
      "Epoch 303/500\n",
      "303/303 - 0s - loss: 1.1095 - mae: 0.7867 - val_loss: 23.2146 - val_mae: 3.0694\n",
      "Epoch 304/500\n",
      "303/303 - 0s - loss: 0.9608 - mae: 0.7249 - val_loss: 19.3655 - val_mae: 2.7720\n",
      "Epoch 305/500\n",
      "303/303 - 0s - loss: 1.0376 - mae: 0.7605 - val_loss: 24.2636 - val_mae: 2.9264\n",
      "Epoch 306/500\n",
      "303/303 - 0s - loss: 1.0444 - mae: 0.7684 - val_loss: 23.5163 - val_mae: 2.8256\n",
      "Epoch 307/500\n",
      "303/303 - 0s - loss: 1.0337 - mae: 0.7536 - val_loss: 19.3316 - val_mae: 2.8415\n",
      "Epoch 308/500\n",
      "303/303 - 0s - loss: 1.0755 - mae: 0.7614 - val_loss: 30.0869 - val_mae: 3.2308\n",
      "Epoch 309/500\n",
      "303/303 - 0s - loss: 0.9687 - mae: 0.7499 - val_loss: 18.6457 - val_mae: 2.8527\n",
      "Epoch 310/500\n",
      "303/303 - 0s - loss: 1.0727 - mae: 0.7851 - val_loss: 23.6796 - val_mae: 2.9848\n",
      "Epoch 311/500\n",
      "303/303 - 0s - loss: 1.0797 - mae: 0.7776 - val_loss: 28.9691 - val_mae: 3.1488\n",
      "Epoch 312/500\n",
      "303/303 - 0s - loss: 1.1887 - mae: 0.7906 - val_loss: 25.9292 - val_mae: 3.3649\n",
      "Epoch 313/500\n",
      "303/303 - 0s - loss: 1.0411 - mae: 0.7650 - val_loss: 25.4541 - val_mae: 3.0075\n",
      "Epoch 314/500\n",
      "303/303 - 0s - loss: 0.9776 - mae: 0.7552 - val_loss: 26.3134 - val_mae: 3.0702\n",
      "Epoch 315/500\n",
      "303/303 - 0s - loss: 1.0203 - mae: 0.7338 - val_loss: 19.6512 - val_mae: 2.8684\n",
      "Epoch 316/500\n",
      "303/303 - 0s - loss: 0.9307 - mae: 0.7149 - val_loss: 23.7943 - val_mae: 2.9090\n",
      "Epoch 317/500\n",
      "303/303 - 0s - loss: 0.9552 - mae: 0.7108 - val_loss: 22.1565 - val_mae: 2.9108\n",
      "Epoch 318/500\n",
      "303/303 - 0s - loss: 1.2665 - mae: 0.7661 - val_loss: 24.0854 - val_mae: 3.1064\n",
      "Epoch 319/500\n",
      "303/303 - 0s - loss: 0.9686 - mae: 0.7501 - val_loss: 24.3112 - val_mae: 2.9110\n",
      "Epoch 320/500\n",
      "303/303 - 0s - loss: 1.0362 - mae: 0.7463 - val_loss: 28.0894 - val_mae: 3.1355\n",
      "Epoch 321/500\n",
      "303/303 - 0s - loss: 1.0141 - mae: 0.7429 - val_loss: 24.6887 - val_mae: 2.9474\n",
      "Epoch 322/500\n",
      "303/303 - 0s - loss: 0.9736 - mae: 0.7487 - val_loss: 21.3825 - val_mae: 2.9528\n",
      "Epoch 323/500\n",
      "303/303 - 0s - loss: 0.9748 - mae: 0.7321 - val_loss: 24.9523 - val_mae: 3.0503\n",
      "Epoch 324/500\n",
      "303/303 - 0s - loss: 0.9748 - mae: 0.7479 - val_loss: 18.1428 - val_mae: 2.7977\n",
      "Epoch 325/500\n",
      "303/303 - 0s - loss: 0.8740 - mae: 0.6982 - val_loss: 29.4500 - val_mae: 3.0538\n",
      "Epoch 326/500\n",
      "303/303 - 0s - loss: 0.9656 - mae: 0.7352 - val_loss: 32.1242 - val_mae: 3.3279\n",
      "Epoch 327/500\n",
      "303/303 - 0s - loss: 1.0871 - mae: 0.7904 - val_loss: 23.6160 - val_mae: 2.9139\n",
      "Epoch 328/500\n",
      "303/303 - 0s - loss: 1.0777 - mae: 0.7521 - val_loss: 26.5631 - val_mae: 3.0256\n",
      "Epoch 329/500\n",
      "303/303 - 0s - loss: 0.9182 - mae: 0.7185 - val_loss: 28.3336 - val_mae: 3.2319\n",
      "Epoch 330/500\n",
      "303/303 - 0s - loss: 1.0776 - mae: 0.7397 - val_loss: 28.6269 - val_mae: 3.1397\n",
      "Epoch 331/500\n",
      "303/303 - 0s - loss: 0.9096 - mae: 0.7307 - val_loss: 32.0440 - val_mae: 3.2450\n",
      "Epoch 332/500\n",
      "303/303 - 0s - loss: 0.9637 - mae: 0.7165 - val_loss: 31.7770 - val_mae: 3.0568\n",
      "Epoch 333/500\n",
      "303/303 - 0s - loss: 0.9571 - mae: 0.6969 - val_loss: 22.9025 - val_mae: 2.9232\n",
      "Epoch 334/500\n",
      "303/303 - 0s - loss: 0.9756 - mae: 0.7579 - val_loss: 24.7984 - val_mae: 3.0544\n",
      "Epoch 335/500\n",
      "303/303 - 0s - loss: 0.9564 - mae: 0.7184 - val_loss: 23.6870 - val_mae: 2.9106\n",
      "Epoch 336/500\n",
      "303/303 - 0s - loss: 0.9492 - mae: 0.7207 - val_loss: 17.3262 - val_mae: 2.6797\n",
      "Epoch 337/500\n",
      "303/303 - 0s - loss: 0.9676 - mae: 0.7309 - val_loss: 24.1468 - val_mae: 2.9473\n",
      "Epoch 338/500\n",
      "303/303 - 0s - loss: 0.9626 - mae: 0.7421 - val_loss: 24.0236 - val_mae: 2.9054\n",
      "Epoch 339/500\n",
      "303/303 - 0s - loss: 0.8840 - mae: 0.7080 - val_loss: 22.9374 - val_mae: 2.8970\n",
      "Epoch 340/500\n",
      "303/303 - 0s - loss: 0.8825 - mae: 0.7019 - val_loss: 20.6406 - val_mae: 2.8374\n",
      "Epoch 341/500\n",
      "303/303 - 0s - loss: 0.9047 - mae: 0.7215 - val_loss: 24.4826 - val_mae: 3.0264\n",
      "Epoch 342/500\n",
      "303/303 - 0s - loss: 1.0265 - mae: 0.7362 - val_loss: 27.6299 - val_mae: 3.2824\n",
      "Epoch 343/500\n",
      "303/303 - 0s - loss: 0.9632 - mae: 0.7470 - val_loss: 24.9350 - val_mae: 2.9553\n",
      "Epoch 344/500\n",
      "303/303 - 0s - loss: 0.9090 - mae: 0.7231 - val_loss: 21.0551 - val_mae: 2.8201\n",
      "Epoch 345/500\n",
      "303/303 - 0s - loss: 0.9468 - mae: 0.7269 - val_loss: 21.4422 - val_mae: 2.8035\n",
      "Epoch 346/500\n",
      "303/303 - 0s - loss: 0.9773 - mae: 0.6901 - val_loss: 25.2551 - val_mae: 3.0890\n",
      "Epoch 347/500\n",
      "303/303 - 0s - loss: 0.9057 - mae: 0.6981 - val_loss: 28.8868 - val_mae: 3.1018\n",
      "Epoch 348/500\n",
      "303/303 - 0s - loss: 0.8989 - mae: 0.7131 - val_loss: 30.5616 - val_mae: 3.1881\n",
      "Epoch 349/500\n",
      "303/303 - 0s - loss: 0.8793 - mae: 0.6761 - val_loss: 29.8409 - val_mae: 3.0839\n",
      "Epoch 350/500\n",
      "303/303 - 0s - loss: 0.9362 - mae: 0.6806 - val_loss: 31.5368 - val_mae: 3.1856\n",
      "Epoch 351/500\n",
      "303/303 - 0s - loss: 0.8900 - mae: 0.6971 - val_loss: 25.7104 - val_mae: 3.0307\n",
      "Epoch 352/500\n",
      "303/303 - 0s - loss: 0.9259 - mae: 0.7198 - val_loss: 31.6743 - val_mae: 3.1211\n",
      "Epoch 353/500\n",
      "303/303 - 0s - loss: 0.8822 - mae: 0.6985 - val_loss: 26.2268 - val_mae: 3.0010\n",
      "Epoch 354/500\n",
      "303/303 - 0s - loss: 0.8717 - mae: 0.7226 - val_loss: 23.6483 - val_mae: 2.8521\n",
      "Epoch 355/500\n",
      "303/303 - 0s - loss: 0.9055 - mae: 0.7159 - val_loss: 23.2342 - val_mae: 2.9355\n",
      "Epoch 356/500\n",
      "303/303 - 0s - loss: 0.8255 - mae: 0.6637 - val_loss: 19.6273 - val_mae: 2.8371\n",
      "Epoch 357/500\n",
      "303/303 - 0s - loss: 0.8953 - mae: 0.7058 - val_loss: 23.2004 - val_mae: 2.9104\n",
      "Epoch 358/500\n",
      "303/303 - 0s - loss: 0.8858 - mae: 0.6851 - val_loss: 24.1584 - val_mae: 2.9617\n",
      "Epoch 359/500\n",
      "303/303 - 0s - loss: 0.9210 - mae: 0.6929 - val_loss: 28.8291 - val_mae: 3.0644\n",
      "Epoch 360/500\n",
      "303/303 - 0s - loss: 0.9679 - mae: 0.7176 - val_loss: 21.1780 - val_mae: 2.8250\n",
      "Epoch 361/500\n",
      "303/303 - 0s - loss: 0.9206 - mae: 0.6673 - val_loss: 26.2764 - val_mae: 3.0782\n",
      "Epoch 362/500\n",
      "303/303 - 0s - loss: 0.9326 - mae: 0.7033 - val_loss: 19.8869 - val_mae: 2.8047\n",
      "Epoch 363/500\n",
      "303/303 - 0s - loss: 0.8787 - mae: 0.7026 - val_loss: 35.6054 - val_mae: 3.3218\n",
      "Epoch 364/500\n",
      "303/303 - 0s - loss: 0.9473 - mae: 0.7133 - val_loss: 21.5678 - val_mae: 2.7855\n",
      "Epoch 365/500\n",
      "303/303 - 0s - loss: 0.8939 - mae: 0.6896 - val_loss: 19.9214 - val_mae: 2.8489\n",
      "Epoch 366/500\n",
      "303/303 - 0s - loss: 0.8560 - mae: 0.6912 - val_loss: 22.4985 - val_mae: 2.8795\n",
      "Epoch 367/500\n",
      "303/303 - 0s - loss: 0.9013 - mae: 0.6893 - val_loss: 24.9131 - val_mae: 2.9728\n",
      "Epoch 368/500\n",
      "303/303 - 0s - loss: 0.9104 - mae: 0.6981 - val_loss: 25.0221 - val_mae: 3.1049\n",
      "Epoch 369/500\n",
      "303/303 - 0s - loss: 0.9319 - mae: 0.7206 - val_loss: 24.9317 - val_mae: 3.0406\n",
      "Epoch 370/500\n",
      "303/303 - 0s - loss: 0.8956 - mae: 0.7129 - val_loss: 24.3960 - val_mae: 2.9912\n",
      "Epoch 371/500\n",
      "303/303 - 0s - loss: 0.9793 - mae: 0.6708 - val_loss: 21.5431 - val_mae: 3.0569\n",
      "Epoch 372/500\n",
      "303/303 - 0s - loss: 0.8301 - mae: 0.7037 - val_loss: 24.7239 - val_mae: 3.0956\n",
      "Epoch 373/500\n",
      "303/303 - 0s - loss: 0.8147 - mae: 0.6908 - val_loss: 21.6227 - val_mae: 3.0540\n",
      "Epoch 374/500\n",
      "303/303 - 0s - loss: 1.0171 - mae: 0.7193 - val_loss: 25.0911 - val_mae: 2.9608\n",
      "Epoch 375/500\n",
      "303/303 - 0s - loss: 0.8855 - mae: 0.7107 - val_loss: 22.7786 - val_mae: 2.9463\n",
      "Epoch 376/500\n",
      "303/303 - 0s - loss: 0.8688 - mae: 0.6770 - val_loss: 22.9729 - val_mae: 2.9866\n",
      "Epoch 377/500\n",
      "303/303 - 0s - loss: 0.7351 - mae: 0.6508 - val_loss: 22.6851 - val_mae: 3.0495\n",
      "Epoch 378/500\n",
      "303/303 - 0s - loss: 0.8348 - mae: 0.6819 - val_loss: 23.1586 - val_mae: 2.9139\n",
      "Epoch 379/500\n",
      "303/303 - 0s - loss: 0.8485 - mae: 0.6833 - val_loss: 26.5850 - val_mae: 3.0666\n",
      "Epoch 380/500\n",
      "303/303 - 0s - loss: 0.8525 - mae: 0.6725 - val_loss: 23.3377 - val_mae: 3.0003\n",
      "Epoch 381/500\n",
      "303/303 - 0s - loss: 0.8538 - mae: 0.6681 - val_loss: 22.8081 - val_mae: 2.9767\n",
      "Epoch 382/500\n",
      "303/303 - 0s - loss: 0.6840 - mae: 0.6162 - val_loss: 25.0364 - val_mae: 2.9448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383/500\n",
      "303/303 - 0s - loss: 0.9927 - mae: 0.7049 - val_loss: 23.3832 - val_mae: 3.0515\n",
      "Epoch 384/500\n",
      "303/303 - 0s - loss: 0.8336 - mae: 0.6799 - val_loss: 23.8071 - val_mae: 2.9631\n",
      "Epoch 385/500\n",
      "303/303 - 0s - loss: 0.9637 - mae: 0.7141 - val_loss: 25.4856 - val_mae: 3.0382\n",
      "Epoch 386/500\n",
      "303/303 - 0s - loss: 0.8592 - mae: 0.7002 - val_loss: 26.2412 - val_mae: 3.0649\n",
      "Epoch 387/500\n",
      "303/303 - 0s - loss: 0.9164 - mae: 0.7320 - val_loss: 24.3831 - val_mae: 2.9522\n",
      "Epoch 388/500\n",
      "303/303 - 0s - loss: 0.7922 - mae: 0.6592 - val_loss: 19.9932 - val_mae: 2.8466\n",
      "Epoch 389/500\n",
      "303/303 - 0s - loss: 0.8233 - mae: 0.6630 - val_loss: 27.2246 - val_mae: 3.0696\n",
      "Epoch 390/500\n",
      "303/303 - 0s - loss: 0.8271 - mae: 0.6827 - val_loss: 27.1870 - val_mae: 3.0284\n",
      "Epoch 391/500\n",
      "303/303 - 0s - loss: 0.8074 - mae: 0.6515 - val_loss: 19.8078 - val_mae: 2.8999\n",
      "Epoch 392/500\n",
      "303/303 - 0s - loss: 0.8387 - mae: 0.7046 - val_loss: 27.4700 - val_mae: 3.1441\n",
      "Epoch 393/500\n",
      "303/303 - 0s - loss: 0.7380 - mae: 0.6034 - val_loss: 28.9894 - val_mae: 3.0306\n",
      "Epoch 394/500\n",
      "303/303 - 0s - loss: 0.9224 - mae: 0.6803 - val_loss: 21.8622 - val_mae: 2.8551\n",
      "Epoch 395/500\n",
      "303/303 - 0s - loss: 0.9346 - mae: 0.7027 - val_loss: 23.2129 - val_mae: 3.0575\n",
      "Epoch 396/500\n",
      "303/303 - 0s - loss: 0.8349 - mae: 0.6754 - val_loss: 27.1406 - val_mae: 3.0970\n",
      "Epoch 397/500\n",
      "303/303 - 0s - loss: 0.8699 - mae: 0.6742 - val_loss: 21.1467 - val_mae: 2.7754\n",
      "Epoch 398/500\n",
      "303/303 - 0s - loss: 0.8750 - mae: 0.6728 - val_loss: 26.4053 - val_mae: 3.0938\n",
      "Epoch 399/500\n",
      "303/303 - 0s - loss: 0.8446 - mae: 0.6816 - val_loss: 28.1164 - val_mae: 3.1888\n",
      "Epoch 400/500\n",
      "303/303 - 0s - loss: 0.7674 - mae: 0.6336 - val_loss: 20.2004 - val_mae: 2.8639\n",
      "Epoch 401/500\n",
      "303/303 - 0s - loss: 0.8277 - mae: 0.6872 - val_loss: 31.0524 - val_mae: 3.1569\n",
      "Epoch 402/500\n",
      "303/303 - 0s - loss: 0.8738 - mae: 0.6857 - val_loss: 17.4761 - val_mae: 2.7504\n",
      "Epoch 403/500\n",
      "303/303 - 0s - loss: 0.7906 - mae: 0.6557 - val_loss: 21.0882 - val_mae: 2.9038\n",
      "Epoch 404/500\n",
      "303/303 - 0s - loss: 0.7508 - mae: 0.6457 - val_loss: 23.6850 - val_mae: 3.0735\n",
      "Epoch 405/500\n",
      "303/303 - 0s - loss: 0.7492 - mae: 0.6378 - val_loss: 21.5140 - val_mae: 2.9218\n",
      "Epoch 406/500\n",
      "303/303 - 0s - loss: 0.8824 - mae: 0.7027 - val_loss: 21.0829 - val_mae: 2.8295\n",
      "Epoch 407/500\n",
      "303/303 - 0s - loss: 0.7944 - mae: 0.6612 - val_loss: 21.4918 - val_mae: 2.7895\n",
      "Epoch 408/500\n",
      "303/303 - 0s - loss: 0.7953 - mae: 0.6665 - val_loss: 21.2659 - val_mae: 2.7560\n",
      "Epoch 409/500\n",
      "303/303 - 0s - loss: 0.8633 - mae: 0.6723 - val_loss: 21.8859 - val_mae: 2.8068\n",
      "Epoch 410/500\n",
      "303/303 - 0s - loss: 0.8410 - mae: 0.7006 - val_loss: 21.2893 - val_mae: 2.9034\n",
      "Epoch 411/500\n",
      "303/303 - 0s - loss: 0.8595 - mae: 0.6843 - val_loss: 18.5647 - val_mae: 2.8250\n",
      "Epoch 412/500\n",
      "303/303 - 0s - loss: 0.7902 - mae: 0.6201 - val_loss: 23.3417 - val_mae: 2.9582\n",
      "Epoch 413/500\n",
      "303/303 - 0s - loss: 0.9436 - mae: 0.6663 - val_loss: 20.6220 - val_mae: 2.9593\n",
      "Epoch 414/500\n",
      "303/303 - 0s - loss: 0.8621 - mae: 0.6694 - val_loss: 24.2015 - val_mae: 3.0004\n",
      "Epoch 415/500\n",
      "303/303 - 0s - loss: 0.7979 - mae: 0.6683 - val_loss: 21.1561 - val_mae: 2.8627\n",
      "Epoch 416/500\n",
      "303/303 - 0s - loss: 0.9205 - mae: 0.6824 - val_loss: 22.2830 - val_mae: 2.8991\n",
      "Epoch 417/500\n",
      "303/303 - 0s - loss: 0.8122 - mae: 0.6614 - val_loss: 18.2320 - val_mae: 2.6814\n",
      "Epoch 418/500\n",
      "303/303 - 0s - loss: 0.7678 - mae: 0.6150 - val_loss: 20.2676 - val_mae: 2.7080\n",
      "Epoch 419/500\n",
      "303/303 - 0s - loss: 0.7506 - mae: 0.6450 - val_loss: 21.7632 - val_mae: 2.9287\n",
      "Epoch 420/500\n",
      "303/303 - 0s - loss: 0.8303 - mae: 0.6787 - val_loss: 17.4635 - val_mae: 2.6892\n",
      "Epoch 421/500\n",
      "303/303 - 0s - loss: 0.7796 - mae: 0.6608 - val_loss: 16.7015 - val_mae: 2.7438\n",
      "Epoch 422/500\n",
      "303/303 - 0s - loss: 0.7629 - mae: 0.6454 - val_loss: 18.6620 - val_mae: 2.8578\n",
      "Epoch 423/500\n",
      "303/303 - 0s - loss: 0.8181 - mae: 0.6798 - val_loss: 23.4974 - val_mae: 2.9040\n",
      "Epoch 424/500\n",
      "303/303 - 0s - loss: 0.7555 - mae: 0.6421 - val_loss: 25.8984 - val_mae: 3.0356\n",
      "Epoch 425/500\n",
      "303/303 - 0s - loss: 0.7889 - mae: 0.6480 - val_loss: 27.7095 - val_mae: 3.0834\n",
      "Epoch 426/500\n",
      "303/303 - 0s - loss: 0.8112 - mae: 0.6474 - val_loss: 22.7610 - val_mae: 2.8967\n",
      "Epoch 427/500\n",
      "303/303 - 0s - loss: 0.7669 - mae: 0.6377 - val_loss: 27.8544 - val_mae: 3.1619\n",
      "Epoch 428/500\n",
      "303/303 - 0s - loss: 0.7495 - mae: 0.6163 - val_loss: 21.5159 - val_mae: 3.0258\n",
      "Epoch 429/500\n",
      "303/303 - 0s - loss: 0.9225 - mae: 0.6790 - val_loss: 22.7341 - val_mae: 2.8719\n",
      "Epoch 430/500\n",
      "303/303 - 0s - loss: 0.8821 - mae: 0.6807 - val_loss: 19.8913 - val_mae: 2.7967\n",
      "Epoch 431/500\n",
      "303/303 - 0s - loss: 0.7312 - mae: 0.6311 - val_loss: 18.4218 - val_mae: 2.7675\n",
      "Epoch 432/500\n",
      "303/303 - 0s - loss: 0.6988 - mae: 0.6332 - val_loss: 19.6680 - val_mae: 2.8787\n",
      "Epoch 433/500\n",
      "303/303 - 0s - loss: 0.8012 - mae: 0.6518 - val_loss: 22.5366 - val_mae: 2.9709\n",
      "Epoch 434/500\n",
      "303/303 - 0s - loss: 0.8194 - mae: 0.6659 - val_loss: 27.6267 - val_mae: 3.1199\n",
      "Epoch 435/500\n",
      "303/303 - 0s - loss: 0.8108 - mae: 0.6407 - val_loss: 25.4206 - val_mae: 2.9042\n",
      "Epoch 436/500\n",
      "303/303 - 0s - loss: 0.8542 - mae: 0.6504 - val_loss: 24.1002 - val_mae: 2.9249\n",
      "Epoch 437/500\n",
      "303/303 - 0s - loss: 0.7351 - mae: 0.5980 - val_loss: 19.8006 - val_mae: 2.7332\n",
      "Epoch 438/500\n",
      "303/303 - 0s - loss: 0.7354 - mae: 0.6587 - val_loss: 18.9165 - val_mae: 2.6455\n",
      "Epoch 439/500\n",
      "303/303 - 0s - loss: 0.8025 - mae: 0.6475 - val_loss: 25.3300 - val_mae: 2.9617\n",
      "Epoch 440/500\n",
      "303/303 - 0s - loss: 0.7379 - mae: 0.6494 - val_loss: 17.5457 - val_mae: 2.7578\n",
      "Epoch 441/500\n",
      "303/303 - 0s - loss: 0.8688 - mae: 0.6740 - val_loss: 25.9510 - val_mae: 2.9871\n",
      "Epoch 442/500\n",
      "303/303 - 0s - loss: 0.7141 - mae: 0.6241 - val_loss: 24.8129 - val_mae: 3.0065\n",
      "Epoch 443/500\n",
      "303/303 - 0s - loss: 0.7216 - mae: 0.6068 - val_loss: 20.9281 - val_mae: 2.8419\n",
      "Epoch 444/500\n",
      "303/303 - 0s - loss: 0.7818 - mae: 0.6524 - val_loss: 25.9829 - val_mae: 3.1819\n",
      "Epoch 445/500\n",
      "303/303 - 0s - loss: 0.7095 - mae: 0.6069 - val_loss: 29.1362 - val_mae: 3.0873\n",
      "Epoch 446/500\n",
      "303/303 - 0s - loss: 0.7826 - mae: 0.6394 - val_loss: 27.5675 - val_mae: 3.0588\n",
      "Epoch 447/500\n",
      "303/303 - 0s - loss: 0.7711 - mae: 0.6673 - val_loss: 24.4765 - val_mae: 3.1665\n",
      "Epoch 448/500\n",
      "303/303 - 0s - loss: 0.7830 - mae: 0.6633 - val_loss: 28.2450 - val_mae: 3.1240\n",
      "Epoch 449/500\n",
      "303/303 - 0s - loss: 0.7182 - mae: 0.6342 - val_loss: 23.6451 - val_mae: 2.8800\n",
      "Epoch 450/500\n",
      "303/303 - 0s - loss: 0.8342 - mae: 0.6742 - val_loss: 22.7287 - val_mae: 2.8349\n",
      "Epoch 451/500\n",
      "303/303 - 0s - loss: 0.6698 - mae: 0.6195 - val_loss: 26.6717 - val_mae: 2.9406\n",
      "Epoch 452/500\n",
      "303/303 - 0s - loss: 0.7349 - mae: 0.6563 - val_loss: 23.7004 - val_mae: 3.0927\n",
      "Epoch 453/500\n",
      "303/303 - 0s - loss: 0.7303 - mae: 0.5949 - val_loss: 27.9170 - val_mae: 3.1312\n",
      "Epoch 454/500\n",
      "303/303 - 0s - loss: 0.7599 - mae: 0.6358 - val_loss: 20.6311 - val_mae: 2.7722\n",
      "Epoch 455/500\n",
      "303/303 - 0s - loss: 0.8065 - mae: 0.6799 - val_loss: 27.1311 - val_mae: 3.1315\n",
      "Epoch 456/500\n",
      "303/303 - 0s - loss: 0.7386 - mae: 0.6466 - val_loss: 23.8300 - val_mae: 2.8461\n",
      "Epoch 457/500\n",
      "303/303 - 0s - loss: 0.7929 - mae: 0.6680 - val_loss: 24.8850 - val_mae: 2.9953\n",
      "Epoch 458/500\n",
      "303/303 - 0s - loss: 0.7052 - mae: 0.6102 - val_loss: 26.4769 - val_mae: 3.0181\n",
      "Epoch 459/500\n",
      "303/303 - 0s - loss: 0.6935 - mae: 0.6032 - val_loss: 25.6586 - val_mae: 2.9827\n",
      "Epoch 460/500\n",
      "303/303 - 0s - loss: 0.7002 - mae: 0.6375 - val_loss: 24.2555 - val_mae: 3.0313\n",
      "Epoch 461/500\n",
      "303/303 - 0s - loss: 0.7208 - mae: 0.6354 - val_loss: 24.3780 - val_mae: 3.0074\n",
      "Epoch 462/500\n",
      "303/303 - 0s - loss: 0.7545 - mae: 0.6435 - val_loss: 24.7771 - val_mae: 3.0313\n",
      "Epoch 463/500\n",
      "303/303 - 0s - loss: 0.8078 - mae: 0.6267 - val_loss: 25.7619 - val_mae: 2.9298\n",
      "Epoch 464/500\n",
      "303/303 - 0s - loss: 0.7530 - mae: 0.6368 - val_loss: 22.8841 - val_mae: 2.9382\n",
      "Epoch 465/500\n",
      "303/303 - 0s - loss: 0.7312 - mae: 0.6367 - val_loss: 23.9521 - val_mae: 2.8348\n",
      "Epoch 466/500\n",
      "303/303 - 0s - loss: 0.6463 - mae: 0.6054 - val_loss: 24.8056 - val_mae: 2.9367\n",
      "Epoch 467/500\n",
      "303/303 - 0s - loss: 0.8020 - mae: 0.6349 - val_loss: 31.8726 - val_mae: 3.1521\n",
      "Epoch 468/500\n",
      "303/303 - 0s - loss: 0.7602 - mae: 0.6290 - val_loss: 28.6129 - val_mae: 3.1005\n",
      "Epoch 469/500\n",
      "303/303 - 0s - loss: 0.7557 - mae: 0.6077 - val_loss: 22.6055 - val_mae: 2.9978\n",
      "Epoch 470/500\n",
      "303/303 - 0s - loss: 0.7951 - mae: 0.6522 - val_loss: 26.2904 - val_mae: 3.0769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 471/500\n",
      "303/303 - 0s - loss: 0.5416 - mae: 0.5580 - val_loss: 23.5915 - val_mae: 2.8079\n",
      "Epoch 472/500\n",
      "303/303 - 0s - loss: 0.7282 - mae: 0.6460 - val_loss: 24.1420 - val_mae: 2.9943\n",
      "Epoch 473/500\n",
      "303/303 - 0s - loss: 0.7309 - mae: 0.6162 - val_loss: 24.9239 - val_mae: 3.0134\n",
      "Epoch 474/500\n",
      "303/303 - 0s - loss: 0.6955 - mae: 0.6107 - val_loss: 26.4266 - val_mae: 2.9986\n",
      "Epoch 475/500\n",
      "303/303 - 0s - loss: 0.6643 - mae: 0.5996 - val_loss: 31.9506 - val_mae: 3.1535\n",
      "Epoch 476/500\n",
      "303/303 - 0s - loss: 0.7576 - mae: 0.6332 - val_loss: 28.4860 - val_mae: 3.1098\n",
      "Epoch 477/500\n",
      "303/303 - 0s - loss: 0.7726 - mae: 0.6425 - val_loss: 25.9834 - val_mae: 3.0055\n",
      "Epoch 478/500\n",
      "303/303 - 0s - loss: 0.6537 - mae: 0.6190 - val_loss: 28.8339 - val_mae: 3.1285\n",
      "Epoch 479/500\n",
      "303/303 - 0s - loss: 0.7496 - mae: 0.6240 - val_loss: 30.0853 - val_mae: 3.2664\n",
      "Epoch 480/500\n",
      "303/303 - 0s - loss: 0.7001 - mae: 0.6283 - val_loss: 25.9294 - val_mae: 3.0012\n",
      "Epoch 481/500\n",
      "303/303 - 0s - loss: 0.7901 - mae: 0.6438 - val_loss: 28.6455 - val_mae: 3.0269\n",
      "Epoch 482/500\n",
      "303/303 - 0s - loss: 0.7122 - mae: 0.6078 - val_loss: 27.0766 - val_mae: 3.1438\n",
      "Epoch 483/500\n",
      "303/303 - 0s - loss: 0.7251 - mae: 0.6298 - val_loss: 24.7153 - val_mae: 2.8938\n",
      "Epoch 484/500\n",
      "303/303 - 0s - loss: 0.6992 - mae: 0.5776 - val_loss: 27.1893 - val_mae: 2.8587\n",
      "Epoch 485/500\n",
      "303/303 - 0s - loss: 0.6797 - mae: 0.5810 - val_loss: 19.0083 - val_mae: 2.7588\n",
      "Epoch 486/500\n",
      "303/303 - 0s - loss: 0.6980 - mae: 0.6182 - val_loss: 23.0997 - val_mae: 2.9071\n",
      "Epoch 487/500\n",
      "303/303 - 0s - loss: 0.7199 - mae: 0.6159 - val_loss: 18.8509 - val_mae: 2.7700\n",
      "Epoch 488/500\n",
      "303/303 - 0s - loss: 0.6874 - mae: 0.6263 - val_loss: 28.4482 - val_mae: 3.0155\n",
      "Epoch 489/500\n",
      "303/303 - 0s - loss: 0.7587 - mae: 0.6189 - val_loss: 20.3830 - val_mae: 2.6633\n",
      "Epoch 490/500\n",
      "303/303 - 0s - loss: 0.6830 - mae: 0.6243 - val_loss: 26.1473 - val_mae: 2.9082\n",
      "Epoch 491/500\n",
      "303/303 - 0s - loss: 0.6523 - mae: 0.6044 - val_loss: 26.4581 - val_mae: 2.9566\n",
      "Epoch 492/500\n",
      "303/303 - 0s - loss: 0.6203 - mae: 0.6027 - val_loss: 27.6965 - val_mae: 2.9260\n",
      "Epoch 493/500\n",
      "303/303 - 0s - loss: 0.6558 - mae: 0.6043 - val_loss: 19.5735 - val_mae: 2.9188\n",
      "Epoch 494/500\n",
      "303/303 - 0s - loss: 0.7914 - mae: 0.6240 - val_loss: 26.8099 - val_mae: 3.1021\n",
      "Epoch 495/500\n",
      "303/303 - 0s - loss: 0.7167 - mae: 0.6105 - val_loss: 30.2357 - val_mae: 3.0839\n",
      "Epoch 496/500\n",
      "303/303 - 0s - loss: 0.7650 - mae: 0.6130 - val_loss: 21.3939 - val_mae: 2.7759\n",
      "Epoch 497/500\n",
      "303/303 - 0s - loss: 0.7052 - mae: 0.6390 - val_loss: 22.1254 - val_mae: 2.8382\n",
      "Epoch 498/500\n",
      "303/303 - 0s - loss: 0.7131 - mae: 0.6344 - val_loss: 27.1604 - val_mae: 3.0400\n",
      "Epoch 499/500\n",
      "303/303 - 0s - loss: 0.6612 - mae: 0.5931 - val_loss: 28.1657 - val_mae: 2.9709\n",
      "Epoch 500/500\n",
      "303/303 - 0s - loss: 0.5945 - mae: 0.5722 - val_loss: 19.6722 - val_mae: 2.9003\n",
      "processing fold # 2\n",
      "Epoch 1/500\n",
      "303/303 - 1s - loss: 237.4089 - mae: 11.7670 - val_loss: 37.0215 - val_mae: 4.2197\n",
      "Epoch 2/500\n",
      "303/303 - 0s - loss: 32.4678 - mae: 3.8286 - val_loss: 24.0660 - val_mae: 3.2489\n",
      "Epoch 3/500\n",
      "303/303 - 0s - loss: 22.5130 - mae: 3.1608 - val_loss: 21.1364 - val_mae: 2.9989\n",
      "Epoch 4/500\n",
      "303/303 - 0s - loss: 18.1155 - mae: 2.8841 - val_loss: 20.6977 - val_mae: 2.9328\n",
      "Epoch 5/500\n",
      "303/303 - 0s - loss: 16.3442 - mae: 2.6830 - val_loss: 17.8390 - val_mae: 2.6964\n",
      "Epoch 6/500\n",
      "303/303 - 0s - loss: 14.0733 - mae: 2.5102 - val_loss: 17.2245 - val_mae: 2.6333\n",
      "Epoch 7/500\n",
      "303/303 - 0s - loss: 12.1311 - mae: 2.4851 - val_loss: 17.1094 - val_mae: 2.6868\n",
      "Epoch 8/500\n",
      "303/303 - 0s - loss: 11.8036 - mae: 2.3368 - val_loss: 17.2602 - val_mae: 2.6184\n",
      "Epoch 9/500\n",
      "303/303 - 0s - loss: 10.9240 - mae: 2.3008 - val_loss: 16.2428 - val_mae: 2.6551\n",
      "Epoch 10/500\n",
      "303/303 - 0s - loss: 10.8695 - mae: 2.2525 - val_loss: 17.1238 - val_mae: 2.9008\n",
      "Epoch 11/500\n",
      "303/303 - 0s - loss: 9.8703 - mae: 2.1538 - val_loss: 15.4419 - val_mae: 2.7162\n",
      "Epoch 12/500\n",
      "303/303 - 0s - loss: 9.5461 - mae: 2.1975 - val_loss: 18.0109 - val_mae: 2.9176\n",
      "Epoch 13/500\n",
      "303/303 - 0s - loss: 9.3637 - mae: 2.1091 - val_loss: 14.3837 - val_mae: 2.4138\n",
      "Epoch 14/500\n",
      "303/303 - 0s - loss: 8.9729 - mae: 2.1224 - val_loss: 14.2112 - val_mae: 2.5567\n",
      "Epoch 15/500\n",
      "303/303 - 0s - loss: 8.7009 - mae: 2.1112 - val_loss: 15.5548 - val_mae: 2.5856\n",
      "Epoch 16/500\n",
      "303/303 - 0s - loss: 8.6392 - mae: 2.0495 - val_loss: 14.6744 - val_mae: 2.4535\n",
      "Epoch 17/500\n",
      "303/303 - 0s - loss: 8.3389 - mae: 2.0545 - val_loss: 14.6159 - val_mae: 2.5137\n",
      "Epoch 18/500\n",
      "303/303 - 0s - loss: 7.9154 - mae: 1.9601 - val_loss: 16.4385 - val_mae: 2.8878\n",
      "Epoch 19/500\n",
      "303/303 - 0s - loss: 8.2289 - mae: 1.9539 - val_loss: 14.1613 - val_mae: 2.5373\n",
      "Epoch 20/500\n",
      "303/303 - 0s - loss: 7.6470 - mae: 1.8807 - val_loss: 14.3246 - val_mae: 2.5839\n",
      "Epoch 21/500\n",
      "303/303 - 0s - loss: 7.9290 - mae: 1.9685 - val_loss: 14.8333 - val_mae: 2.6729\n",
      "Epoch 22/500\n",
      "303/303 - 0s - loss: 7.2947 - mae: 1.9371 - val_loss: 15.5848 - val_mae: 2.8101\n",
      "Epoch 23/500\n",
      "303/303 - 0s - loss: 6.9878 - mae: 1.8524 - val_loss: 14.0629 - val_mae: 2.5289\n",
      "Epoch 24/500\n",
      "303/303 - 0s - loss: 7.0954 - mae: 1.8409 - val_loss: 14.6568 - val_mae: 2.5883\n",
      "Epoch 25/500\n",
      "303/303 - 0s - loss: 7.0536 - mae: 1.8164 - val_loss: 14.0966 - val_mae: 2.5356\n",
      "Epoch 26/500\n",
      "303/303 - 0s - loss: 7.2458 - mae: 1.8518 - val_loss: 14.8281 - val_mae: 2.6101\n",
      "Epoch 27/500\n",
      "303/303 - 0s - loss: 7.0468 - mae: 1.7475 - val_loss: 15.7998 - val_mae: 2.7651\n",
      "Epoch 28/500\n",
      "303/303 - 0s - loss: 6.8041 - mae: 1.8299 - val_loss: 13.7663 - val_mae: 2.4256\n",
      "Epoch 29/500\n",
      "303/303 - 0s - loss: 6.6974 - mae: 1.7768 - val_loss: 14.1022 - val_mae: 2.6026\n",
      "Epoch 30/500\n",
      "303/303 - 0s - loss: 6.6093 - mae: 1.7460 - val_loss: 14.3908 - val_mae: 2.6292\n",
      "Epoch 31/500\n",
      "303/303 - 0s - loss: 6.7146 - mae: 1.7911 - val_loss: 14.6741 - val_mae: 2.6037\n",
      "Epoch 32/500\n",
      "303/303 - 0s - loss: 6.1610 - mae: 1.7018 - val_loss: 14.0673 - val_mae: 2.3487\n",
      "Epoch 33/500\n",
      "303/303 - 0s - loss: 6.3788 - mae: 1.6913 - val_loss: 14.2406 - val_mae: 2.4812\n",
      "Epoch 34/500\n",
      "303/303 - 0s - loss: 6.1285 - mae: 1.7528 - val_loss: 14.7301 - val_mae: 2.6504\n",
      "Epoch 35/500\n",
      "303/303 - 0s - loss: 5.7716 - mae: 1.6965 - val_loss: 14.0841 - val_mae: 2.4735\n",
      "Epoch 36/500\n",
      "303/303 - 0s - loss: 6.2145 - mae: 1.7183 - val_loss: 16.2779 - val_mae: 2.9241\n",
      "Epoch 37/500\n",
      "303/303 - 0s - loss: 5.7724 - mae: 1.7113 - val_loss: 14.8333 - val_mae: 2.5267\n",
      "Epoch 38/500\n",
      "303/303 - 0s - loss: 5.8266 - mae: 1.6083 - val_loss: 14.1681 - val_mae: 2.4175\n",
      "Epoch 39/500\n",
      "303/303 - 0s - loss: 5.7825 - mae: 1.6808 - val_loss: 15.2482 - val_mae: 2.6171\n",
      "Epoch 40/500\n",
      "303/303 - 0s - loss: 5.9493 - mae: 1.6295 - val_loss: 14.1306 - val_mae: 2.4563\n",
      "Epoch 41/500\n",
      "303/303 - 0s - loss: 5.5596 - mae: 1.5920 - val_loss: 14.5573 - val_mae: 2.6604\n",
      "Epoch 42/500\n",
      "303/303 - 0s - loss: 5.4967 - mae: 1.6546 - val_loss: 15.6643 - val_mae: 2.6623\n",
      "Epoch 43/500\n",
      "303/303 - 0s - loss: 5.5706 - mae: 1.6226 - val_loss: 14.3057 - val_mae: 2.4897\n",
      "Epoch 44/500\n",
      "303/303 - 0s - loss: 5.6265 - mae: 1.6100 - val_loss: 14.2544 - val_mae: 2.4655\n",
      "Epoch 45/500\n",
      "303/303 - 0s - loss: 5.4577 - mae: 1.5818 - val_loss: 15.0359 - val_mae: 2.6243\n",
      "Epoch 46/500\n",
      "303/303 - 0s - loss: 4.9402 - mae: 1.5825 - val_loss: 14.9820 - val_mae: 2.6785\n",
      "Epoch 47/500\n",
      "303/303 - 0s - loss: 5.2935 - mae: 1.6268 - val_loss: 14.1179 - val_mae: 2.5355\n",
      "Epoch 48/500\n",
      "303/303 - 0s - loss: 5.4038 - mae: 1.6094 - val_loss: 13.9503 - val_mae: 2.4796\n",
      "Epoch 49/500\n",
      "303/303 - 0s - loss: 5.6556 - mae: 1.6027 - val_loss: 14.7008 - val_mae: 2.5969\n",
      "Epoch 50/500\n",
      "303/303 - 0s - loss: 4.9545 - mae: 1.5561 - val_loss: 14.9347 - val_mae: 2.6787\n",
      "Epoch 51/500\n",
      "303/303 - 0s - loss: 4.8367 - mae: 1.5363 - val_loss: 15.5591 - val_mae: 2.6401\n",
      "Epoch 52/500\n",
      "303/303 - 0s - loss: 5.3694 - mae: 1.5219 - val_loss: 14.3449 - val_mae: 2.4387\n",
      "Epoch 53/500\n",
      "303/303 - 0s - loss: 4.9087 - mae: 1.5169 - val_loss: 15.2129 - val_mae: 2.6618\n",
      "Epoch 54/500\n",
      "303/303 - 0s - loss: 5.0490 - mae: 1.5521 - val_loss: 14.6893 - val_mae: 2.6159\n",
      "Epoch 55/500\n",
      "303/303 - 0s - loss: 4.6641 - mae: 1.4773 - val_loss: 14.3330 - val_mae: 2.5617\n",
      "Epoch 56/500\n",
      "303/303 - 0s - loss: 5.0195 - mae: 1.5426 - val_loss: 15.1454 - val_mae: 2.6024\n",
      "Epoch 57/500\n",
      "303/303 - 0s - loss: 4.7459 - mae: 1.5070 - val_loss: 14.2711 - val_mae: 2.4841\n",
      "Epoch 58/500\n",
      "303/303 - 0s - loss: 4.5178 - mae: 1.4662 - val_loss: 14.8184 - val_mae: 2.4930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "303/303 - 0s - loss: 4.7766 - mae: 1.4566 - val_loss: 16.4310 - val_mae: 2.7589\n",
      "Epoch 60/500\n",
      "303/303 - 0s - loss: 4.5686 - mae: 1.5368 - val_loss: 16.5268 - val_mae: 2.6712\n",
      "Epoch 61/500\n",
      "303/303 - 0s - loss: 4.6130 - mae: 1.4907 - val_loss: 14.7477 - val_mae: 2.6002\n",
      "Epoch 62/500\n",
      "303/303 - 0s - loss: 4.3767 - mae: 1.4119 - val_loss: 16.0864 - val_mae: 2.6532\n",
      "Epoch 63/500\n",
      "303/303 - 0s - loss: 4.4052 - mae: 1.4455 - val_loss: 18.7024 - val_mae: 2.9291\n",
      "Epoch 64/500\n",
      "303/303 - 0s - loss: 4.3970 - mae: 1.4835 - val_loss: 16.2929 - val_mae: 2.6140\n",
      "Epoch 65/500\n",
      "303/303 - 0s - loss: 4.2117 - mae: 1.4375 - val_loss: 15.8411 - val_mae: 2.5199\n",
      "Epoch 66/500\n",
      "303/303 - 0s - loss: 4.5393 - mae: 1.4700 - val_loss: 15.6382 - val_mae: 2.5239\n",
      "Epoch 67/500\n",
      "303/303 - 0s - loss: 4.2578 - mae: 1.3910 - val_loss: 15.3528 - val_mae: 2.5629\n",
      "Epoch 68/500\n",
      "303/303 - 0s - loss: 4.2529 - mae: 1.4013 - val_loss: 15.6135 - val_mae: 2.5238\n",
      "Epoch 69/500\n",
      "303/303 - 0s - loss: 4.1503 - mae: 1.4092 - val_loss: 16.8858 - val_mae: 2.8473\n",
      "Epoch 70/500\n",
      "303/303 - 0s - loss: 4.2409 - mae: 1.4172 - val_loss: 15.4215 - val_mae: 2.5669\n",
      "Epoch 71/500\n",
      "303/303 - 0s - loss: 4.2471 - mae: 1.4585 - val_loss: 15.3056 - val_mae: 2.5687\n",
      "Epoch 72/500\n",
      "303/303 - 0s - loss: 3.9586 - mae: 1.3873 - val_loss: 16.8093 - val_mae: 2.8296\n",
      "Epoch 73/500\n",
      "303/303 - 0s - loss: 4.0001 - mae: 1.4051 - val_loss: 14.9372 - val_mae: 2.5586\n",
      "Epoch 74/500\n",
      "303/303 - 0s - loss: 3.9948 - mae: 1.3601 - val_loss: 16.3569 - val_mae: 2.7528\n",
      "Epoch 75/500\n",
      "303/303 - 0s - loss: 3.9242 - mae: 1.4371 - val_loss: 15.3868 - val_mae: 2.5170\n",
      "Epoch 76/500\n",
      "303/303 - 0s - loss: 3.9546 - mae: 1.4011 - val_loss: 16.0042 - val_mae: 2.7150\n",
      "Epoch 77/500\n",
      "303/303 - 0s - loss: 3.8206 - mae: 1.3771 - val_loss: 15.3926 - val_mae: 2.5713\n",
      "Epoch 78/500\n",
      "303/303 - 0s - loss: 3.9598 - mae: 1.3844 - val_loss: 18.0020 - val_mae: 2.7231\n",
      "Epoch 79/500\n",
      "303/303 - 0s - loss: 3.8432 - mae: 1.3765 - val_loss: 17.7870 - val_mae: 2.8059\n",
      "Epoch 80/500\n",
      "303/303 - 0s - loss: 3.5055 - mae: 1.3580 - val_loss: 17.1065 - val_mae: 2.7369\n",
      "Epoch 81/500\n",
      "303/303 - 0s - loss: 3.7584 - mae: 1.3838 - val_loss: 18.5483 - val_mae: 2.8217\n",
      "Epoch 82/500\n",
      "303/303 - 0s - loss: 3.6627 - mae: 1.3229 - val_loss: 15.9307 - val_mae: 2.6262\n",
      "Epoch 83/500\n",
      "303/303 - 0s - loss: 3.8022 - mae: 1.3802 - val_loss: 17.1894 - val_mae: 2.6421\n",
      "Epoch 84/500\n",
      "303/303 - 0s - loss: 3.6601 - mae: 1.3499 - val_loss: 14.8781 - val_mae: 2.5658\n",
      "Epoch 85/500\n",
      "303/303 - 0s - loss: 3.5720 - mae: 1.3476 - val_loss: 14.7858 - val_mae: 2.4969\n",
      "Epoch 86/500\n",
      "303/303 - 0s - loss: 3.5637 - mae: 1.3523 - val_loss: 15.7271 - val_mae: 2.6177\n",
      "Epoch 87/500\n",
      "303/303 - 0s - loss: 3.4041 - mae: 1.2893 - val_loss: 15.0491 - val_mae: 2.5790\n",
      "Epoch 88/500\n",
      "303/303 - 0s - loss: 3.4942 - mae: 1.3216 - val_loss: 17.2935 - val_mae: 2.7433\n",
      "Epoch 89/500\n",
      "303/303 - 0s - loss: 3.6277 - mae: 1.3315 - val_loss: 17.9922 - val_mae: 2.9501\n",
      "Epoch 90/500\n",
      "303/303 - 0s - loss: 3.4899 - mae: 1.3190 - val_loss: 15.1152 - val_mae: 2.5139\n",
      "Epoch 91/500\n",
      "303/303 - 0s - loss: 3.1700 - mae: 1.2394 - val_loss: 17.3596 - val_mae: 2.7563\n",
      "Epoch 92/500\n",
      "303/303 - 0s - loss: 3.3028 - mae: 1.2749 - val_loss: 16.0791 - val_mae: 2.5842\n",
      "Epoch 93/500\n",
      "303/303 - 0s - loss: 3.1697 - mae: 1.2611 - val_loss: 16.6452 - val_mae: 2.6735\n",
      "Epoch 94/500\n",
      "303/303 - 0s - loss: 3.4640 - mae: 1.3047 - val_loss: 15.4117 - val_mae: 2.5564\n",
      "Epoch 95/500\n",
      "303/303 - 0s - loss: 3.3350 - mae: 1.3160 - val_loss: 16.9944 - val_mae: 2.7175\n",
      "Epoch 96/500\n",
      "303/303 - 0s - loss: 3.1815 - mae: 1.2550 - val_loss: 16.4350 - val_mae: 2.6150\n",
      "Epoch 97/500\n",
      "303/303 - 0s - loss: 3.4243 - mae: 1.3082 - val_loss: 15.6125 - val_mae: 2.6235\n",
      "Epoch 98/500\n",
      "303/303 - 0s - loss: 3.2571 - mae: 1.2714 - val_loss: 16.2117 - val_mae: 2.6657\n",
      "Epoch 99/500\n",
      "303/303 - 0s - loss: 3.2764 - mae: 1.2883 - val_loss: 16.5289 - val_mae: 2.6482\n",
      "Epoch 100/500\n",
      "303/303 - 0s - loss: 2.8734 - mae: 1.2277 - val_loss: 17.4775 - val_mae: 2.6977\n",
      "Epoch 101/500\n",
      "303/303 - 0s - loss: 2.9721 - mae: 1.2029 - val_loss: 22.0301 - val_mae: 3.2480\n",
      "Epoch 102/500\n",
      "303/303 - 0s - loss: 2.8421 - mae: 1.1789 - val_loss: 19.8817 - val_mae: 2.9756\n",
      "Epoch 103/500\n",
      "303/303 - 0s - loss: 2.9664 - mae: 1.2446 - val_loss: 16.8515 - val_mae: 2.7908\n",
      "Epoch 104/500\n",
      "303/303 - 0s - loss: 3.1480 - mae: 1.2563 - val_loss: 15.8883 - val_mae: 2.5898\n",
      "Epoch 105/500\n",
      "303/303 - 0s - loss: 3.1999 - mae: 1.2927 - val_loss: 16.3439 - val_mae: 2.6543\n",
      "Epoch 106/500\n",
      "303/303 - 0s - loss: 2.9245 - mae: 1.2052 - val_loss: 16.7806 - val_mae: 2.7546\n",
      "Epoch 107/500\n",
      "303/303 - 0s - loss: 2.7960 - mae: 1.2034 - val_loss: 17.5329 - val_mae: 2.8286\n",
      "Epoch 108/500\n",
      "303/303 - 0s - loss: 2.7561 - mae: 1.1984 - val_loss: 16.6987 - val_mae: 2.6511\n",
      "Epoch 109/500\n",
      "303/303 - 0s - loss: 2.9420 - mae: 1.1966 - val_loss: 17.5568 - val_mae: 2.6996\n",
      "Epoch 110/500\n",
      "303/303 - 0s - loss: 3.2585 - mae: 1.2471 - val_loss: 15.8401 - val_mae: 2.5768\n",
      "Epoch 111/500\n",
      "303/303 - 0s - loss: 2.8893 - mae: 1.1943 - val_loss: 15.7505 - val_mae: 2.6690\n",
      "Epoch 112/500\n",
      "303/303 - 0s - loss: 3.1415 - mae: 1.2197 - val_loss: 16.1860 - val_mae: 2.6557\n",
      "Epoch 113/500\n",
      "303/303 - 0s - loss: 2.7705 - mae: 1.1851 - val_loss: 18.1847 - val_mae: 2.8766\n",
      "Epoch 114/500\n",
      "303/303 - 0s - loss: 2.9064 - mae: 1.2363 - val_loss: 18.5301 - val_mae: 2.9145\n",
      "Epoch 115/500\n",
      "303/303 - 0s - loss: 2.9373 - mae: 1.2098 - val_loss: 17.1662 - val_mae: 2.7096\n",
      "Epoch 116/500\n",
      "303/303 - 0s - loss: 2.9797 - mae: 1.1924 - val_loss: 16.2327 - val_mae: 2.6873\n",
      "Epoch 117/500\n",
      "303/303 - 0s - loss: 2.8527 - mae: 1.2108 - val_loss: 16.6819 - val_mae: 2.7544\n",
      "Epoch 118/500\n",
      "303/303 - 0s - loss: 2.6325 - mae: 1.1646 - val_loss: 16.2638 - val_mae: 2.6152\n",
      "Epoch 119/500\n",
      "303/303 - 0s - loss: 2.7682 - mae: 1.1861 - val_loss: 17.5268 - val_mae: 2.8201\n",
      "Epoch 120/500\n",
      "303/303 - 0s - loss: 2.3971 - mae: 1.1238 - val_loss: 17.7634 - val_mae: 2.6857\n",
      "Epoch 121/500\n",
      "303/303 - 0s - loss: 2.7417 - mae: 1.1799 - val_loss: 16.2993 - val_mae: 2.6110\n",
      "Epoch 122/500\n",
      "303/303 - 0s - loss: 2.8761 - mae: 1.1836 - val_loss: 16.1705 - val_mae: 2.6492\n",
      "Epoch 123/500\n",
      "303/303 - 0s - loss: 2.6799 - mae: 1.1674 - val_loss: 17.4067 - val_mae: 2.7542\n",
      "Epoch 124/500\n",
      "303/303 - 0s - loss: 2.5215 - mae: 1.1570 - val_loss: 17.4851 - val_mae: 2.8092\n",
      "Epoch 125/500\n",
      "303/303 - 0s - loss: 2.6905 - mae: 1.1766 - val_loss: 17.9446 - val_mae: 2.8110\n",
      "Epoch 126/500\n",
      "303/303 - 0s - loss: 2.5123 - mae: 1.1574 - val_loss: 18.4186 - val_mae: 2.9142\n",
      "Epoch 127/500\n",
      "303/303 - 0s - loss: 2.3868 - mae: 1.1219 - val_loss: 17.6730 - val_mae: 2.8171\n",
      "Epoch 128/500\n",
      "303/303 - 0s - loss: 2.7060 - mae: 1.2025 - val_loss: 16.0342 - val_mae: 2.5982\n",
      "Epoch 129/500\n",
      "303/303 - 0s - loss: 2.5147 - mae: 1.1453 - val_loss: 16.2347 - val_mae: 2.6494\n",
      "Epoch 130/500\n",
      "303/303 - 0s - loss: 2.6234 - mae: 1.1641 - val_loss: 17.3649 - val_mae: 2.7028\n",
      "Epoch 131/500\n",
      "303/303 - 0s - loss: 2.4366 - mae: 1.1223 - val_loss: 16.9040 - val_mae: 2.6641\n",
      "Epoch 132/500\n",
      "303/303 - 0s - loss: 2.3405 - mae: 1.1227 - val_loss: 16.5106 - val_mae: 2.6919\n",
      "Epoch 133/500\n",
      "303/303 - 0s - loss: 2.3821 - mae: 1.1062 - val_loss: 18.0349 - val_mae: 2.7507\n",
      "Epoch 134/500\n",
      "303/303 - 0s - loss: 2.5716 - mae: 1.1373 - val_loss: 16.4136 - val_mae: 2.7032\n",
      "Epoch 135/500\n",
      "303/303 - 0s - loss: 2.4036 - mae: 1.1245 - val_loss: 17.5782 - val_mae: 2.7805\n",
      "Epoch 136/500\n",
      "303/303 - 0s - loss: 2.4043 - mae: 1.1156 - val_loss: 16.1448 - val_mae: 2.6813\n",
      "Epoch 137/500\n",
      "303/303 - 0s - loss: 2.2196 - mae: 1.0707 - val_loss: 16.6865 - val_mae: 2.7552\n",
      "Epoch 138/500\n",
      "303/303 - 0s - loss: 2.6887 - mae: 1.1472 - val_loss: 18.7365 - val_mae: 2.7560\n",
      "Epoch 139/500\n",
      "303/303 - 0s - loss: 2.4765 - mae: 1.0867 - val_loss: 16.9629 - val_mae: 2.7778\n",
      "Epoch 140/500\n",
      "303/303 - 0s - loss: 2.4063 - mae: 1.1026 - val_loss: 16.2940 - val_mae: 2.6696\n",
      "Epoch 141/500\n",
      "303/303 - 0s - loss: 2.3234 - mae: 1.1190 - val_loss: 17.9556 - val_mae: 2.8400\n",
      "Epoch 142/500\n",
      "303/303 - 0s - loss: 2.1843 - mae: 1.0614 - val_loss: 20.8275 - val_mae: 3.1527\n",
      "Epoch 143/500\n",
      "303/303 - 0s - loss: 2.1120 - mae: 1.0461 - val_loss: 16.3340 - val_mae: 2.7088\n",
      "Epoch 144/500\n",
      "303/303 - 0s - loss: 2.4507 - mae: 1.1042 - val_loss: 17.3660 - val_mae: 2.7419\n",
      "Epoch 145/500\n",
      "303/303 - 0s - loss: 2.0526 - mae: 1.0758 - val_loss: 18.1357 - val_mae: 2.9583\n",
      "Epoch 146/500\n",
      "303/303 - 0s - loss: 2.2376 - mae: 1.0958 - val_loss: 16.7732 - val_mae: 2.6899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/500\n",
      "303/303 - 0s - loss: 2.2000 - mae: 1.0789 - val_loss: 18.6399 - val_mae: 2.8696\n",
      "Epoch 148/500\n",
      "303/303 - 0s - loss: 2.3295 - mae: 1.0615 - val_loss: 18.4616 - val_mae: 2.8288\n",
      "Epoch 149/500\n",
      "303/303 - 0s - loss: 2.1862 - mae: 1.0261 - val_loss: 17.1609 - val_mae: 2.7557\n",
      "Epoch 150/500\n",
      "303/303 - 0s - loss: 2.4464 - mae: 1.0697 - val_loss: 18.2999 - val_mae: 2.7604\n",
      "Epoch 151/500\n",
      "303/303 - 0s - loss: 2.1564 - mae: 1.0787 - val_loss: 17.8927 - val_mae: 2.7792\n",
      "Epoch 152/500\n",
      "303/303 - 0s - loss: 2.2251 - mae: 1.0683 - val_loss: 19.6854 - val_mae: 2.9038\n",
      "Epoch 153/500\n",
      "303/303 - 0s - loss: 2.0117 - mae: 1.0821 - val_loss: 16.3009 - val_mae: 2.6396\n",
      "Epoch 154/500\n",
      "303/303 - 0s - loss: 2.2044 - mae: 1.0678 - val_loss: 16.6137 - val_mae: 2.6481\n",
      "Epoch 155/500\n",
      "303/303 - 0s - loss: 2.1621 - mae: 1.0464 - val_loss: 16.3249 - val_mae: 2.6131\n",
      "Epoch 156/500\n",
      "303/303 - 0s - loss: 1.8919 - mae: 1.0123 - val_loss: 19.5542 - val_mae: 2.9550\n",
      "Epoch 157/500\n",
      "303/303 - 0s - loss: 2.1197 - mae: 1.0343 - val_loss: 17.1918 - val_mae: 2.7266\n",
      "Epoch 158/500\n",
      "303/303 - 0s - loss: 2.0356 - mae: 1.0417 - val_loss: 16.8705 - val_mae: 2.6069\n",
      "Epoch 159/500\n",
      "303/303 - 0s - loss: 1.9595 - mae: 1.0189 - val_loss: 17.4672 - val_mae: 2.8118\n",
      "Epoch 160/500\n",
      "303/303 - 0s - loss: 2.0195 - mae: 1.0527 - val_loss: 17.3352 - val_mae: 2.7459\n",
      "Epoch 161/500\n",
      "303/303 - 0s - loss: 1.8880 - mae: 0.9456 - val_loss: 19.4567 - val_mae: 2.9480\n",
      "Epoch 162/500\n",
      "303/303 - 0s - loss: 1.8495 - mae: 1.0084 - val_loss: 16.1754 - val_mae: 2.5197\n",
      "Epoch 163/500\n",
      "303/303 - 0s - loss: 2.0435 - mae: 1.0573 - val_loss: 17.1285 - val_mae: 2.6751\n",
      "Epoch 164/500\n",
      "303/303 - 0s - loss: 1.9979 - mae: 1.0078 - val_loss: 16.2860 - val_mae: 2.6364\n",
      "Epoch 165/500\n",
      "303/303 - 0s - loss: 1.8044 - mae: 0.9701 - val_loss: 16.1518 - val_mae: 2.6360\n",
      "Epoch 166/500\n",
      "303/303 - 0s - loss: 1.8208 - mae: 0.9842 - val_loss: 15.3094 - val_mae: 2.5922\n",
      "Epoch 167/500\n",
      "303/303 - 0s - loss: 1.7633 - mae: 0.9769 - val_loss: 16.4084 - val_mae: 2.7244\n",
      "Epoch 168/500\n",
      "303/303 - 0s - loss: 1.8585 - mae: 1.0003 - val_loss: 18.1610 - val_mae: 2.7411\n",
      "Epoch 169/500\n",
      "303/303 - 0s - loss: 1.6827 - mae: 0.9269 - val_loss: 18.6986 - val_mae: 2.9440\n",
      "Epoch 170/500\n",
      "303/303 - 0s - loss: 1.7411 - mae: 0.9509 - val_loss: 20.7891 - val_mae: 3.1426\n",
      "Epoch 171/500\n",
      "303/303 - 0s - loss: 1.9218 - mae: 1.0049 - val_loss: 16.8412 - val_mae: 2.6781\n",
      "Epoch 172/500\n",
      "303/303 - 0s - loss: 1.7242 - mae: 0.9525 - val_loss: 16.9736 - val_mae: 2.6688\n",
      "Epoch 173/500\n",
      "303/303 - 0s - loss: 1.9408 - mae: 0.9650 - val_loss: 17.7545 - val_mae: 2.7500\n",
      "Epoch 174/500\n",
      "303/303 - 0s - loss: 1.8517 - mae: 0.9840 - val_loss: 15.7704 - val_mae: 2.6394\n",
      "Epoch 175/500\n",
      "303/303 - 0s - loss: 1.7140 - mae: 0.9947 - val_loss: 17.4934 - val_mae: 2.7302\n",
      "Epoch 176/500\n",
      "303/303 - 0s - loss: 1.6741 - mae: 0.9682 - val_loss: 16.2987 - val_mae: 2.7173\n",
      "Epoch 177/500\n",
      "303/303 - 0s - loss: 1.9273 - mae: 0.9963 - val_loss: 17.3541 - val_mae: 2.6414\n",
      "Epoch 178/500\n",
      "303/303 - 0s - loss: 1.6723 - mae: 0.8787 - val_loss: 17.3049 - val_mae: 2.6840\n",
      "Epoch 179/500\n",
      "303/303 - 0s - loss: 1.7926 - mae: 0.9642 - val_loss: 16.7851 - val_mae: 2.6418\n",
      "Epoch 180/500\n",
      "303/303 - 0s - loss: 1.8298 - mae: 0.9783 - val_loss: 15.5926 - val_mae: 2.5662\n",
      "Epoch 181/500\n",
      "303/303 - 0s - loss: 1.8165 - mae: 1.0003 - val_loss: 16.5128 - val_mae: 2.7173\n",
      "Epoch 182/500\n",
      "303/303 - 0s - loss: 1.7575 - mae: 0.9576 - val_loss: 17.5911 - val_mae: 2.8595\n",
      "Epoch 183/500\n",
      "303/303 - 0s - loss: 1.7762 - mae: 0.9688 - val_loss: 16.1745 - val_mae: 2.5831\n",
      "Epoch 184/500\n",
      "303/303 - 0s - loss: 1.7907 - mae: 0.9618 - val_loss: 16.6194 - val_mae: 2.7014\n",
      "Epoch 185/500\n",
      "303/303 - 0s - loss: 1.6727 - mae: 0.9438 - val_loss: 15.8811 - val_mae: 2.6100\n",
      "Epoch 186/500\n",
      "303/303 - 0s - loss: 1.6627 - mae: 0.9476 - val_loss: 17.0972 - val_mae: 2.6900\n",
      "Epoch 187/500\n",
      "303/303 - 0s - loss: 1.7455 - mae: 0.9672 - val_loss: 18.9731 - val_mae: 2.8858\n",
      "Epoch 188/500\n",
      "303/303 - 0s - loss: 1.9846 - mae: 1.0044 - val_loss: 16.7473 - val_mae: 2.7017\n",
      "Epoch 189/500\n",
      "303/303 - 0s - loss: 1.6666 - mae: 0.9241 - val_loss: 18.7361 - val_mae: 2.8423\n",
      "Epoch 190/500\n",
      "303/303 - 0s - loss: 1.6655 - mae: 0.9022 - val_loss: 16.8616 - val_mae: 2.6962\n",
      "Epoch 191/500\n",
      "303/303 - 0s - loss: 1.6532 - mae: 0.9202 - val_loss: 17.4400 - val_mae: 2.6999\n",
      "Epoch 192/500\n",
      "303/303 - 0s - loss: 1.6939 - mae: 0.9246 - val_loss: 17.1655 - val_mae: 2.7344\n",
      "Epoch 193/500\n",
      "303/303 - 0s - loss: 1.5128 - mae: 0.9362 - val_loss: 16.6636 - val_mae: 2.6541\n",
      "Epoch 194/500\n",
      "303/303 - 0s - loss: 1.5933 - mae: 0.9225 - val_loss: 16.3672 - val_mae: 2.7040\n",
      "Epoch 195/500\n",
      "303/303 - 0s - loss: 1.6305 - mae: 0.9553 - val_loss: 14.7486 - val_mae: 2.4997\n",
      "Epoch 196/500\n",
      "303/303 - 0s - loss: 1.5992 - mae: 0.9207 - val_loss: 14.4354 - val_mae: 2.5907\n",
      "Epoch 197/500\n",
      "303/303 - 0s - loss: 1.6327 - mae: 0.9276 - val_loss: 17.3449 - val_mae: 2.6967\n",
      "Epoch 198/500\n",
      "303/303 - 0s - loss: 1.7424 - mae: 0.9740 - val_loss: 15.4440 - val_mae: 2.6359\n",
      "Epoch 199/500\n",
      "303/303 - 0s - loss: 1.4910 - mae: 0.9094 - val_loss: 17.8090 - val_mae: 2.7822\n",
      "Epoch 200/500\n",
      "303/303 - 0s - loss: 1.6773 - mae: 0.9245 - val_loss: 17.2633 - val_mae: 2.6906\n",
      "Epoch 201/500\n",
      "303/303 - 0s - loss: 1.5609 - mae: 0.9190 - val_loss: 19.3648 - val_mae: 2.8514\n",
      "Epoch 202/500\n",
      "303/303 - 0s - loss: 1.6844 - mae: 0.9436 - val_loss: 15.8309 - val_mae: 2.6831\n",
      "Epoch 203/500\n",
      "303/303 - 0s - loss: 1.5325 - mae: 0.8903 - val_loss: 17.6457 - val_mae: 2.7955\n",
      "Epoch 204/500\n",
      "303/303 - 0s - loss: 1.5545 - mae: 0.9055 - val_loss: 16.6173 - val_mae: 2.7432\n",
      "Epoch 205/500\n",
      "303/303 - 0s - loss: 1.6570 - mae: 0.9308 - val_loss: 14.9415 - val_mae: 2.5268\n",
      "Epoch 206/500\n",
      "303/303 - 0s - loss: 1.4305 - mae: 0.9085 - val_loss: 16.4672 - val_mae: 2.5973\n",
      "Epoch 207/500\n",
      "303/303 - 0s - loss: 1.4924 - mae: 0.9051 - val_loss: 17.1772 - val_mae: 2.7368\n",
      "Epoch 208/500\n",
      "303/303 - 0s - loss: 1.6834 - mae: 0.9551 - val_loss: 17.0825 - val_mae: 2.8416\n",
      "Epoch 209/500\n",
      "303/303 - 0s - loss: 1.4596 - mae: 0.8636 - val_loss: 18.0249 - val_mae: 2.6742\n",
      "Epoch 210/500\n",
      "303/303 - 0s - loss: 1.4116 - mae: 0.8652 - val_loss: 15.0159 - val_mae: 2.5854\n",
      "Epoch 211/500\n",
      "303/303 - 0s - loss: 1.6539 - mae: 0.8989 - val_loss: 16.7958 - val_mae: 2.7145\n",
      "Epoch 212/500\n",
      "303/303 - 0s - loss: 1.4787 - mae: 0.8760 - val_loss: 17.4346 - val_mae: 2.8502\n",
      "Epoch 213/500\n",
      "303/303 - 0s - loss: 1.4175 - mae: 0.8649 - val_loss: 15.8049 - val_mae: 2.6008\n",
      "Epoch 214/500\n",
      "303/303 - 0s - loss: 1.5355 - mae: 0.9003 - val_loss: 16.4419 - val_mae: 2.7334\n",
      "Epoch 215/500\n",
      "303/303 - 0s - loss: 1.3478 - mae: 0.8468 - val_loss: 17.0240 - val_mae: 2.8277\n",
      "Epoch 216/500\n",
      "303/303 - 0s - loss: 1.5042 - mae: 0.8701 - val_loss: 15.3176 - val_mae: 2.5810\n",
      "Epoch 217/500\n",
      "303/303 - 0s - loss: 1.2610 - mae: 0.8236 - val_loss: 15.6948 - val_mae: 2.5308\n",
      "Epoch 218/500\n",
      "303/303 - 0s - loss: 1.5394 - mae: 0.9015 - val_loss: 16.4406 - val_mae: 2.6405\n",
      "Epoch 219/500\n",
      "303/303 - 0s - loss: 1.5690 - mae: 0.9180 - val_loss: 16.2262 - val_mae: 2.6734\n",
      "Epoch 220/500\n",
      "303/303 - 0s - loss: 1.3659 - mae: 0.8319 - val_loss: 15.6066 - val_mae: 2.6201\n",
      "Epoch 221/500\n",
      "303/303 - 0s - loss: 1.2193 - mae: 0.8127 - val_loss: 17.5863 - val_mae: 2.7312\n",
      "Epoch 222/500\n",
      "303/303 - 0s - loss: 1.4026 - mae: 0.8891 - val_loss: 15.5637 - val_mae: 2.5993\n",
      "Epoch 223/500\n",
      "303/303 - 0s - loss: 1.3894 - mae: 0.8787 - val_loss: 15.1936 - val_mae: 2.5602\n",
      "Epoch 224/500\n",
      "303/303 - 0s - loss: 1.4310 - mae: 0.8543 - val_loss: 17.3022 - val_mae: 2.6982\n",
      "Epoch 225/500\n",
      "303/303 - 0s - loss: 1.4305 - mae: 0.8497 - val_loss: 14.6783 - val_mae: 2.5188\n",
      "Epoch 226/500\n",
      "303/303 - 0s - loss: 1.4116 - mae: 0.8570 - val_loss: 16.1792 - val_mae: 2.6277\n",
      "Epoch 227/500\n",
      "303/303 - 0s - loss: 1.3659 - mae: 0.8357 - val_loss: 16.1672 - val_mae: 2.6283\n",
      "Epoch 228/500\n",
      "303/303 - 0s - loss: 1.4582 - mae: 0.8788 - val_loss: 15.5664 - val_mae: 2.6856\n",
      "Epoch 229/500\n",
      "303/303 - 0s - loss: 1.3597 - mae: 0.8415 - val_loss: 15.5025 - val_mae: 2.6223\n",
      "Epoch 230/500\n",
      "303/303 - 0s - loss: 1.2902 - mae: 0.8398 - val_loss: 15.8127 - val_mae: 2.5753\n",
      "Epoch 231/500\n",
      "303/303 - 0s - loss: 1.3763 - mae: 0.8895 - val_loss: 15.3484 - val_mae: 2.5699\n",
      "Epoch 232/500\n",
      "303/303 - 0s - loss: 1.3283 - mae: 0.8358 - val_loss: 16.2345 - val_mae: 2.6330\n",
      "Epoch 233/500\n",
      "303/303 - 0s - loss: 1.2570 - mae: 0.8408 - val_loss: 16.2829 - val_mae: 2.7383\n",
      "Epoch 234/500\n",
      "303/303 - 0s - loss: 1.2474 - mae: 0.8114 - val_loss: 15.1998 - val_mae: 2.6398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/500\n",
      "303/303 - 0s - loss: 1.3621 - mae: 0.8264 - val_loss: 16.8190 - val_mae: 2.6761\n",
      "Epoch 236/500\n",
      "303/303 - 0s - loss: 1.3510 - mae: 0.8184 - val_loss: 16.3847 - val_mae: 2.8708\n",
      "Epoch 237/500\n",
      "303/303 - 0s - loss: 1.3625 - mae: 0.8176 - val_loss: 15.0998 - val_mae: 2.5055\n",
      "Epoch 238/500\n",
      "303/303 - 0s - loss: 1.3692 - mae: 0.8429 - val_loss: 15.1635 - val_mae: 2.6355\n",
      "Epoch 239/500\n",
      "303/303 - 0s - loss: 1.4963 - mae: 0.8722 - val_loss: 14.5091 - val_mae: 2.6032\n",
      "Epoch 240/500\n",
      "303/303 - 0s - loss: 1.2368 - mae: 0.8189 - val_loss: 14.9360 - val_mae: 2.6452\n",
      "Epoch 241/500\n",
      "303/303 - 0s - loss: 1.3148 - mae: 0.8399 - val_loss: 17.0880 - val_mae: 2.7812\n",
      "Epoch 242/500\n",
      "303/303 - 0s - loss: 1.1660 - mae: 0.8095 - val_loss: 15.2862 - val_mae: 2.5799\n",
      "Epoch 243/500\n",
      "303/303 - 0s - loss: 1.4141 - mae: 0.8591 - val_loss: 15.4894 - val_mae: 2.6649\n",
      "Epoch 244/500\n",
      "303/303 - 0s - loss: 1.3087 - mae: 0.8146 - val_loss: 15.8221 - val_mae: 2.7276\n",
      "Epoch 245/500\n",
      "303/303 - 0s - loss: 1.2115 - mae: 0.7811 - val_loss: 15.2493 - val_mae: 2.6447\n",
      "Epoch 246/500\n",
      "303/303 - 0s - loss: 1.2075 - mae: 0.7710 - val_loss: 15.3670 - val_mae: 2.6408\n",
      "Epoch 247/500\n",
      "303/303 - 0s - loss: 1.3375 - mae: 0.8039 - val_loss: 15.0017 - val_mae: 2.5503\n",
      "Epoch 248/500\n",
      "303/303 - 0s - loss: 1.2467 - mae: 0.7959 - val_loss: 13.8907 - val_mae: 2.5072\n",
      "Epoch 249/500\n",
      "303/303 - 0s - loss: 1.1712 - mae: 0.8010 - val_loss: 14.1947 - val_mae: 2.5424\n",
      "Epoch 250/500\n",
      "303/303 - 0s - loss: 1.3056 - mae: 0.8222 - val_loss: 13.7877 - val_mae: 2.4464\n",
      "Epoch 251/500\n",
      "303/303 - 0s - loss: 1.2193 - mae: 0.8379 - val_loss: 15.2788 - val_mae: 2.6240\n",
      "Epoch 252/500\n",
      "303/303 - 0s - loss: 1.3032 - mae: 0.8605 - val_loss: 15.4277 - val_mae: 2.6188\n",
      "Epoch 253/500\n",
      "303/303 - 0s - loss: 1.3866 - mae: 0.8616 - val_loss: 15.1847 - val_mae: 2.6076\n",
      "Epoch 254/500\n",
      "303/303 - 0s - loss: 1.0678 - mae: 0.7571 - val_loss: 15.7012 - val_mae: 2.6546\n",
      "Epoch 255/500\n",
      "303/303 - 0s - loss: 1.1907 - mae: 0.8007 - val_loss: 15.5326 - val_mae: 2.6709\n",
      "Epoch 256/500\n",
      "303/303 - 0s - loss: 1.1034 - mae: 0.7842 - val_loss: 15.1147 - val_mae: 2.5506\n",
      "Epoch 257/500\n",
      "303/303 - 0s - loss: 1.3229 - mae: 0.8544 - val_loss: 14.5379 - val_mae: 2.5117\n",
      "Epoch 258/500\n",
      "303/303 - 0s - loss: 1.1433 - mae: 0.8037 - val_loss: 14.4412 - val_mae: 2.5386\n",
      "Epoch 259/500\n",
      "303/303 - 0s - loss: 1.1839 - mae: 0.8219 - val_loss: 15.0318 - val_mae: 2.6287\n",
      "Epoch 260/500\n",
      "303/303 - 0s - loss: 1.1903 - mae: 0.8058 - val_loss: 15.1661 - val_mae: 2.6174\n",
      "Epoch 261/500\n",
      "303/303 - 0s - loss: 1.0795 - mae: 0.7550 - val_loss: 15.0331 - val_mae: 2.5790\n",
      "Epoch 262/500\n",
      "303/303 - 0s - loss: 1.3014 - mae: 0.8417 - val_loss: 15.6752 - val_mae: 2.5514\n",
      "Epoch 263/500\n",
      "303/303 - 0s - loss: 1.2358 - mae: 0.8197 - val_loss: 14.8412 - val_mae: 2.5241\n",
      "Epoch 264/500\n",
      "303/303 - 0s - loss: 1.2477 - mae: 0.8101 - val_loss: 15.1135 - val_mae: 2.6329\n",
      "Epoch 265/500\n",
      "303/303 - 0s - loss: 1.1374 - mae: 0.7979 - val_loss: 15.2349 - val_mae: 2.5905\n",
      "Epoch 266/500\n",
      "303/303 - 0s - loss: 1.0898 - mae: 0.7889 - val_loss: 15.5834 - val_mae: 2.5684\n",
      "Epoch 267/500\n",
      "303/303 - 0s - loss: 1.1074 - mae: 0.7611 - val_loss: 15.4016 - val_mae: 2.6079\n",
      "Epoch 268/500\n",
      "303/303 - 0s - loss: 1.0996 - mae: 0.7779 - val_loss: 14.7220 - val_mae: 2.5336\n",
      "Epoch 269/500\n",
      "303/303 - 0s - loss: 1.1291 - mae: 0.7714 - val_loss: 16.4128 - val_mae: 2.7351\n",
      "Epoch 270/500\n",
      "303/303 - 0s - loss: 1.0499 - mae: 0.7512 - val_loss: 15.5639 - val_mae: 2.6443\n",
      "Epoch 271/500\n",
      "303/303 - 0s - loss: 1.1114 - mae: 0.7694 - val_loss: 15.2386 - val_mae: 2.6004\n",
      "Epoch 272/500\n",
      "303/303 - 0s - loss: 1.0952 - mae: 0.7537 - val_loss: 14.3278 - val_mae: 2.5113\n",
      "Epoch 273/500\n",
      "303/303 - 0s - loss: 1.1577 - mae: 0.8074 - val_loss: 14.5076 - val_mae: 2.5453\n",
      "Epoch 274/500\n",
      "303/303 - 0s - loss: 1.1486 - mae: 0.7829 - val_loss: 15.3075 - val_mae: 2.6024\n",
      "Epoch 275/500\n",
      "303/303 - 0s - loss: 1.0907 - mae: 0.7577 - val_loss: 15.8765 - val_mae: 2.7854\n",
      "Epoch 276/500\n",
      "303/303 - 0s - loss: 1.1149 - mae: 0.7841 - val_loss: 14.9407 - val_mae: 2.6069\n",
      "Epoch 277/500\n",
      "303/303 - 0s - loss: 1.1635 - mae: 0.7857 - val_loss: 16.5454 - val_mae: 2.7779\n",
      "Epoch 278/500\n",
      "303/303 - 0s - loss: 1.0983 - mae: 0.7786 - val_loss: 15.2900 - val_mae: 2.5953\n",
      "Epoch 279/500\n",
      "303/303 - 0s - loss: 1.1333 - mae: 0.7645 - val_loss: 15.5084 - val_mae: 2.6775\n",
      "Epoch 280/500\n",
      "303/303 - 0s - loss: 1.0266 - mae: 0.7520 - val_loss: 15.0678 - val_mae: 2.5933\n",
      "Epoch 281/500\n",
      "303/303 - 0s - loss: 1.0528 - mae: 0.7621 - val_loss: 15.0514 - val_mae: 2.5775\n",
      "Epoch 282/500\n",
      "303/303 - 0s - loss: 1.1228 - mae: 0.7842 - val_loss: 15.1906 - val_mae: 2.6456\n",
      "Epoch 283/500\n",
      "303/303 - 0s - loss: 1.1227 - mae: 0.7485 - val_loss: 14.7087 - val_mae: 2.6149\n",
      "Epoch 284/500\n",
      "303/303 - 0s - loss: 1.1029 - mae: 0.7629 - val_loss: 13.9664 - val_mae: 2.5334\n",
      "Epoch 285/500\n",
      "303/303 - 0s - loss: 1.2085 - mae: 0.7619 - val_loss: 14.9013 - val_mae: 2.6522\n",
      "Epoch 286/500\n",
      "303/303 - 0s - loss: 1.0168 - mae: 0.7270 - val_loss: 14.9557 - val_mae: 2.5746\n",
      "Epoch 287/500\n",
      "303/303 - 0s - loss: 1.0237 - mae: 0.7665 - val_loss: 14.3569 - val_mae: 2.5306\n",
      "Epoch 288/500\n",
      "303/303 - 0s - loss: 1.1418 - mae: 0.8022 - val_loss: 15.6620 - val_mae: 2.7927\n",
      "Epoch 289/500\n",
      "303/303 - 0s - loss: 0.9638 - mae: 0.7134 - val_loss: 15.8850 - val_mae: 2.6532\n",
      "Epoch 290/500\n",
      "303/303 - 0s - loss: 1.0844 - mae: 0.7800 - val_loss: 15.5895 - val_mae: 2.6873\n",
      "Epoch 291/500\n",
      "303/303 - 0s - loss: 1.2011 - mae: 0.8140 - val_loss: 14.1104 - val_mae: 2.5264\n",
      "Epoch 292/500\n",
      "303/303 - 0s - loss: 1.0543 - mae: 0.7645 - val_loss: 16.4053 - val_mae: 2.7170\n",
      "Epoch 293/500\n",
      "303/303 - 0s - loss: 1.1129 - mae: 0.7379 - val_loss: 15.2395 - val_mae: 2.6352\n",
      "Epoch 294/500\n",
      "303/303 - 0s - loss: 1.0580 - mae: 0.7446 - val_loss: 14.7570 - val_mae: 2.6108\n",
      "Epoch 295/500\n",
      "303/303 - 0s - loss: 1.0418 - mae: 0.7621 - val_loss: 15.6659 - val_mae: 2.5980\n",
      "Epoch 296/500\n",
      "303/303 - 0s - loss: 0.9849 - mae: 0.7518 - val_loss: 15.3086 - val_mae: 2.6044\n",
      "Epoch 297/500\n",
      "303/303 - 0s - loss: 0.9942 - mae: 0.7548 - val_loss: 14.5047 - val_mae: 2.6684\n",
      "Epoch 298/500\n",
      "303/303 - 0s - loss: 1.0251 - mae: 0.7468 - val_loss: 15.0480 - val_mae: 2.6043\n",
      "Epoch 299/500\n",
      "303/303 - 0s - loss: 1.0924 - mae: 0.7663 - val_loss: 14.9251 - val_mae: 2.6343\n",
      "Epoch 300/500\n",
      "303/303 - 0s - loss: 0.9313 - mae: 0.7068 - val_loss: 16.6490 - val_mae: 2.7362\n",
      "Epoch 301/500\n",
      "303/303 - 0s - loss: 1.0209 - mae: 0.7606 - val_loss: 14.9988 - val_mae: 2.5829\n",
      "Epoch 302/500\n",
      "303/303 - 0s - loss: 1.0386 - mae: 0.7774 - val_loss: 16.0447 - val_mae: 2.6917\n",
      "Epoch 303/500\n",
      "303/303 - 0s - loss: 0.9332 - mae: 0.7326 - val_loss: 15.7145 - val_mae: 2.6662\n",
      "Epoch 304/500\n",
      "303/303 - 0s - loss: 1.0112 - mae: 0.7287 - val_loss: 14.2686 - val_mae: 2.5604\n",
      "Epoch 305/500\n",
      "303/303 - 0s - loss: 1.0444 - mae: 0.7577 - val_loss: 14.7005 - val_mae: 2.5499\n",
      "Epoch 306/500\n",
      "303/303 - 0s - loss: 0.9880 - mae: 0.7466 - val_loss: 14.1348 - val_mae: 2.5780\n",
      "Epoch 307/500\n",
      "303/303 - 0s - loss: 1.0550 - mae: 0.7521 - val_loss: 16.0768 - val_mae: 2.6738\n",
      "Epoch 308/500\n",
      "303/303 - 0s - loss: 1.0404 - mae: 0.7628 - val_loss: 15.9797 - val_mae: 2.6622\n",
      "Epoch 309/500\n",
      "303/303 - 0s - loss: 1.0633 - mae: 0.7513 - val_loss: 14.8462 - val_mae: 2.6635\n",
      "Epoch 310/500\n",
      "303/303 - 0s - loss: 0.9830 - mae: 0.7276 - val_loss: 15.1498 - val_mae: 2.6399\n",
      "Epoch 311/500\n",
      "303/303 - 0s - loss: 1.0150 - mae: 0.7512 - val_loss: 14.7195 - val_mae: 2.5453\n",
      "Epoch 312/500\n",
      "303/303 - 0s - loss: 1.0165 - mae: 0.7395 - val_loss: 16.4982 - val_mae: 2.8255\n",
      "Epoch 313/500\n",
      "303/303 - 0s - loss: 0.9097 - mae: 0.7071 - val_loss: 14.2358 - val_mae: 2.4801\n",
      "Epoch 314/500\n",
      "303/303 - 0s - loss: 0.9079 - mae: 0.7023 - val_loss: 14.2906 - val_mae: 2.5033\n",
      "Epoch 315/500\n",
      "303/303 - 0s - loss: 0.9769 - mae: 0.7281 - val_loss: 14.9180 - val_mae: 2.5700\n",
      "Epoch 316/500\n",
      "303/303 - 0s - loss: 1.0609 - mae: 0.7633 - val_loss: 15.5933 - val_mae: 2.5666\n",
      "Epoch 317/500\n",
      "303/303 - 0s - loss: 0.9590 - mae: 0.7253 - val_loss: 15.2563 - val_mae: 2.6025\n",
      "Epoch 318/500\n",
      "303/303 - 0s - loss: 0.8498 - mae: 0.6844 - val_loss: 15.5414 - val_mae: 2.8153\n",
      "Epoch 319/500\n",
      "303/303 - 0s - loss: 1.0724 - mae: 0.7823 - val_loss: 14.5824 - val_mae: 2.6093\n",
      "Epoch 320/500\n",
      "303/303 - 0s - loss: 0.8444 - mae: 0.6935 - val_loss: 14.3810 - val_mae: 2.6241\n",
      "Epoch 321/500\n",
      "303/303 - 0s - loss: 1.0070 - mae: 0.7336 - val_loss: 15.3920 - val_mae: 2.6501\n",
      "Epoch 322/500\n",
      "303/303 - 0s - loss: 0.8329 - mae: 0.6687 - val_loss: 14.9899 - val_mae: 2.6420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323/500\n",
      "303/303 - 0s - loss: 0.8700 - mae: 0.6854 - val_loss: 14.0218 - val_mae: 2.5128\n",
      "Epoch 324/500\n",
      "303/303 - 0s - loss: 0.9295 - mae: 0.7119 - val_loss: 14.3496 - val_mae: 2.5089\n",
      "Epoch 325/500\n",
      "303/303 - 0s - loss: 1.0065 - mae: 0.7502 - val_loss: 16.0371 - val_mae: 2.7024\n",
      "Epoch 326/500\n",
      "303/303 - 0s - loss: 0.8414 - mae: 0.6938 - val_loss: 15.4600 - val_mae: 2.6218\n",
      "Epoch 327/500\n",
      "303/303 - 0s - loss: 0.9789 - mae: 0.7723 - val_loss: 14.8433 - val_mae: 2.6322\n",
      "Epoch 328/500\n",
      "303/303 - 0s - loss: 0.9664 - mae: 0.7121 - val_loss: 15.3211 - val_mae: 2.6826\n",
      "Epoch 329/500\n",
      "303/303 - 0s - loss: 0.8053 - mae: 0.6872 - val_loss: 15.1638 - val_mae: 2.6343\n",
      "Epoch 330/500\n",
      "303/303 - 0s - loss: 1.0301 - mae: 0.7284 - val_loss: 15.0415 - val_mae: 2.5341\n",
      "Epoch 331/500\n",
      "303/303 - 0s - loss: 0.9523 - mae: 0.7170 - val_loss: 15.0682 - val_mae: 2.5887\n",
      "Epoch 332/500\n",
      "303/303 - 0s - loss: 0.9012 - mae: 0.6875 - val_loss: 14.8650 - val_mae: 2.6053\n",
      "Epoch 333/500\n",
      "303/303 - 0s - loss: 0.9490 - mae: 0.7260 - val_loss: 14.4185 - val_mae: 2.6046\n",
      "Epoch 334/500\n",
      "303/303 - 0s - loss: 0.9356 - mae: 0.7123 - val_loss: 15.2022 - val_mae: 2.5713\n",
      "Epoch 335/500\n",
      "303/303 - 0s - loss: 0.9637 - mae: 0.7153 - val_loss: 15.7294 - val_mae: 2.6855\n",
      "Epoch 336/500\n",
      "303/303 - 0s - loss: 0.9054 - mae: 0.6970 - val_loss: 15.4546 - val_mae: 2.5916\n",
      "Epoch 337/500\n",
      "303/303 - 0s - loss: 0.8737 - mae: 0.7097 - val_loss: 14.8930 - val_mae: 2.6602\n",
      "Epoch 338/500\n",
      "303/303 - 0s - loss: 0.9341 - mae: 0.7208 - val_loss: 15.9703 - val_mae: 2.7755\n",
      "Epoch 339/500\n",
      "303/303 - 0s - loss: 0.9890 - mae: 0.7369 - val_loss: 14.9137 - val_mae: 2.6178\n",
      "Epoch 340/500\n",
      "303/303 - 0s - loss: 0.8707 - mae: 0.6802 - val_loss: 15.4672 - val_mae: 2.6450\n",
      "Epoch 341/500\n",
      "303/303 - 0s - loss: 0.8424 - mae: 0.6806 - val_loss: 15.5151 - val_mae: 2.7244\n",
      "Epoch 342/500\n",
      "303/303 - 0s - loss: 1.0246 - mae: 0.7466 - val_loss: 15.1731 - val_mae: 2.6715\n",
      "Epoch 343/500\n",
      "303/303 - 0s - loss: 0.8109 - mae: 0.6735 - val_loss: 16.1263 - val_mae: 2.7738\n",
      "Epoch 344/500\n",
      "303/303 - 0s - loss: 1.0038 - mae: 0.6843 - val_loss: 13.9838 - val_mae: 2.5504\n",
      "Epoch 345/500\n",
      "303/303 - 0s - loss: 0.8890 - mae: 0.6977 - val_loss: 15.5891 - val_mae: 2.6571\n",
      "Epoch 346/500\n",
      "303/303 - 0s - loss: 0.8820 - mae: 0.7107 - val_loss: 15.3711 - val_mae: 2.6651\n",
      "Epoch 347/500\n",
      "303/303 - 0s - loss: 0.9151 - mae: 0.7081 - val_loss: 14.4917 - val_mae: 2.6558\n",
      "Epoch 348/500\n",
      "303/303 - 0s - loss: 0.8148 - mae: 0.6362 - val_loss: 15.8646 - val_mae: 2.7334\n",
      "Epoch 349/500\n",
      "303/303 - 0s - loss: 0.9412 - mae: 0.7367 - val_loss: 15.5492 - val_mae: 2.6701\n",
      "Epoch 350/500\n",
      "303/303 - 0s - loss: 0.7744 - mae: 0.6654 - val_loss: 15.1450 - val_mae: 2.6054\n",
      "Epoch 351/500\n",
      "303/303 - 0s - loss: 1.0093 - mae: 0.7594 - val_loss: 15.0417 - val_mae: 2.6244\n",
      "Epoch 352/500\n",
      "303/303 - 0s - loss: 0.8922 - mae: 0.6921 - val_loss: 15.2379 - val_mae: 2.6551\n",
      "Epoch 353/500\n",
      "303/303 - 0s - loss: 0.7255 - mae: 0.6640 - val_loss: 14.6591 - val_mae: 2.6475\n",
      "Epoch 354/500\n",
      "303/303 - 0s - loss: 0.8277 - mae: 0.6688 - val_loss: 16.0498 - val_mae: 2.6583\n",
      "Epoch 355/500\n",
      "303/303 - 0s - loss: 0.8855 - mae: 0.7064 - val_loss: 14.2787 - val_mae: 2.5754\n",
      "Epoch 356/500\n",
      "303/303 - 0s - loss: 0.8829 - mae: 0.6973 - val_loss: 14.0079 - val_mae: 2.4587\n",
      "Epoch 357/500\n",
      "303/303 - 0s - loss: 0.8899 - mae: 0.7029 - val_loss: 14.1472 - val_mae: 2.5889\n",
      "Epoch 358/500\n",
      "303/303 - 0s - loss: 0.9164 - mae: 0.7047 - val_loss: 14.7660 - val_mae: 2.5779\n",
      "Epoch 359/500\n",
      "303/303 - 0s - loss: 0.7753 - mae: 0.6526 - val_loss: 14.3902 - val_mae: 2.5706\n",
      "Epoch 360/500\n",
      "303/303 - 0s - loss: 0.9207 - mae: 0.6944 - val_loss: 14.4264 - val_mae: 2.5575\n",
      "Epoch 361/500\n",
      "303/303 - 0s - loss: 0.9433 - mae: 0.7051 - val_loss: 14.2422 - val_mae: 2.6190\n",
      "Epoch 362/500\n",
      "303/303 - 0s - loss: 0.8590 - mae: 0.6843 - val_loss: 14.7563 - val_mae: 2.5305\n",
      "Epoch 363/500\n",
      "303/303 - 0s - loss: 0.8039 - mae: 0.6647 - val_loss: 14.5934 - val_mae: 2.5952\n",
      "Epoch 364/500\n",
      "303/303 - 0s - loss: 0.8804 - mae: 0.6980 - val_loss: 13.7728 - val_mae: 2.5259\n",
      "Epoch 365/500\n",
      "303/303 - 0s - loss: 0.8370 - mae: 0.6858 - val_loss: 14.0178 - val_mae: 2.5924\n",
      "Epoch 366/500\n",
      "303/303 - 0s - loss: 0.8028 - mae: 0.6785 - val_loss: 14.7374 - val_mae: 2.6589\n",
      "Epoch 367/500\n",
      "303/303 - 0s - loss: 0.8601 - mae: 0.6704 - val_loss: 14.6150 - val_mae: 2.6362\n",
      "Epoch 368/500\n",
      "303/303 - 0s - loss: 0.8445 - mae: 0.6883 - val_loss: 14.5541 - val_mae: 2.6042\n",
      "Epoch 369/500\n",
      "303/303 - 0s - loss: 0.7853 - mae: 0.6620 - val_loss: 13.8129 - val_mae: 2.5376\n",
      "Epoch 370/500\n",
      "303/303 - 0s - loss: 0.8548 - mae: 0.6690 - val_loss: 14.0902 - val_mae: 2.5526\n",
      "Epoch 371/500\n",
      "303/303 - 0s - loss: 0.7561 - mae: 0.6514 - val_loss: 14.5080 - val_mae: 2.5793\n",
      "Epoch 372/500\n",
      "303/303 - 0s - loss: 0.8621 - mae: 0.6948 - val_loss: 15.0986 - val_mae: 2.6019\n",
      "Epoch 373/500\n",
      "303/303 - 0s - loss: 0.8012 - mae: 0.6354 - val_loss: 14.2861 - val_mae: 2.6054\n",
      "Epoch 374/500\n",
      "303/303 - 0s - loss: 0.8059 - mae: 0.6738 - val_loss: 14.8393 - val_mae: 2.7618\n",
      "Epoch 375/500\n",
      "303/303 - 0s - loss: 0.8149 - mae: 0.6753 - val_loss: 15.2753 - val_mae: 2.6936\n",
      "Epoch 376/500\n",
      "303/303 - 0s - loss: 0.7934 - mae: 0.6709 - val_loss: 15.9291 - val_mae: 2.8766\n",
      "Epoch 377/500\n",
      "303/303 - 0s - loss: 0.7835 - mae: 0.6570 - val_loss: 14.5971 - val_mae: 2.6745\n",
      "Epoch 378/500\n",
      "303/303 - 0s - loss: 0.8561 - mae: 0.6890 - val_loss: 16.3127 - val_mae: 2.8144\n",
      "Epoch 379/500\n",
      "303/303 - 0s - loss: 0.8091 - mae: 0.6634 - val_loss: 14.7412 - val_mae: 2.6515\n",
      "Epoch 380/500\n",
      "303/303 - 0s - loss: 0.7536 - mae: 0.6403 - val_loss: 15.1611 - val_mae: 2.6545\n",
      "Epoch 381/500\n",
      "303/303 - 0s - loss: 0.7939 - mae: 0.6826 - val_loss: 14.4334 - val_mae: 2.5393\n",
      "Epoch 382/500\n",
      "303/303 - 0s - loss: 0.8004 - mae: 0.6957 - val_loss: 14.0773 - val_mae: 2.6434\n",
      "Epoch 383/500\n",
      "303/303 - 0s - loss: 0.7004 - mae: 0.6220 - val_loss: 15.9223 - val_mae: 2.7257\n",
      "Epoch 384/500\n",
      "303/303 - 0s - loss: 0.8537 - mae: 0.7091 - val_loss: 15.5902 - val_mae: 2.7454\n",
      "Epoch 385/500\n",
      "303/303 - 0s - loss: 0.7631 - mae: 0.6376 - val_loss: 14.4817 - val_mae: 2.6302\n",
      "Epoch 386/500\n",
      "303/303 - 0s - loss: 0.8300 - mae: 0.6967 - val_loss: 14.5505 - val_mae: 2.6213\n",
      "Epoch 387/500\n",
      "303/303 - 0s - loss: 0.8210 - mae: 0.6547 - val_loss: 15.0683 - val_mae: 2.6215\n",
      "Epoch 388/500\n",
      "303/303 - 0s - loss: 0.7670 - mae: 0.6638 - val_loss: 14.5449 - val_mae: 2.5733\n",
      "Epoch 389/500\n",
      "303/303 - 0s - loss: 0.9008 - mae: 0.6878 - val_loss: 15.1457 - val_mae: 2.6782\n",
      "Epoch 390/500\n",
      "303/303 - 0s - loss: 0.7047 - mae: 0.6315 - val_loss: 15.2853 - val_mae: 2.6188\n",
      "Epoch 391/500\n",
      "303/303 - 0s - loss: 0.8204 - mae: 0.6588 - val_loss: 13.8851 - val_mae: 2.6483\n",
      "Epoch 392/500\n",
      "303/303 - 0s - loss: 0.7731 - mae: 0.6831 - val_loss: 14.6340 - val_mae: 2.6736\n",
      "Epoch 393/500\n",
      "303/303 - 0s - loss: 0.8055 - mae: 0.6593 - val_loss: 14.4775 - val_mae: 2.6183\n",
      "Epoch 394/500\n",
      "303/303 - 0s - loss: 0.8405 - mae: 0.6727 - val_loss: 14.7660 - val_mae: 2.6334\n",
      "Epoch 395/500\n",
      "303/303 - 0s - loss: 0.7200 - mae: 0.6161 - val_loss: 15.4474 - val_mae: 2.6970\n",
      "Epoch 396/500\n",
      "303/303 - 0s - loss: 0.7759 - mae: 0.6371 - val_loss: 15.3324 - val_mae: 2.6400\n",
      "Epoch 397/500\n",
      "303/303 - 0s - loss: 0.7762 - mae: 0.6507 - val_loss: 14.0431 - val_mae: 2.6457\n",
      "Epoch 398/500\n",
      "303/303 - 0s - loss: 0.7323 - mae: 0.6495 - val_loss: 14.9119 - val_mae: 2.6587\n",
      "Epoch 399/500\n",
      "303/303 - 0s - loss: 0.7309 - mae: 0.6184 - val_loss: 14.0525 - val_mae: 2.5760\n",
      "Epoch 400/500\n",
      "303/303 - 0s - loss: 0.7940 - mae: 0.6536 - val_loss: 14.8122 - val_mae: 2.5996\n",
      "Epoch 401/500\n",
      "303/303 - 0s - loss: 0.7629 - mae: 0.6147 - val_loss: 15.5982 - val_mae: 2.8095\n",
      "Epoch 402/500\n",
      "303/303 - 0s - loss: 0.7202 - mae: 0.6382 - val_loss: 13.1404 - val_mae: 2.5396\n",
      "Epoch 403/500\n",
      "303/303 - 0s - loss: 0.7908 - mae: 0.6360 - val_loss: 13.4051 - val_mae: 2.5405\n",
      "Epoch 404/500\n",
      "303/303 - 0s - loss: 0.8136 - mae: 0.6738 - val_loss: 14.6551 - val_mae: 2.7178\n",
      "Epoch 405/500\n",
      "303/303 - 0s - loss: 0.6869 - mae: 0.6292 - val_loss: 15.1979 - val_mae: 2.7666\n",
      "Epoch 406/500\n",
      "303/303 - 0s - loss: 0.7334 - mae: 0.6158 - val_loss: 14.8918 - val_mae: 2.6803\n",
      "Epoch 407/500\n",
      "303/303 - 0s - loss: 0.8251 - mae: 0.6595 - val_loss: 14.2591 - val_mae: 2.5981\n",
      "Epoch 408/500\n",
      "303/303 - 0s - loss: 0.8023 - mae: 0.6567 - val_loss: 14.6628 - val_mae: 2.6721\n",
      "Epoch 409/500\n",
      "303/303 - 0s - loss: 0.7226 - mae: 0.6074 - val_loss: 15.0349 - val_mae: 2.6042\n",
      "Epoch 410/500\n",
      "303/303 - 0s - loss: 0.7380 - mae: 0.6483 - val_loss: 14.4957 - val_mae: 2.6236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 411/500\n",
      "303/303 - 0s - loss: 0.7141 - mae: 0.6474 - val_loss: 15.0084 - val_mae: 2.6494\n",
      "Epoch 412/500\n",
      "303/303 - 0s - loss: 0.7675 - mae: 0.6688 - val_loss: 15.2320 - val_mae: 2.6797\n",
      "Epoch 413/500\n",
      "303/303 - 0s - loss: 0.8399 - mae: 0.6473 - val_loss: 14.8634 - val_mae: 2.6523\n",
      "Epoch 414/500\n",
      "303/303 - 0s - loss: 0.7185 - mae: 0.6330 - val_loss: 14.2794 - val_mae: 2.6054\n",
      "Epoch 415/500\n",
      "303/303 - 0s - loss: 0.6966 - mae: 0.6385 - val_loss: 14.1198 - val_mae: 2.5889\n",
      "Epoch 416/500\n",
      "303/303 - 0s - loss: 0.7826 - mae: 0.6381 - val_loss: 13.7655 - val_mae: 2.6045\n",
      "Epoch 417/500\n",
      "303/303 - 0s - loss: 0.7902 - mae: 0.6605 - val_loss: 13.5133 - val_mae: 2.5564\n",
      "Epoch 418/500\n",
      "303/303 - 0s - loss: 0.6365 - mae: 0.5766 - val_loss: 13.4871 - val_mae: 2.5644\n",
      "Epoch 419/500\n",
      "303/303 - 0s - loss: 0.7790 - mae: 0.6381 - val_loss: 13.6035 - val_mae: 2.6244\n",
      "Epoch 420/500\n",
      "303/303 - 0s - loss: 0.7161 - mae: 0.6333 - val_loss: 14.6484 - val_mae: 2.7109\n",
      "Epoch 421/500\n",
      "303/303 - 0s - loss: 0.7325 - mae: 0.6488 - val_loss: 14.3599 - val_mae: 2.6177\n",
      "Epoch 422/500\n",
      "303/303 - 0s - loss: 0.7150 - mae: 0.6006 - val_loss: 14.8618 - val_mae: 2.6088\n",
      "Epoch 423/500\n",
      "303/303 - 0s - loss: 0.7654 - mae: 0.6535 - val_loss: 14.5054 - val_mae: 2.6942\n",
      "Epoch 424/500\n",
      "303/303 - 0s - loss: 0.7555 - mae: 0.6224 - val_loss: 14.1242 - val_mae: 2.5437\n",
      "Epoch 425/500\n",
      "303/303 - 0s - loss: 0.7091 - mae: 0.6381 - val_loss: 14.4611 - val_mae: 2.6414\n",
      "Epoch 426/500\n",
      "303/303 - 0s - loss: 0.7302 - mae: 0.6550 - val_loss: 14.3278 - val_mae: 2.6559\n",
      "Epoch 427/500\n",
      "303/303 - 0s - loss: 0.7346 - mae: 0.6290 - val_loss: 13.8595 - val_mae: 2.5987\n",
      "Epoch 428/500\n",
      "303/303 - 0s - loss: 0.7377 - mae: 0.6112 - val_loss: 14.4320 - val_mae: 2.6768\n",
      "Epoch 429/500\n",
      "303/303 - 0s - loss: 0.6999 - mae: 0.6003 - val_loss: 14.2404 - val_mae: 2.5970\n",
      "Epoch 430/500\n",
      "303/303 - 0s - loss: 0.7408 - mae: 0.6293 - val_loss: 14.3585 - val_mae: 2.6343\n",
      "Epoch 431/500\n",
      "303/303 - 0s - loss: 0.6636 - mae: 0.6042 - val_loss: 14.5962 - val_mae: 2.6585\n",
      "Epoch 432/500\n",
      "303/303 - 0s - loss: 0.7579 - mae: 0.6321 - val_loss: 14.5044 - val_mae: 2.6383\n",
      "Epoch 433/500\n",
      "303/303 - 0s - loss: 0.7261 - mae: 0.6427 - val_loss: 15.0791 - val_mae: 2.7043\n",
      "Epoch 434/500\n",
      "303/303 - 0s - loss: 0.6311 - mae: 0.5935 - val_loss: 13.9884 - val_mae: 2.5971\n",
      "Epoch 435/500\n",
      "303/303 - 0s - loss: 0.7057 - mae: 0.6413 - val_loss: 14.5883 - val_mae: 2.6403\n",
      "Epoch 436/500\n",
      "303/303 - 0s - loss: 0.6824 - mae: 0.6213 - val_loss: 15.7448 - val_mae: 2.7247\n",
      "Epoch 437/500\n",
      "303/303 - 0s - loss: 0.6390 - mae: 0.5995 - val_loss: 15.8441 - val_mae: 2.8945\n",
      "Epoch 438/500\n",
      "303/303 - 0s - loss: 0.7301 - mae: 0.6434 - val_loss: 15.8695 - val_mae: 2.8007\n",
      "Epoch 439/500\n",
      "303/303 - 0s - loss: 0.6340 - mae: 0.6116 - val_loss: 15.5819 - val_mae: 2.7827\n",
      "Epoch 440/500\n",
      "303/303 - 0s - loss: 0.6774 - mae: 0.6247 - val_loss: 14.3311 - val_mae: 2.6691\n",
      "Epoch 441/500\n",
      "303/303 - 0s - loss: 0.7987 - mae: 0.6462 - val_loss: 14.4214 - val_mae: 2.6870\n",
      "Epoch 442/500\n",
      "303/303 - 0s - loss: 0.6756 - mae: 0.6120 - val_loss: 14.2359 - val_mae: 2.6686\n",
      "Epoch 443/500\n",
      "303/303 - 0s - loss: 0.7053 - mae: 0.6099 - val_loss: 13.6247 - val_mae: 2.6256\n",
      "Epoch 444/500\n",
      "303/303 - 0s - loss: 0.6708 - mae: 0.6296 - val_loss: 14.1899 - val_mae: 2.6935\n",
      "Epoch 445/500\n",
      "303/303 - 0s - loss: 0.6757 - mae: 0.6003 - val_loss: 14.5847 - val_mae: 2.6760\n",
      "Epoch 446/500\n",
      "303/303 - 0s - loss: 0.7278 - mae: 0.6481 - val_loss: 14.3737 - val_mae: 2.6601\n",
      "Epoch 447/500\n",
      "303/303 - 0s - loss: 0.6378 - mae: 0.5909 - val_loss: 13.8229 - val_mae: 2.5652\n",
      "Epoch 448/500\n",
      "303/303 - 0s - loss: 0.6756 - mae: 0.6079 - val_loss: 14.3407 - val_mae: 2.6711\n",
      "Epoch 449/500\n",
      "303/303 - 0s - loss: 0.7468 - mae: 0.6279 - val_loss: 14.3688 - val_mae: 2.6564\n",
      "Epoch 450/500\n",
      "303/303 - 0s - loss: 0.7226 - mae: 0.6354 - val_loss: 14.1278 - val_mae: 2.6549\n",
      "Epoch 451/500\n",
      "303/303 - 0s - loss: 0.6999 - mae: 0.6205 - val_loss: 13.8412 - val_mae: 2.5927\n",
      "Epoch 452/500\n",
      "303/303 - 0s - loss: 0.7013 - mae: 0.5940 - val_loss: 14.1304 - val_mae: 2.6173\n",
      "Epoch 453/500\n",
      "303/303 - 0s - loss: 0.7011 - mae: 0.6316 - val_loss: 14.1532 - val_mae: 2.6543\n",
      "Epoch 454/500\n",
      "303/303 - 0s - loss: 0.7017 - mae: 0.6000 - val_loss: 14.0467 - val_mae: 2.6529\n",
      "Epoch 455/500\n",
      "303/303 - 0s - loss: 0.5850 - mae: 0.5785 - val_loss: 13.9549 - val_mae: 2.6590\n",
      "Epoch 456/500\n",
      "303/303 - 0s - loss: 0.7714 - mae: 0.6264 - val_loss: 13.6854 - val_mae: 2.6265\n",
      "Epoch 457/500\n",
      "303/303 - 0s - loss: 0.7017 - mae: 0.6167 - val_loss: 14.0021 - val_mae: 2.6266\n",
      "Epoch 458/500\n",
      "303/303 - 0s - loss: 0.7641 - mae: 0.6260 - val_loss: 14.4509 - val_mae: 2.6427\n",
      "Epoch 459/500\n",
      "303/303 - 0s - loss: 0.6637 - mae: 0.6056 - val_loss: 14.1077 - val_mae: 2.5939\n",
      "Epoch 460/500\n",
      "303/303 - 0s - loss: 0.5515 - mae: 0.5489 - val_loss: 14.7834 - val_mae: 2.6878\n",
      "Epoch 461/500\n",
      "303/303 - 0s - loss: 0.6632 - mae: 0.6014 - val_loss: 13.7331 - val_mae: 2.5501\n",
      "Epoch 462/500\n",
      "303/303 - 0s - loss: 0.6242 - mae: 0.6160 - val_loss: 14.0422 - val_mae: 2.6568\n",
      "Epoch 463/500\n",
      "303/303 - 0s - loss: 0.7589 - mae: 0.6411 - val_loss: 13.6249 - val_mae: 2.5425\n",
      "Epoch 464/500\n",
      "303/303 - 0s - loss: 0.7298 - mae: 0.6258 - val_loss: 13.9845 - val_mae: 2.5536\n",
      "Epoch 465/500\n",
      "303/303 - 0s - loss: 0.7107 - mae: 0.6268 - val_loss: 14.1197 - val_mae: 2.5226\n",
      "Epoch 466/500\n",
      "303/303 - 0s - loss: 0.6650 - mae: 0.6166 - val_loss: 13.5936 - val_mae: 2.6071\n",
      "Epoch 467/500\n",
      "303/303 - 0s - loss: 0.6536 - mae: 0.6031 - val_loss: 14.1207 - val_mae: 2.6728\n",
      "Epoch 468/500\n",
      "303/303 - 0s - loss: 0.6725 - mae: 0.6200 - val_loss: 13.5142 - val_mae: 2.6104\n",
      "Epoch 469/500\n",
      "303/303 - 0s - loss: 0.6522 - mae: 0.5789 - val_loss: 14.2046 - val_mae: 2.6578\n",
      "Epoch 470/500\n",
      "303/303 - 0s - loss: 0.6373 - mae: 0.5810 - val_loss: 14.8403 - val_mae: 2.7112\n",
      "Epoch 471/500\n",
      "303/303 - 0s - loss: 0.6918 - mae: 0.6143 - val_loss: 13.6407 - val_mae: 2.5573\n",
      "Epoch 472/500\n",
      "303/303 - 0s - loss: 0.7741 - mae: 0.6306 - val_loss: 13.3767 - val_mae: 2.5182\n",
      "Epoch 473/500\n",
      "303/303 - 0s - loss: 0.6674 - mae: 0.6122 - val_loss: 15.0318 - val_mae: 2.7300\n",
      "Epoch 474/500\n",
      "303/303 - 0s - loss: 0.7348 - mae: 0.6193 - val_loss: 13.5148 - val_mae: 2.5879\n",
      "Epoch 475/500\n",
      "303/303 - 0s - loss: 0.6662 - mae: 0.6268 - val_loss: 14.0183 - val_mae: 2.5950\n",
      "Epoch 476/500\n",
      "303/303 - 0s - loss: 0.6532 - mae: 0.5951 - val_loss: 14.1000 - val_mae: 2.6833\n",
      "Epoch 477/500\n",
      "303/303 - 0s - loss: 0.6885 - mae: 0.6018 - val_loss: 15.1003 - val_mae: 2.6769\n",
      "Epoch 478/500\n",
      "303/303 - 0s - loss: 0.7019 - mae: 0.6060 - val_loss: 14.5119 - val_mae: 2.6601\n",
      "Epoch 479/500\n",
      "303/303 - 0s - loss: 0.5733 - mae: 0.5882 - val_loss: 14.5213 - val_mae: 2.6189\n",
      "Epoch 480/500\n",
      "303/303 - 0s - loss: 0.6428 - mae: 0.5888 - val_loss: 14.3712 - val_mae: 2.7313\n",
      "Epoch 481/500\n",
      "303/303 - 0s - loss: 0.6270 - mae: 0.5781 - val_loss: 14.3452 - val_mae: 2.5982\n",
      "Epoch 482/500\n",
      "303/303 - 0s - loss: 0.6777 - mae: 0.6324 - val_loss: 15.4108 - val_mae: 2.8171\n",
      "Epoch 483/500\n",
      "303/303 - 0s - loss: 0.6599 - mae: 0.6177 - val_loss: 14.2921 - val_mae: 2.6445\n",
      "Epoch 484/500\n",
      "303/303 - 0s - loss: 0.7411 - mae: 0.6314 - val_loss: 14.2069 - val_mae: 2.6407\n",
      "Epoch 485/500\n",
      "303/303 - 0s - loss: 0.6851 - mae: 0.6120 - val_loss: 14.7360 - val_mae: 2.7178\n",
      "Epoch 486/500\n",
      "303/303 - 0s - loss: 0.6519 - mae: 0.5820 - val_loss: 14.3455 - val_mae: 2.6452\n",
      "Epoch 487/500\n",
      "303/303 - 0s - loss: 0.6815 - mae: 0.6216 - val_loss: 14.4447 - val_mae: 2.6821\n",
      "Epoch 488/500\n",
      "303/303 - 0s - loss: 0.7545 - mae: 0.6104 - val_loss: 14.3096 - val_mae: 2.6496\n",
      "Epoch 489/500\n",
      "303/303 - 0s - loss: 0.6486 - mae: 0.5890 - val_loss: 14.7842 - val_mae: 2.6697\n",
      "Epoch 490/500\n",
      "303/303 - 0s - loss: 0.6969 - mae: 0.6097 - val_loss: 14.6725 - val_mae: 2.8001\n",
      "Epoch 491/500\n",
      "303/303 - 0s - loss: 0.6647 - mae: 0.6076 - val_loss: 14.6546 - val_mae: 2.6446\n",
      "Epoch 492/500\n",
      "303/303 - 0s - loss: 0.5919 - mae: 0.5786 - val_loss: 14.0020 - val_mae: 2.6405\n",
      "Epoch 493/500\n",
      "303/303 - 0s - loss: 0.5523 - mae: 0.5475 - val_loss: 14.8387 - val_mae: 2.7039\n",
      "Epoch 494/500\n",
      "303/303 - 0s - loss: 0.6758 - mae: 0.6213 - val_loss: 14.3376 - val_mae: 2.6613\n",
      "Epoch 495/500\n",
      "303/303 - 0s - loss: 0.5909 - mae: 0.5965 - val_loss: 15.6439 - val_mae: 2.7409\n",
      "Epoch 496/500\n",
      "303/303 - 0s - loss: 0.6583 - mae: 0.5869 - val_loss: 14.2270 - val_mae: 2.7249\n",
      "Epoch 497/500\n",
      "303/303 - 0s - loss: 0.6462 - mae: 0.5801 - val_loss: 15.1736 - val_mae: 2.7664\n",
      "Epoch 498/500\n",
      "303/303 - 0s - loss: 0.6662 - mae: 0.6099 - val_loss: 14.7424 - val_mae: 2.7325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/500\n",
      "303/303 - 0s - loss: 0.6435 - mae: 0.5813 - val_loss: 13.7304 - val_mae: 2.5496\n",
      "Epoch 500/500\n",
      "303/303 - 0s - loss: 0.6475 - mae: 0.5837 - val_loss: 13.9087 - val_mae: 2.6407\n",
      "processing fold # 3\n",
      "Epoch 1/500\n",
      "303/303 - 1s - loss: 169.7901 - mae: 9.8682 - val_loss: 46.7110 - val_mae: 4.6397\n",
      "Epoch 2/500\n",
      "303/303 - 0s - loss: 23.2256 - mae: 3.2221 - val_loss: 29.9529 - val_mae: 3.3638\n",
      "Epoch 3/500\n",
      "303/303 - 0s - loss: 18.0881 - mae: 2.7383 - val_loss: 26.3185 - val_mae: 3.1137\n",
      "Epoch 4/500\n",
      "303/303 - 0s - loss: 15.9573 - mae: 2.6057 - val_loss: 24.8316 - val_mae: 2.9793\n",
      "Epoch 5/500\n",
      "303/303 - 0s - loss: 14.9860 - mae: 2.4988 - val_loss: 22.2642 - val_mae: 2.9760\n",
      "Epoch 6/500\n",
      "303/303 - 0s - loss: 13.6933 - mae: 2.3883 - val_loss: 22.4860 - val_mae: 3.0031\n",
      "Epoch 7/500\n",
      "303/303 - 0s - loss: 12.7432 - mae: 2.3166 - val_loss: 20.9626 - val_mae: 2.7267\n",
      "Epoch 8/500\n",
      "303/303 - 0s - loss: 12.1069 - mae: 2.1752 - val_loss: 23.5235 - val_mae: 3.1361\n",
      "Epoch 9/500\n",
      "303/303 - 0s - loss: 11.7029 - mae: 2.2653 - val_loss: 21.1257 - val_mae: 2.8482\n",
      "Epoch 10/500\n",
      "303/303 - 0s - loss: 11.2255 - mae: 2.1952 - val_loss: 15.9704 - val_mae: 2.5767\n",
      "Epoch 11/500\n",
      "303/303 - 0s - loss: 10.9569 - mae: 2.1723 - val_loss: 18.0601 - val_mae: 2.6239\n",
      "Epoch 12/500\n",
      "303/303 - 0s - loss: 10.6698 - mae: 2.1931 - val_loss: 15.9016 - val_mae: 2.4937\n",
      "Epoch 13/500\n",
      "303/303 - 0s - loss: 10.1622 - mae: 2.0521 - val_loss: 16.2504 - val_mae: 2.5827\n",
      "Epoch 14/500\n",
      "303/303 - 0s - loss: 10.5866 - mae: 2.1076 - val_loss: 16.3187 - val_mae: 2.5076\n",
      "Epoch 15/500\n",
      "303/303 - 0s - loss: 9.6782 - mae: 2.0599 - val_loss: 15.0115 - val_mae: 2.5614\n",
      "Epoch 16/500\n",
      "303/303 - 0s - loss: 9.6915 - mae: 2.0359 - val_loss: 19.2446 - val_mae: 2.8423\n",
      "Epoch 17/500\n",
      "303/303 - 0s - loss: 9.4620 - mae: 2.0126 - val_loss: 14.4892 - val_mae: 2.5683\n",
      "Epoch 18/500\n",
      "303/303 - 0s - loss: 8.9747 - mae: 1.9906 - val_loss: 13.2046 - val_mae: 2.4272\n",
      "Epoch 19/500\n",
      "303/303 - 0s - loss: 9.0919 - mae: 1.9650 - val_loss: 14.0165 - val_mae: 2.5299\n",
      "Epoch 20/500\n",
      "303/303 - 0s - loss: 8.5816 - mae: 1.9670 - val_loss: 14.8033 - val_mae: 2.5174\n",
      "Epoch 21/500\n",
      "303/303 - 0s - loss: 9.2473 - mae: 1.9475 - val_loss: 13.2637 - val_mae: 2.4229\n",
      "Epoch 22/500\n",
      "303/303 - 0s - loss: 8.3999 - mae: 1.9344 - val_loss: 13.8452 - val_mae: 2.6155\n",
      "Epoch 23/500\n",
      "303/303 - 0s - loss: 8.4589 - mae: 1.9460 - val_loss: 14.4711 - val_mae: 2.5141\n",
      "Epoch 24/500\n",
      "303/303 - 0s - loss: 8.2256 - mae: 1.9011 - val_loss: 13.2323 - val_mae: 2.5607\n",
      "Epoch 25/500\n",
      "303/303 - 0s - loss: 7.5226 - mae: 1.8610 - val_loss: 16.2867 - val_mae: 2.7506\n",
      "Epoch 26/500\n",
      "303/303 - 0s - loss: 8.2182 - mae: 1.9002 - val_loss: 12.4864 - val_mae: 2.3755\n",
      "Epoch 27/500\n",
      "303/303 - 0s - loss: 8.1784 - mae: 1.8319 - val_loss: 13.6235 - val_mae: 2.4689\n",
      "Epoch 28/500\n",
      "303/303 - 0s - loss: 8.0833 - mae: 1.8902 - val_loss: 11.9558 - val_mae: 2.3923\n",
      "Epoch 29/500\n",
      "303/303 - 0s - loss: 7.8496 - mae: 1.8490 - val_loss: 13.2524 - val_mae: 2.4490\n",
      "Epoch 30/500\n",
      "303/303 - 0s - loss: 7.5684 - mae: 1.8245 - val_loss: 12.2604 - val_mae: 2.4343\n",
      "Epoch 31/500\n",
      "303/303 - 0s - loss: 7.6973 - mae: 1.8397 - val_loss: 12.6218 - val_mae: 2.4503\n",
      "Epoch 32/500\n",
      "303/303 - 0s - loss: 7.2642 - mae: 1.8164 - val_loss: 12.9673 - val_mae: 2.5684\n",
      "Epoch 33/500\n",
      "303/303 - 0s - loss: 7.3502 - mae: 1.8260 - val_loss: 12.7119 - val_mae: 2.4358\n",
      "Epoch 34/500\n",
      "303/303 - 0s - loss: 7.4479 - mae: 1.7503 - val_loss: 12.3334 - val_mae: 2.5313\n",
      "Epoch 35/500\n",
      "303/303 - 0s - loss: 7.3008 - mae: 1.7779 - val_loss: 12.7613 - val_mae: 2.5263\n",
      "Epoch 36/500\n",
      "303/303 - 0s - loss: 6.9176 - mae: 1.7351 - val_loss: 14.5562 - val_mae: 2.7036\n",
      "Epoch 37/500\n",
      "303/303 - 0s - loss: 7.2073 - mae: 1.7565 - val_loss: 12.5084 - val_mae: 2.5355\n",
      "Epoch 38/500\n",
      "303/303 - 0s - loss: 7.2590 - mae: 1.7160 - val_loss: 13.6160 - val_mae: 2.5992\n",
      "Epoch 39/500\n",
      "303/303 - 0s - loss: 6.8001 - mae: 1.7255 - val_loss: 12.7316 - val_mae: 2.5463\n",
      "Epoch 40/500\n",
      "303/303 - 0s - loss: 7.1363 - mae: 1.7767 - val_loss: 12.0364 - val_mae: 2.5159\n",
      "Epoch 41/500\n",
      "303/303 - 0s - loss: 7.0214 - mae: 1.7477 - val_loss: 12.4254 - val_mae: 2.5151\n",
      "Epoch 42/500\n",
      "303/303 - 0s - loss: 6.7669 - mae: 1.6339 - val_loss: 13.6888 - val_mae: 2.6396\n",
      "Epoch 43/500\n",
      "303/303 - 0s - loss: 6.5004 - mae: 1.6277 - val_loss: 12.1801 - val_mae: 2.5010\n",
      "Epoch 44/500\n",
      "303/303 - 0s - loss: 6.6216 - mae: 1.6515 - val_loss: 12.1403 - val_mae: 2.4078\n",
      "Epoch 45/500\n",
      "303/303 - 0s - loss: 6.3258 - mae: 1.6688 - val_loss: 11.6023 - val_mae: 2.3559\n",
      "Epoch 46/500\n",
      "303/303 - 0s - loss: 5.9782 - mae: 1.5967 - val_loss: 13.4730 - val_mae: 2.6253\n",
      "Epoch 47/500\n",
      "303/303 - 0s - loss: 5.9719 - mae: 1.6392 - val_loss: 13.7226 - val_mae: 2.7070\n",
      "Epoch 48/500\n",
      "303/303 - 0s - loss: 6.1525 - mae: 1.5754 - val_loss: 12.7685 - val_mae: 2.5283\n",
      "Epoch 49/500\n",
      "303/303 - 0s - loss: 5.9925 - mae: 1.5513 - val_loss: 12.0663 - val_mae: 2.4497\n",
      "Epoch 50/500\n",
      "303/303 - 0s - loss: 6.2606 - mae: 1.6219 - val_loss: 11.6432 - val_mae: 2.3754\n",
      "Epoch 51/500\n",
      "303/303 - 0s - loss: 6.0209 - mae: 1.6092 - val_loss: 12.3896 - val_mae: 2.4879\n",
      "Epoch 52/500\n",
      "303/303 - 0s - loss: 5.5801 - mae: 1.5564 - val_loss: 12.1311 - val_mae: 2.3945\n",
      "Epoch 53/500\n",
      "303/303 - 0s - loss: 5.7142 - mae: 1.6278 - val_loss: 11.9084 - val_mae: 2.3345\n",
      "Epoch 54/500\n",
      "303/303 - 0s - loss: 5.7454 - mae: 1.5948 - val_loss: 11.8420 - val_mae: 2.3992\n",
      "Epoch 55/500\n",
      "303/303 - 0s - loss: 5.4034 - mae: 1.5271 - val_loss: 12.1988 - val_mae: 2.5271\n",
      "Epoch 56/500\n",
      "303/303 - 0s - loss: 5.6547 - mae: 1.5442 - val_loss: 13.0179 - val_mae: 2.6573\n",
      "Epoch 57/500\n",
      "303/303 - 0s - loss: 5.4802 - mae: 1.5232 - val_loss: 13.6504 - val_mae: 2.7063\n",
      "Epoch 58/500\n",
      "303/303 - 0s - loss: 5.6829 - mae: 1.5959 - val_loss: 11.7871 - val_mae: 2.4661\n",
      "Epoch 59/500\n",
      "303/303 - 0s - loss: 5.7637 - mae: 1.5624 - val_loss: 12.1999 - val_mae: 2.5485\n",
      "Epoch 60/500\n",
      "303/303 - 0s - loss: 5.1901 - mae: 1.4704 - val_loss: 12.1986 - val_mae: 2.4895\n",
      "Epoch 61/500\n",
      "303/303 - 0s - loss: 5.3817 - mae: 1.4755 - val_loss: 12.0008 - val_mae: 2.5203\n",
      "Epoch 62/500\n",
      "303/303 - 0s - loss: 5.4771 - mae: 1.4754 - val_loss: 11.9307 - val_mae: 2.4406\n",
      "Epoch 63/500\n",
      "303/303 - 0s - loss: 4.8552 - mae: 1.4836 - val_loss: 11.9645 - val_mae: 2.3912\n",
      "Epoch 64/500\n",
      "303/303 - 0s - loss: 5.4113 - mae: 1.4657 - val_loss: 13.7037 - val_mae: 2.6420\n",
      "Epoch 65/500\n",
      "303/303 - 0s - loss: 5.1463 - mae: 1.4795 - val_loss: 12.2064 - val_mae: 2.5277\n",
      "Epoch 66/500\n",
      "303/303 - 0s - loss: 5.1166 - mae: 1.4294 - val_loss: 12.3656 - val_mae: 2.5843\n",
      "Epoch 67/500\n",
      "303/303 - 0s - loss: 4.8579 - mae: 1.4429 - val_loss: 11.7858 - val_mae: 2.4251\n",
      "Epoch 68/500\n",
      "303/303 - 0s - loss: 4.8848 - mae: 1.4174 - val_loss: 11.7692 - val_mae: 2.4486\n",
      "Epoch 69/500\n",
      "303/303 - 0s - loss: 4.7536 - mae: 1.3950 - val_loss: 16.1203 - val_mae: 3.0178\n",
      "Epoch 70/500\n",
      "303/303 - 0s - loss: 4.8044 - mae: 1.3727 - val_loss: 11.0421 - val_mae: 2.3643\n",
      "Epoch 71/500\n",
      "303/303 - 0s - loss: 5.0153 - mae: 1.4470 - val_loss: 11.6692 - val_mae: 2.4206\n",
      "Epoch 72/500\n",
      "303/303 - 0s - loss: 5.0219 - mae: 1.4325 - val_loss: 12.3010 - val_mae: 2.5268\n",
      "Epoch 73/500\n",
      "303/303 - 0s - loss: 4.8563 - mae: 1.4197 - val_loss: 11.9034 - val_mae: 2.5022\n",
      "Epoch 74/500\n",
      "303/303 - 0s - loss: 5.0729 - mae: 1.3781 - val_loss: 10.9938 - val_mae: 2.3707\n",
      "Epoch 75/500\n",
      "303/303 - 0s - loss: 4.3725 - mae: 1.3324 - val_loss: 11.7016 - val_mae: 2.4733\n",
      "Epoch 76/500\n",
      "303/303 - 0s - loss: 4.7766 - mae: 1.3808 - val_loss: 12.3949 - val_mae: 2.5256\n",
      "Epoch 77/500\n",
      "303/303 - 0s - loss: 4.4188 - mae: 1.3364 - val_loss: 12.7891 - val_mae: 2.6046\n",
      "Epoch 78/500\n",
      "303/303 - 0s - loss: 4.6952 - mae: 1.3315 - val_loss: 11.5926 - val_mae: 2.4258\n",
      "Epoch 79/500\n",
      "303/303 - 0s - loss: 4.4279 - mae: 1.3776 - val_loss: 13.1979 - val_mae: 2.6684\n",
      "Epoch 80/500\n",
      "303/303 - 0s - loss: 4.5521 - mae: 1.3353 - val_loss: 13.8085 - val_mae: 2.7441\n",
      "Epoch 81/500\n",
      "303/303 - 0s - loss: 4.4215 - mae: 1.3280 - val_loss: 12.0850 - val_mae: 2.4568\n",
      "Epoch 82/500\n",
      "303/303 - 0s - loss: 4.2246 - mae: 1.3513 - val_loss: 12.2165 - val_mae: 2.5029\n",
      "Epoch 83/500\n",
      "303/303 - 0s - loss: 4.5310 - mae: 1.3424 - val_loss: 11.2967 - val_mae: 2.4439\n",
      "Epoch 84/500\n",
      "303/303 - 0s - loss: 4.3410 - mae: 1.3119 - val_loss: 12.9654 - val_mae: 2.6010\n",
      "Epoch 85/500\n",
      "303/303 - 0s - loss: 4.2043 - mae: 1.3425 - val_loss: 12.8264 - val_mae: 2.5848\n",
      "Epoch 86/500\n",
      "303/303 - 0s - loss: 4.1958 - mae: 1.2920 - val_loss: 13.1205 - val_mae: 2.6016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/500\n",
      "303/303 - 0s - loss: 4.2417 - mae: 1.3042 - val_loss: 11.2154 - val_mae: 2.3825\n",
      "Epoch 88/500\n",
      "303/303 - 0s - loss: 4.3757 - mae: 1.2830 - val_loss: 13.9741 - val_mae: 2.7876\n",
      "Epoch 89/500\n",
      "303/303 - 0s - loss: 4.1589 - mae: 1.2955 - val_loss: 12.9632 - val_mae: 2.6645\n",
      "Epoch 90/500\n",
      "303/303 - 0s - loss: 3.8319 - mae: 1.2782 - val_loss: 12.7945 - val_mae: 2.5569\n",
      "Epoch 91/500\n",
      "303/303 - 0s - loss: 3.9591 - mae: 1.2968 - val_loss: 11.3199 - val_mae: 2.5169\n",
      "Epoch 92/500\n",
      "303/303 - 0s - loss: 4.0407 - mae: 1.3228 - val_loss: 11.5955 - val_mae: 2.4984\n",
      "Epoch 93/500\n",
      "303/303 - 0s - loss: 3.7560 - mae: 1.2355 - val_loss: 12.3426 - val_mae: 2.5641\n",
      "Epoch 94/500\n",
      "303/303 - 0s - loss: 3.9384 - mae: 1.2546 - val_loss: 15.7506 - val_mae: 2.8982\n",
      "Epoch 95/500\n",
      "303/303 - 0s - loss: 4.1068 - mae: 1.2718 - val_loss: 12.9709 - val_mae: 2.5668\n",
      "Epoch 96/500\n",
      "303/303 - 0s - loss: 3.7315 - mae: 1.2571 - val_loss: 10.5938 - val_mae: 2.3296\n",
      "Epoch 97/500\n",
      "303/303 - 0s - loss: 3.9914 - mae: 1.2904 - val_loss: 12.2313 - val_mae: 2.5380\n",
      "Epoch 98/500\n",
      "303/303 - 0s - loss: 3.7286 - mae: 1.2541 - val_loss: 11.9628 - val_mae: 2.4419\n",
      "Epoch 99/500\n",
      "303/303 - 0s - loss: 3.8687 - mae: 1.2481 - val_loss: 11.8705 - val_mae: 2.4792\n",
      "Epoch 100/500\n",
      "303/303 - 0s - loss: 3.7555 - mae: 1.2448 - val_loss: 11.9613 - val_mae: 2.4904\n",
      "Epoch 101/500\n",
      "303/303 - 0s - loss: 3.7896 - mae: 1.2358 - val_loss: 11.4326 - val_mae: 2.4077\n",
      "Epoch 102/500\n",
      "303/303 - 0s - loss: 3.7763 - mae: 1.2323 - val_loss: 12.1102 - val_mae: 2.4732\n",
      "Epoch 103/500\n",
      "303/303 - 0s - loss: 3.7047 - mae: 1.2217 - val_loss: 11.6991 - val_mae: 2.4367\n",
      "Epoch 104/500\n",
      "303/303 - 0s - loss: 3.8640 - mae: 1.2413 - val_loss: 11.8704 - val_mae: 2.4978\n",
      "Epoch 105/500\n",
      "303/303 - 0s - loss: 3.5607 - mae: 1.1762 - val_loss: 11.0339 - val_mae: 2.3482\n",
      "Epoch 106/500\n",
      "303/303 - 0s - loss: 3.4753 - mae: 1.1977 - val_loss: 11.4384 - val_mae: 2.4108\n",
      "Epoch 107/500\n",
      "303/303 - 0s - loss: 3.4411 - mae: 1.1849 - val_loss: 11.2908 - val_mae: 2.4367\n",
      "Epoch 108/500\n",
      "303/303 - 0s - loss: 3.7672 - mae: 1.2367 - val_loss: 11.3344 - val_mae: 2.4271\n",
      "Epoch 109/500\n",
      "303/303 - 0s - loss: 3.7101 - mae: 1.1925 - val_loss: 11.5566 - val_mae: 2.4414\n",
      "Epoch 110/500\n",
      "303/303 - 0s - loss: 3.5373 - mae: 1.1638 - val_loss: 11.8222 - val_mae: 2.5095\n",
      "Epoch 111/500\n",
      "303/303 - 0s - loss: 3.3613 - mae: 1.2104 - val_loss: 11.7431 - val_mae: 2.4890\n",
      "Epoch 112/500\n",
      "303/303 - 0s - loss: 3.3800 - mae: 1.1632 - val_loss: 12.9163 - val_mae: 2.7062\n",
      "Epoch 113/500\n",
      "303/303 - 0s - loss: 3.2385 - mae: 1.2097 - val_loss: 11.1586 - val_mae: 2.4116\n",
      "Epoch 114/500\n",
      "303/303 - 0s - loss: 3.4359 - mae: 1.1404 - val_loss: 11.8663 - val_mae: 2.4621\n",
      "Epoch 115/500\n",
      "303/303 - 0s - loss: 3.4937 - mae: 1.1677 - val_loss: 13.0887 - val_mae: 2.5869\n",
      "Epoch 116/500\n",
      "303/303 - 0s - loss: 3.3752 - mae: 1.2045 - val_loss: 11.5564 - val_mae: 2.4366\n",
      "Epoch 117/500\n",
      "303/303 - 0s - loss: 3.1994 - mae: 1.1821 - val_loss: 12.1589 - val_mae: 2.5253\n",
      "Epoch 118/500\n",
      "303/303 - 0s - loss: 3.2041 - mae: 1.1895 - val_loss: 11.0408 - val_mae: 2.4182\n",
      "Epoch 119/500\n",
      "303/303 - 0s - loss: 3.2888 - mae: 1.1775 - val_loss: 13.3023 - val_mae: 2.6509\n",
      "Epoch 120/500\n",
      "303/303 - 0s - loss: 3.1381 - mae: 1.1528 - val_loss: 13.3167 - val_mae: 2.6228\n",
      "Epoch 121/500\n",
      "303/303 - 0s - loss: 3.0098 - mae: 1.0924 - val_loss: 12.9291 - val_mae: 2.5332\n",
      "Epoch 122/500\n",
      "303/303 - 0s - loss: 3.0967 - mae: 1.1671 - val_loss: 15.3728 - val_mae: 2.8528\n",
      "Epoch 123/500\n",
      "303/303 - 0s - loss: 3.1688 - mae: 1.1695 - val_loss: 13.2796 - val_mae: 2.7044\n",
      "Epoch 124/500\n",
      "303/303 - 0s - loss: 3.0183 - mae: 1.1794 - val_loss: 12.2721 - val_mae: 2.5114\n",
      "Epoch 125/500\n",
      "303/303 - 0s - loss: 3.0508 - mae: 1.0852 - val_loss: 14.5074 - val_mae: 2.8697\n",
      "Epoch 126/500\n",
      "303/303 - 0s - loss: 3.1043 - mae: 1.1471 - val_loss: 11.4394 - val_mae: 2.4824\n",
      "Epoch 127/500\n",
      "303/303 - 0s - loss: 2.9614 - mae: 1.2034 - val_loss: 11.0585 - val_mae: 2.3616\n",
      "Epoch 128/500\n",
      "303/303 - 0s - loss: 3.0891 - mae: 1.1422 - val_loss: 11.9437 - val_mae: 2.5082\n",
      "Epoch 129/500\n",
      "303/303 - 0s - loss: 3.2001 - mae: 1.1264 - val_loss: 11.7061 - val_mae: 2.4623\n",
      "Epoch 130/500\n",
      "303/303 - 0s - loss: 3.0059 - mae: 1.1257 - val_loss: 11.2957 - val_mae: 2.3981\n",
      "Epoch 131/500\n",
      "303/303 - 0s - loss: 3.4687 - mae: 1.1390 - val_loss: 10.9233 - val_mae: 2.4072\n",
      "Epoch 132/500\n",
      "303/303 - 0s - loss: 2.8840 - mae: 1.0906 - val_loss: 12.1903 - val_mae: 2.5535\n",
      "Epoch 133/500\n",
      "303/303 - 0s - loss: 2.9618 - mae: 1.1121 - val_loss: 11.4775 - val_mae: 2.4096\n",
      "Epoch 134/500\n",
      "303/303 - 0s - loss: 2.9829 - mae: 1.1285 - val_loss: 11.5446 - val_mae: 2.4613\n",
      "Epoch 135/500\n",
      "303/303 - 0s - loss: 3.0476 - mae: 1.1234 - val_loss: 11.1306 - val_mae: 2.4150\n",
      "Epoch 136/500\n",
      "303/303 - 0s - loss: 2.8380 - mae: 1.1066 - val_loss: 12.3151 - val_mae: 2.5741\n",
      "Epoch 137/500\n",
      "303/303 - 0s - loss: 2.8495 - mae: 1.0783 - val_loss: 11.3878 - val_mae: 2.4151\n",
      "Epoch 138/500\n",
      "303/303 - 0s - loss: 2.8401 - mae: 1.0773 - val_loss: 11.2784 - val_mae: 2.4066\n",
      "Epoch 139/500\n",
      "303/303 - 0s - loss: 2.7704 - mae: 1.0620 - val_loss: 13.1425 - val_mae: 2.6434\n",
      "Epoch 140/500\n",
      "303/303 - 0s - loss: 2.8690 - mae: 1.0775 - val_loss: 11.2464 - val_mae: 2.4753\n",
      "Epoch 141/500\n",
      "303/303 - 0s - loss: 2.8590 - mae: 1.1165 - val_loss: 10.6771 - val_mae: 2.3909\n",
      "Epoch 142/500\n",
      "303/303 - 0s - loss: 2.6369 - mae: 1.0862 - val_loss: 10.2292 - val_mae: 2.2840\n",
      "Epoch 143/500\n",
      "303/303 - 0s - loss: 2.5359 - mae: 0.9976 - val_loss: 11.8619 - val_mae: 2.5390\n",
      "Epoch 144/500\n",
      "303/303 - 0s - loss: 2.9049 - mae: 1.1311 - val_loss: 11.7361 - val_mae: 2.4911\n",
      "Epoch 145/500\n",
      "303/303 - 0s - loss: 2.7816 - mae: 1.0707 - val_loss: 11.3533 - val_mae: 2.4596\n",
      "Epoch 146/500\n",
      "303/303 - 0s - loss: 2.7897 - mae: 1.1223 - val_loss: 12.0883 - val_mae: 2.5042\n",
      "Epoch 147/500\n",
      "303/303 - 0s - loss: 2.6413 - mae: 1.0516 - val_loss: 13.8771 - val_mae: 2.7415\n",
      "Epoch 148/500\n",
      "303/303 - 0s - loss: 2.6115 - mae: 1.0553 - val_loss: 12.6806 - val_mae: 2.6739\n",
      "Epoch 149/500\n",
      "303/303 - 0s - loss: 2.6041 - mae: 1.0658 - val_loss: 11.9559 - val_mae: 2.5361\n",
      "Epoch 150/500\n",
      "303/303 - 0s - loss: 2.4047 - mae: 1.0450 - val_loss: 12.7403 - val_mae: 2.6258\n",
      "Epoch 151/500\n",
      "303/303 - 0s - loss: 2.6027 - mae: 1.0518 - val_loss: 11.5983 - val_mae: 2.4574\n",
      "Epoch 152/500\n",
      "303/303 - 0s - loss: 2.7781 - mae: 1.0759 - val_loss: 11.7007 - val_mae: 2.5231\n",
      "Epoch 153/500\n",
      "303/303 - 0s - loss: 2.3842 - mae: 1.0341 - val_loss: 12.3343 - val_mae: 2.5334\n",
      "Epoch 154/500\n",
      "303/303 - 0s - loss: 2.6591 - mae: 1.0767 - val_loss: 11.3175 - val_mae: 2.4522\n",
      "Epoch 155/500\n",
      "303/303 - 0s - loss: 2.6100 - mae: 1.0969 - val_loss: 11.7604 - val_mae: 2.4856\n",
      "Epoch 156/500\n",
      "303/303 - 0s - loss: 2.6000 - mae: 1.0560 - val_loss: 13.2152 - val_mae: 2.6801\n",
      "Epoch 157/500\n",
      "303/303 - 0s - loss: 2.4688 - mae: 1.0473 - val_loss: 11.5074 - val_mae: 2.5095\n",
      "Epoch 158/500\n",
      "303/303 - 0s - loss: 2.4000 - mae: 1.0447 - val_loss: 11.8349 - val_mae: 2.5045\n",
      "Epoch 159/500\n",
      "303/303 - 0s - loss: 2.7289 - mae: 1.0584 - val_loss: 11.6549 - val_mae: 2.4656\n",
      "Epoch 160/500\n",
      "303/303 - 0s - loss: 2.7174 - mae: 1.0717 - val_loss: 11.2627 - val_mae: 2.5044\n",
      "Epoch 161/500\n",
      "303/303 - 0s - loss: 2.4962 - mae: 1.0301 - val_loss: 13.3071 - val_mae: 2.6887\n",
      "Epoch 162/500\n",
      "303/303 - 0s - loss: 2.4807 - mae: 1.0827 - val_loss: 12.2977 - val_mae: 2.5664\n",
      "Epoch 163/500\n",
      "303/303 - 0s - loss: 2.4642 - mae: 1.0388 - val_loss: 12.9763 - val_mae: 2.5862\n",
      "Epoch 164/500\n",
      "303/303 - 0s - loss: 2.3584 - mae: 1.0405 - val_loss: 11.1071 - val_mae: 2.4246\n",
      "Epoch 165/500\n",
      "303/303 - 0s - loss: 2.4189 - mae: 1.0341 - val_loss: 11.8892 - val_mae: 2.4732\n",
      "Epoch 166/500\n",
      "303/303 - 0s - loss: 2.4634 - mae: 1.0580 - val_loss: 11.8102 - val_mae: 2.4712\n",
      "Epoch 167/500\n",
      "303/303 - 0s - loss: 2.3992 - mae: 0.9974 - val_loss: 12.0261 - val_mae: 2.4854\n",
      "Epoch 168/500\n",
      "303/303 - 0s - loss: 2.2702 - mae: 0.9640 - val_loss: 12.1049 - val_mae: 2.4727\n",
      "Epoch 169/500\n",
      "303/303 - 0s - loss: 2.4575 - mae: 1.0221 - val_loss: 11.4740 - val_mae: 2.4459\n",
      "Epoch 170/500\n",
      "303/303 - 0s - loss: 2.3389 - mae: 1.0129 - val_loss: 13.1555 - val_mae: 2.6175\n",
      "Epoch 171/500\n",
      "303/303 - 0s - loss: 2.3161 - mae: 1.0429 - val_loss: 13.9620 - val_mae: 2.7569\n",
      "Epoch 172/500\n",
      "303/303 - 0s - loss: 2.5299 - mae: 1.0385 - val_loss: 12.6556 - val_mae: 2.5847\n",
      "Epoch 173/500\n",
      "303/303 - 0s - loss: 2.2781 - mae: 1.0313 - val_loss: 11.3887 - val_mae: 2.4858\n",
      "Epoch 174/500\n",
      "303/303 - 0s - loss: 2.3006 - mae: 1.0032 - val_loss: 12.1782 - val_mae: 2.5551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/500\n",
      "303/303 - 0s - loss: 2.2105 - mae: 1.0175 - val_loss: 13.0614 - val_mae: 2.6664\n",
      "Epoch 176/500\n",
      "303/303 - 0s - loss: 2.4682 - mae: 1.0427 - val_loss: 12.6004 - val_mae: 2.5860\n",
      "Epoch 177/500\n",
      "303/303 - 0s - loss: 2.3631 - mae: 0.9942 - val_loss: 11.5286 - val_mae: 2.4798\n",
      "Epoch 178/500\n",
      "303/303 - 0s - loss: 2.5257 - mae: 1.0123 - val_loss: 11.8140 - val_mae: 2.4938\n",
      "Epoch 179/500\n",
      "303/303 - 0s - loss: 2.2418 - mae: 1.0301 - val_loss: 11.1410 - val_mae: 2.4297\n",
      "Epoch 180/500\n",
      "303/303 - 0s - loss: 2.2775 - mae: 1.0368 - val_loss: 11.9095 - val_mae: 2.5369\n",
      "Epoch 181/500\n",
      "303/303 - 0s - loss: 2.1780 - mae: 1.0168 - val_loss: 12.1325 - val_mae: 2.5184\n",
      "Epoch 182/500\n",
      "303/303 - 0s - loss: 1.9498 - mae: 0.9653 - val_loss: 12.2016 - val_mae: 2.5525\n",
      "Epoch 183/500\n",
      "303/303 - 0s - loss: 2.2213 - mae: 1.0338 - val_loss: 12.3525 - val_mae: 2.5705\n",
      "Epoch 184/500\n",
      "303/303 - 0s - loss: 2.2130 - mae: 1.0053 - val_loss: 11.6786 - val_mae: 2.4569\n",
      "Epoch 185/500\n",
      "303/303 - 0s - loss: 2.2412 - mae: 1.0337 - val_loss: 11.2274 - val_mae: 2.4339\n",
      "Epoch 186/500\n",
      "303/303 - 0s - loss: 2.3324 - mae: 1.0102 - val_loss: 11.1974 - val_mae: 2.4007\n",
      "Epoch 187/500\n",
      "303/303 - 0s - loss: 2.2154 - mae: 1.0443 - val_loss: 11.4474 - val_mae: 2.5048\n",
      "Epoch 188/500\n",
      "303/303 - 0s - loss: 2.3244 - mae: 0.9864 - val_loss: 11.2004 - val_mae: 2.4016\n",
      "Epoch 189/500\n",
      "303/303 - 0s - loss: 2.1262 - mae: 1.0088 - val_loss: 12.7300 - val_mae: 2.5835\n",
      "Epoch 190/500\n",
      "303/303 - 0s - loss: 2.3298 - mae: 1.0026 - val_loss: 11.4332 - val_mae: 2.4639\n",
      "Epoch 191/500\n",
      "303/303 - 0s - loss: 2.1274 - mae: 0.9778 - val_loss: 11.3787 - val_mae: 2.4632\n",
      "Epoch 192/500\n",
      "303/303 - 0s - loss: 2.0674 - mae: 1.0222 - val_loss: 11.5210 - val_mae: 2.4913\n",
      "Epoch 193/500\n",
      "303/303 - 0s - loss: 2.2425 - mae: 1.0076 - val_loss: 12.4193 - val_mae: 2.6024\n",
      "Epoch 194/500\n",
      "303/303 - 0s - loss: 2.0756 - mae: 0.9527 - val_loss: 11.5520 - val_mae: 2.4329\n",
      "Epoch 195/500\n",
      "303/303 - 0s - loss: 2.0442 - mae: 1.0009 - val_loss: 11.9967 - val_mae: 2.4963\n",
      "Epoch 196/500\n",
      "303/303 - 0s - loss: 2.0294 - mae: 0.9740 - val_loss: 11.7237 - val_mae: 2.4729\n",
      "Epoch 197/500\n",
      "303/303 - 0s - loss: 2.0137 - mae: 0.9407 - val_loss: 12.8468 - val_mae: 2.5856\n",
      "Epoch 198/500\n",
      "303/303 - 0s - loss: 1.9382 - mae: 0.9653 - val_loss: 12.6116 - val_mae: 2.5807\n",
      "Epoch 199/500\n",
      "303/303 - 0s - loss: 1.9936 - mae: 0.9491 - val_loss: 13.0724 - val_mae: 2.7218\n",
      "Epoch 200/500\n",
      "303/303 - 0s - loss: 2.0992 - mae: 0.9774 - val_loss: 11.2543 - val_mae: 2.4140\n",
      "Epoch 201/500\n",
      "303/303 - 0s - loss: 2.1165 - mae: 1.0258 - val_loss: 12.3131 - val_mae: 2.5615\n",
      "Epoch 202/500\n",
      "303/303 - 0s - loss: 2.0361 - mae: 0.9709 - val_loss: 11.9368 - val_mae: 2.5440\n",
      "Epoch 203/500\n",
      "303/303 - 0s - loss: 1.9402 - mae: 0.9543 - val_loss: 13.7594 - val_mae: 2.7617\n",
      "Epoch 204/500\n",
      "303/303 - 0s - loss: 1.9006 - mae: 0.9587 - val_loss: 12.8844 - val_mae: 2.5998\n",
      "Epoch 205/500\n",
      "303/303 - 0s - loss: 2.0226 - mae: 0.9914 - val_loss: 14.2546 - val_mae: 2.7629\n",
      "Epoch 206/500\n",
      "303/303 - 0s - loss: 1.9039 - mae: 0.9543 - val_loss: 12.6988 - val_mae: 2.6748\n",
      "Epoch 207/500\n",
      "303/303 - 0s - loss: 2.0776 - mae: 0.9550 - val_loss: 12.1372 - val_mae: 2.5066\n",
      "Epoch 208/500\n",
      "303/303 - 0s - loss: 1.9969 - mae: 0.9662 - val_loss: 12.8237 - val_mae: 2.5363\n",
      "Epoch 209/500\n",
      "303/303 - 0s - loss: 2.0458 - mae: 0.9888 - val_loss: 11.8560 - val_mae: 2.5144\n",
      "Epoch 210/500\n",
      "303/303 - 0s - loss: 1.9412 - mae: 0.9483 - val_loss: 13.4350 - val_mae: 2.6509\n",
      "Epoch 211/500\n",
      "303/303 - 0s - loss: 1.9464 - mae: 0.9768 - val_loss: 11.9505 - val_mae: 2.5268\n",
      "Epoch 212/500\n",
      "303/303 - 0s - loss: 2.0058 - mae: 0.9917 - val_loss: 13.5090 - val_mae: 2.6870\n",
      "Epoch 213/500\n",
      "303/303 - 0s - loss: 1.9220 - mae: 0.9476 - val_loss: 11.8560 - val_mae: 2.4528\n",
      "Epoch 214/500\n",
      "303/303 - 0s - loss: 1.9003 - mae: 0.9444 - val_loss: 12.7534 - val_mae: 2.6566\n",
      "Epoch 215/500\n",
      "303/303 - 0s - loss: 2.1513 - mae: 0.9130 - val_loss: 12.9360 - val_mae: 2.6818\n",
      "Epoch 216/500\n",
      "303/303 - 0s - loss: 1.8415 - mae: 0.9491 - val_loss: 13.5921 - val_mae: 2.7002\n",
      "Epoch 217/500\n",
      "303/303 - 0s - loss: 2.0025 - mae: 0.9703 - val_loss: 12.3203 - val_mae: 2.5310\n",
      "Epoch 218/500\n",
      "303/303 - 0s - loss: 1.9121 - mae: 0.9551 - val_loss: 12.3367 - val_mae: 2.4899\n",
      "Epoch 219/500\n",
      "303/303 - 0s - loss: 1.8914 - mae: 0.9475 - val_loss: 15.4564 - val_mae: 2.9041\n",
      "Epoch 220/500\n",
      "303/303 - 0s - loss: 1.8740 - mae: 0.9506 - val_loss: 12.2743 - val_mae: 2.5216\n",
      "Epoch 221/500\n",
      "303/303 - 0s - loss: 1.6969 - mae: 0.9222 - val_loss: 14.6600 - val_mae: 2.6711\n",
      "Epoch 222/500\n",
      "303/303 - 0s - loss: 1.9378 - mae: 0.9765 - val_loss: 11.3089 - val_mae: 2.4120\n",
      "Epoch 223/500\n",
      "303/303 - 0s - loss: 1.8814 - mae: 0.9478 - val_loss: 12.0861 - val_mae: 2.4772\n",
      "Epoch 224/500\n",
      "303/303 - 0s - loss: 1.8944 - mae: 0.9336 - val_loss: 12.5509 - val_mae: 2.5995\n",
      "Epoch 225/500\n",
      "303/303 - 0s - loss: 1.7747 - mae: 0.8827 - val_loss: 13.9562 - val_mae: 2.7327\n",
      "Epoch 226/500\n",
      "303/303 - 0s - loss: 1.7946 - mae: 0.9233 - val_loss: 12.8620 - val_mae: 2.6075\n",
      "Epoch 227/500\n",
      "303/303 - 0s - loss: 1.8413 - mae: 0.9154 - val_loss: 12.6390 - val_mae: 2.6055\n",
      "Epoch 228/500\n",
      "303/303 - 0s - loss: 1.7569 - mae: 0.9549 - val_loss: 13.0040 - val_mae: 2.6524\n",
      "Epoch 229/500\n",
      "303/303 - 0s - loss: 1.7447 - mae: 0.8761 - val_loss: 14.1983 - val_mae: 2.6969\n",
      "Epoch 230/500\n",
      "303/303 - 0s - loss: 1.9318 - mae: 0.9345 - val_loss: 11.7197 - val_mae: 2.4208\n",
      "Epoch 231/500\n",
      "303/303 - 0s - loss: 1.8654 - mae: 0.9028 - val_loss: 12.3926 - val_mae: 2.5480\n",
      "Epoch 232/500\n",
      "303/303 - 0s - loss: 1.7667 - mae: 0.9242 - val_loss: 12.5001 - val_mae: 2.5524\n",
      "Epoch 233/500\n",
      "303/303 - 0s - loss: 1.8175 - mae: 0.9553 - val_loss: 12.8139 - val_mae: 2.5769\n",
      "Epoch 234/500\n",
      "303/303 - 0s - loss: 1.6210 - mae: 0.9043 - val_loss: 12.1175 - val_mae: 2.5431\n",
      "Epoch 235/500\n",
      "303/303 - 0s - loss: 1.6987 - mae: 0.9130 - val_loss: 12.4005 - val_mae: 2.5429\n",
      "Epoch 236/500\n",
      "303/303 - 0s - loss: 1.7005 - mae: 0.9462 - val_loss: 13.4380 - val_mae: 2.6511\n",
      "Epoch 237/500\n",
      "303/303 - 0s - loss: 1.8981 - mae: 0.9728 - val_loss: 12.5715 - val_mae: 2.4971\n",
      "Epoch 238/500\n",
      "303/303 - 0s - loss: 1.4765 - mae: 0.8629 - val_loss: 12.8914 - val_mae: 2.5933\n",
      "Epoch 239/500\n",
      "303/303 - 0s - loss: 1.6623 - mae: 0.8743 - val_loss: 12.5682 - val_mae: 2.5475\n",
      "Epoch 240/500\n",
      "303/303 - 0s - loss: 1.8360 - mae: 0.9362 - val_loss: 11.7121 - val_mae: 2.4840\n",
      "Epoch 241/500\n",
      "303/303 - 0s - loss: 1.7061 - mae: 0.8999 - val_loss: 13.3007 - val_mae: 2.6167\n",
      "Epoch 242/500\n",
      "303/303 - 0s - loss: 1.7222 - mae: 0.8875 - val_loss: 12.2858 - val_mae: 2.5522\n",
      "Epoch 243/500\n",
      "303/303 - 0s - loss: 1.5910 - mae: 0.9081 - val_loss: 12.4783 - val_mae: 2.5184\n",
      "Epoch 244/500\n",
      "303/303 - 0s - loss: 1.6649 - mae: 0.9312 - val_loss: 13.4049 - val_mae: 2.7305\n",
      "Epoch 245/500\n",
      "303/303 - 0s - loss: 1.7274 - mae: 0.9195 - val_loss: 11.5967 - val_mae: 2.4326\n",
      "Epoch 246/500\n",
      "303/303 - 0s - loss: 1.4673 - mae: 0.8806 - val_loss: 14.4237 - val_mae: 2.7376\n",
      "Epoch 247/500\n",
      "303/303 - 0s - loss: 1.7077 - mae: 0.9152 - val_loss: 14.2977 - val_mae: 2.6997\n",
      "Epoch 248/500\n",
      "303/303 - 0s - loss: 1.6422 - mae: 0.8964 - val_loss: 13.1719 - val_mae: 2.6366\n",
      "Epoch 249/500\n",
      "303/303 - 0s - loss: 1.6819 - mae: 0.9179 - val_loss: 11.8094 - val_mae: 2.4414\n",
      "Epoch 250/500\n",
      "303/303 - 0s - loss: 1.6268 - mae: 0.9454 - val_loss: 12.3679 - val_mae: 2.5573\n",
      "Epoch 251/500\n",
      "303/303 - 0s - loss: 1.6476 - mae: 0.9149 - val_loss: 12.6199 - val_mae: 2.6094\n",
      "Epoch 252/500\n",
      "303/303 - 0s - loss: 1.4814 - mae: 0.8969 - val_loss: 14.4999 - val_mae: 2.7647\n",
      "Epoch 253/500\n",
      "303/303 - 0s - loss: 1.4387 - mae: 0.8720 - val_loss: 13.4951 - val_mae: 2.6662\n",
      "Epoch 254/500\n",
      "303/303 - 0s - loss: 1.6386 - mae: 0.8999 - val_loss: 13.8444 - val_mae: 2.6669\n",
      "Epoch 255/500\n",
      "303/303 - 0s - loss: 1.5502 - mae: 0.9009 - val_loss: 13.8782 - val_mae: 2.6894\n",
      "Epoch 256/500\n",
      "303/303 - 0s - loss: 1.6739 - mae: 0.9026 - val_loss: 12.7957 - val_mae: 2.6074\n",
      "Epoch 257/500\n",
      "303/303 - 0s - loss: 1.5956 - mae: 0.8739 - val_loss: 13.0191 - val_mae: 2.5504\n",
      "Epoch 258/500\n",
      "303/303 - 0s - loss: 1.6060 - mae: 0.9063 - val_loss: 13.5790 - val_mae: 2.6654\n",
      "Epoch 259/500\n",
      "303/303 - 0s - loss: 1.6678 - mae: 0.9185 - val_loss: 12.3789 - val_mae: 2.5602\n",
      "Epoch 260/500\n",
      "303/303 - 0s - loss: 1.4832 - mae: 0.8451 - val_loss: 13.6336 - val_mae: 2.7122\n",
      "Epoch 261/500\n",
      "303/303 - 0s - loss: 1.4600 - mae: 0.8475 - val_loss: 14.7147 - val_mae: 2.8519\n",
      "Epoch 262/500\n",
      "303/303 - 0s - loss: 1.6105 - mae: 0.9246 - val_loss: 13.0755 - val_mae: 2.6491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 263/500\n",
      "303/303 - 0s - loss: 1.5462 - mae: 0.9014 - val_loss: 13.5071 - val_mae: 2.6902\n",
      "Epoch 264/500\n",
      "303/303 - 0s - loss: 1.4871 - mae: 0.8598 - val_loss: 12.9560 - val_mae: 2.6227\n",
      "Epoch 265/500\n",
      "303/303 - 0s - loss: 1.5236 - mae: 0.8574 - val_loss: 13.6695 - val_mae: 2.7078\n",
      "Epoch 266/500\n",
      "303/303 - 0s - loss: 1.5075 - mae: 0.9037 - val_loss: 11.9856 - val_mae: 2.5736\n",
      "Epoch 267/500\n",
      "303/303 - 0s - loss: 1.5990 - mae: 0.8699 - val_loss: 12.9913 - val_mae: 2.5809\n",
      "Epoch 268/500\n",
      "303/303 - 0s - loss: 1.4962 - mae: 0.8703 - val_loss: 12.7810 - val_mae: 2.6155\n",
      "Epoch 269/500\n",
      "303/303 - 0s - loss: 1.6257 - mae: 0.8676 - val_loss: 12.9495 - val_mae: 2.6342\n",
      "Epoch 270/500\n",
      "303/303 - 0s - loss: 1.4191 - mae: 0.8570 - val_loss: 12.6863 - val_mae: 2.5538\n",
      "Epoch 271/500\n",
      "303/303 - 0s - loss: 1.4950 - mae: 0.8674 - val_loss: 15.2789 - val_mae: 2.9081\n",
      "Epoch 272/500\n",
      "303/303 - 0s - loss: 1.4011 - mae: 0.8057 - val_loss: 12.5956 - val_mae: 2.5405\n",
      "Epoch 273/500\n",
      "303/303 - 0s - loss: 1.5199 - mae: 0.8658 - val_loss: 13.0934 - val_mae: 2.6337\n",
      "Epoch 274/500\n",
      "303/303 - 0s - loss: 1.5467 - mae: 0.8672 - val_loss: 15.6863 - val_mae: 2.9520\n",
      "Epoch 275/500\n",
      "303/303 - 0s - loss: 1.4651 - mae: 0.8990 - val_loss: 12.9319 - val_mae: 2.6113\n",
      "Epoch 276/500\n",
      "303/303 - 0s - loss: 1.4804 - mae: 0.8617 - val_loss: 13.0516 - val_mae: 2.5763\n",
      "Epoch 277/500\n",
      "303/303 - 0s - loss: 1.4857 - mae: 0.8783 - val_loss: 13.0884 - val_mae: 2.6200\n",
      "Epoch 278/500\n",
      "303/303 - 0s - loss: 1.4283 - mae: 0.8174 - val_loss: 12.1449 - val_mae: 2.4971\n",
      "Epoch 279/500\n",
      "303/303 - 0s - loss: 1.3269 - mae: 0.8567 - val_loss: 13.3072 - val_mae: 2.6341\n",
      "Epoch 280/500\n",
      "303/303 - 0s - loss: 1.4073 - mae: 0.8427 - val_loss: 14.5156 - val_mae: 2.7597\n",
      "Epoch 281/500\n",
      "303/303 - 0s - loss: 1.4088 - mae: 0.8184 - val_loss: 13.0882 - val_mae: 2.6220\n",
      "Epoch 282/500\n",
      "303/303 - 0s - loss: 1.4935 - mae: 0.8872 - val_loss: 12.2887 - val_mae: 2.5575\n",
      "Epoch 283/500\n",
      "303/303 - 0s - loss: 1.3309 - mae: 0.8300 - val_loss: 15.3040 - val_mae: 2.9465\n",
      "Epoch 284/500\n",
      "303/303 - 0s - loss: 1.2810 - mae: 0.8312 - val_loss: 14.5025 - val_mae: 2.7970\n",
      "Epoch 285/500\n",
      "303/303 - 0s - loss: 1.4477 - mae: 0.8515 - val_loss: 14.7003 - val_mae: 2.8644\n",
      "Epoch 286/500\n",
      "303/303 - 0s - loss: 1.2141 - mae: 0.7944 - val_loss: 13.5489 - val_mae: 2.6873\n",
      "Epoch 287/500\n",
      "303/303 - 0s - loss: 1.5219 - mae: 0.8639 - val_loss: 13.7932 - val_mae: 2.7551\n",
      "Epoch 288/500\n",
      "303/303 - 0s - loss: 1.4036 - mae: 0.8544 - val_loss: 13.2279 - val_mae: 2.6774\n",
      "Epoch 289/500\n",
      "303/303 - 0s - loss: 1.2880 - mae: 0.8351 - val_loss: 14.4848 - val_mae: 2.7772\n",
      "Epoch 290/500\n",
      "303/303 - 0s - loss: 1.2928 - mae: 0.8625 - val_loss: 12.3448 - val_mae: 2.6074\n",
      "Epoch 291/500\n",
      "303/303 - 0s - loss: 1.2444 - mae: 0.8348 - val_loss: 11.8590 - val_mae: 2.5567\n",
      "Epoch 292/500\n",
      "303/303 - 0s - loss: 1.2792 - mae: 0.8333 - val_loss: 13.6983 - val_mae: 2.7285\n",
      "Epoch 293/500\n",
      "303/303 - 0s - loss: 1.2650 - mae: 0.8431 - val_loss: 12.7038 - val_mae: 2.6707\n",
      "Epoch 294/500\n",
      "303/303 - 0s - loss: 1.3096 - mae: 0.8413 - val_loss: 12.9035 - val_mae: 2.5742\n",
      "Epoch 295/500\n",
      "303/303 - 0s - loss: 1.3503 - mae: 0.8542 - val_loss: 12.1485 - val_mae: 2.5681\n",
      "Epoch 296/500\n",
      "303/303 - 0s - loss: 1.2097 - mae: 0.8290 - val_loss: 12.5700 - val_mae: 2.5611\n",
      "Epoch 297/500\n",
      "303/303 - 0s - loss: 1.2692 - mae: 0.7931 - val_loss: 14.6418 - val_mae: 2.8211\n",
      "Epoch 298/500\n",
      "303/303 - 0s - loss: 1.3694 - mae: 0.8139 - val_loss: 14.0502 - val_mae: 2.7682\n",
      "Epoch 299/500\n",
      "303/303 - 0s - loss: 1.3084 - mae: 0.8362 - val_loss: 12.6304 - val_mae: 2.6347\n",
      "Epoch 300/500\n",
      "303/303 - 0s - loss: 1.2336 - mae: 0.8317 - val_loss: 12.8693 - val_mae: 2.6286\n",
      "Epoch 301/500\n",
      "303/303 - 0s - loss: 1.3764 - mae: 0.8507 - val_loss: 14.2526 - val_mae: 2.7490\n",
      "Epoch 302/500\n",
      "303/303 - 0s - loss: 1.3917 - mae: 0.8303 - val_loss: 13.2325 - val_mae: 2.7145\n",
      "Epoch 303/500\n",
      "303/303 - 0s - loss: 1.2593 - mae: 0.8082 - val_loss: 12.9659 - val_mae: 2.6774\n",
      "Epoch 304/500\n",
      "303/303 - 0s - loss: 1.2008 - mae: 0.8101 - val_loss: 14.3232 - val_mae: 2.8064\n",
      "Epoch 305/500\n",
      "303/303 - 0s - loss: 1.2023 - mae: 0.8318 - val_loss: 13.2713 - val_mae: 2.6835\n",
      "Epoch 306/500\n",
      "303/303 - 0s - loss: 1.1812 - mae: 0.8039 - val_loss: 13.5888 - val_mae: 2.6871\n",
      "Epoch 307/500\n",
      "303/303 - 0s - loss: 1.3192 - mae: 0.8270 - val_loss: 13.0355 - val_mae: 2.6281\n",
      "Epoch 308/500\n",
      "303/303 - 0s - loss: 1.3108 - mae: 0.8335 - val_loss: 13.4674 - val_mae: 2.6829\n",
      "Epoch 309/500\n",
      "303/303 - 0s - loss: 1.1000 - mae: 0.7702 - val_loss: 12.6145 - val_mae: 2.6080\n",
      "Epoch 310/500\n",
      "303/303 - 0s - loss: 1.3379 - mae: 0.7996 - val_loss: 12.8315 - val_mae: 2.6280\n",
      "Epoch 311/500\n",
      "303/303 - 0s - loss: 1.3195 - mae: 0.8069 - val_loss: 13.0645 - val_mae: 2.6149\n",
      "Epoch 312/500\n",
      "303/303 - 0s - loss: 1.2254 - mae: 0.8099 - val_loss: 12.0284 - val_mae: 2.6088\n",
      "Epoch 313/500\n",
      "303/303 - 0s - loss: 1.1624 - mae: 0.7526 - val_loss: 12.7048 - val_mae: 2.7479\n",
      "Epoch 314/500\n",
      "303/303 - 0s - loss: 1.3275 - mae: 0.8032 - val_loss: 12.2880 - val_mae: 2.5564\n",
      "Epoch 315/500\n",
      "303/303 - 0s - loss: 1.2283 - mae: 0.8232 - val_loss: 14.7916 - val_mae: 2.9072\n",
      "Epoch 316/500\n",
      "303/303 - 0s - loss: 1.2305 - mae: 0.7949 - val_loss: 12.1955 - val_mae: 2.5929\n",
      "Epoch 317/500\n",
      "303/303 - 0s - loss: 1.2042 - mae: 0.8102 - val_loss: 12.4408 - val_mae: 2.5835\n",
      "Epoch 318/500\n",
      "303/303 - 0s - loss: 1.1918 - mae: 0.7902 - val_loss: 12.0866 - val_mae: 2.6338\n",
      "Epoch 319/500\n",
      "303/303 - 0s - loss: 1.1920 - mae: 0.8013 - val_loss: 12.8367 - val_mae: 2.6364\n",
      "Epoch 320/500\n",
      "303/303 - 0s - loss: 1.1141 - mae: 0.8012 - val_loss: 12.8420 - val_mae: 2.6129\n",
      "Epoch 321/500\n",
      "303/303 - 0s - loss: 1.2092 - mae: 0.8050 - val_loss: 12.3811 - val_mae: 2.5969\n",
      "Epoch 322/500\n",
      "303/303 - 0s - loss: 1.3414 - mae: 0.8338 - val_loss: 13.6548 - val_mae: 2.7184\n",
      "Epoch 323/500\n",
      "303/303 - 0s - loss: 1.2103 - mae: 0.8059 - val_loss: 12.5989 - val_mae: 2.6134\n",
      "Epoch 324/500\n",
      "303/303 - 0s - loss: 1.2454 - mae: 0.7866 - val_loss: 13.2760 - val_mae: 2.7190\n",
      "Epoch 325/500\n",
      "303/303 - 0s - loss: 1.3198 - mae: 0.8264 - val_loss: 13.1107 - val_mae: 2.6573\n",
      "Epoch 326/500\n",
      "303/303 - 0s - loss: 1.1562 - mae: 0.7717 - val_loss: 12.6414 - val_mae: 2.6480\n",
      "Epoch 327/500\n",
      "303/303 - 0s - loss: 1.0952 - mae: 0.7703 - val_loss: 13.9373 - val_mae: 2.7713\n",
      "Epoch 328/500\n",
      "303/303 - 0s - loss: 1.1904 - mae: 0.8141 - val_loss: 15.3417 - val_mae: 2.9019\n",
      "Epoch 329/500\n",
      "303/303 - 0s - loss: 1.1723 - mae: 0.8183 - val_loss: 12.7671 - val_mae: 2.6312\n",
      "Epoch 330/500\n",
      "303/303 - 0s - loss: 1.2761 - mae: 0.8379 - val_loss: 14.1116 - val_mae: 2.7630\n",
      "Epoch 331/500\n",
      "303/303 - 0s - loss: 1.1555 - mae: 0.7849 - val_loss: 12.8281 - val_mae: 2.5959\n",
      "Epoch 332/500\n",
      "303/303 - 0s - loss: 1.0785 - mae: 0.7606 - val_loss: 16.5310 - val_mae: 3.0719\n",
      "Epoch 333/500\n",
      "303/303 - 0s - loss: 1.1669 - mae: 0.7804 - val_loss: 13.4076 - val_mae: 2.7138\n",
      "Epoch 334/500\n",
      "303/303 - 0s - loss: 1.1630 - mae: 0.7685 - val_loss: 12.1131 - val_mae: 2.6134\n",
      "Epoch 335/500\n",
      "303/303 - 0s - loss: 1.1892 - mae: 0.7766 - val_loss: 13.3141 - val_mae: 2.7046\n",
      "Epoch 336/500\n",
      "303/303 - 0s - loss: 1.0924 - mae: 0.7817 - val_loss: 13.1488 - val_mae: 2.6969\n",
      "Epoch 337/500\n",
      "303/303 - 0s - loss: 1.2068 - mae: 0.7821 - val_loss: 15.2152 - val_mae: 2.8791\n",
      "Epoch 338/500\n",
      "303/303 - 0s - loss: 1.2527 - mae: 0.8322 - val_loss: 12.2629 - val_mae: 2.5977\n",
      "Epoch 339/500\n",
      "303/303 - 0s - loss: 1.0255 - mae: 0.7658 - val_loss: 13.9572 - val_mae: 2.6763\n",
      "Epoch 340/500\n",
      "303/303 - 0s - loss: 1.2148 - mae: 0.7741 - val_loss: 13.1571 - val_mae: 2.6478\n",
      "Epoch 341/500\n",
      "303/303 - 0s - loss: 1.1498 - mae: 0.7613 - val_loss: 12.8125 - val_mae: 2.6597\n",
      "Epoch 342/500\n",
      "303/303 - 0s - loss: 1.0572 - mae: 0.7372 - val_loss: 14.3642 - val_mae: 2.7759\n",
      "Epoch 343/500\n",
      "303/303 - 0s - loss: 1.1667 - mae: 0.8008 - val_loss: 13.0166 - val_mae: 2.6394\n",
      "Epoch 344/500\n",
      "303/303 - 0s - loss: 1.1068 - mae: 0.7620 - val_loss: 14.9674 - val_mae: 2.8708\n",
      "Epoch 345/500\n",
      "303/303 - 0s - loss: 1.1515 - mae: 0.8100 - val_loss: 12.7747 - val_mae: 2.5640\n",
      "Epoch 346/500\n",
      "303/303 - 0s - loss: 1.0751 - mae: 0.7695 - val_loss: 13.4283 - val_mae: 2.6846\n",
      "Epoch 347/500\n",
      "303/303 - 0s - loss: 1.0237 - mae: 0.7480 - val_loss: 12.7324 - val_mae: 2.5508\n",
      "Epoch 348/500\n",
      "303/303 - 0s - loss: 1.1653 - mae: 0.7820 - val_loss: 12.7942 - val_mae: 2.6394\n",
      "Epoch 349/500\n",
      "303/303 - 0s - loss: 1.0861 - mae: 0.7534 - val_loss: 13.8216 - val_mae: 2.7457\n",
      "Epoch 350/500\n",
      "303/303 - 0s - loss: 1.0997 - mae: 0.7666 - val_loss: 12.9412 - val_mae: 2.5697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351/500\n",
      "303/303 - 0s - loss: 0.9805 - mae: 0.7302 - val_loss: 12.0051 - val_mae: 2.5932\n",
      "Epoch 352/500\n",
      "303/303 - 0s - loss: 1.1660 - mae: 0.7732 - val_loss: 12.8215 - val_mae: 2.6328\n",
      "Epoch 353/500\n",
      "303/303 - 0s - loss: 1.0399 - mae: 0.7289 - val_loss: 13.3255 - val_mae: 2.6458\n",
      "Epoch 354/500\n",
      "303/303 - 0s - loss: 1.0200 - mae: 0.7454 - val_loss: 14.3726 - val_mae: 2.7925\n",
      "Epoch 355/500\n",
      "303/303 - 0s - loss: 0.9962 - mae: 0.7181 - val_loss: 13.1898 - val_mae: 2.6274\n",
      "Epoch 356/500\n",
      "303/303 - 0s - loss: 1.1518 - mae: 0.7894 - val_loss: 13.6869 - val_mae: 2.7192\n",
      "Epoch 357/500\n",
      "303/303 - 0s - loss: 0.9931 - mae: 0.7076 - val_loss: 12.2545 - val_mae: 2.5495\n",
      "Epoch 358/500\n",
      "303/303 - 0s - loss: 1.0609 - mae: 0.7449 - val_loss: 13.9712 - val_mae: 2.6872\n",
      "Epoch 359/500\n",
      "303/303 - 0s - loss: 1.1607 - mae: 0.7745 - val_loss: 13.6655 - val_mae: 2.6937\n",
      "Epoch 360/500\n",
      "303/303 - 0s - loss: 1.1179 - mae: 0.7446 - val_loss: 12.8931 - val_mae: 2.6762\n",
      "Epoch 361/500\n",
      "303/303 - 0s - loss: 1.2040 - mae: 0.8040 - val_loss: 14.0175 - val_mae: 2.7392\n",
      "Epoch 362/500\n",
      "303/303 - 0s - loss: 1.0456 - mae: 0.7588 - val_loss: 14.8323 - val_mae: 2.8655\n",
      "Epoch 363/500\n",
      "303/303 - 0s - loss: 1.0551 - mae: 0.7808 - val_loss: 14.3122 - val_mae: 2.7432\n",
      "Epoch 364/500\n",
      "303/303 - 0s - loss: 0.9472 - mae: 0.7229 - val_loss: 13.0387 - val_mae: 2.6901\n",
      "Epoch 365/500\n",
      "303/303 - 0s - loss: 1.0629 - mae: 0.7681 - val_loss: 14.8675 - val_mae: 2.8316\n",
      "Epoch 366/500\n",
      "303/303 - 0s - loss: 1.0797 - mae: 0.7427 - val_loss: 14.4999 - val_mae: 2.8092\n",
      "Epoch 367/500\n",
      "303/303 - 0s - loss: 1.0568 - mae: 0.7680 - val_loss: 14.9686 - val_mae: 2.8421\n",
      "Epoch 368/500\n",
      "303/303 - 0s - loss: 1.0715 - mae: 0.7566 - val_loss: 14.3187 - val_mae: 2.8386\n",
      "Epoch 369/500\n",
      "303/303 - 0s - loss: 1.0731 - mae: 0.7858 - val_loss: 12.6784 - val_mae: 2.6313\n",
      "Epoch 370/500\n",
      "303/303 - 0s - loss: 1.0930 - mae: 0.7433 - val_loss: 12.7605 - val_mae: 2.6524\n",
      "Epoch 371/500\n",
      "303/303 - 0s - loss: 1.0872 - mae: 0.7418 - val_loss: 13.0703 - val_mae: 2.6791\n",
      "Epoch 372/500\n",
      "303/303 - 0s - loss: 1.1240 - mae: 0.7656 - val_loss: 13.9502 - val_mae: 2.7399\n",
      "Epoch 373/500\n",
      "303/303 - 0s - loss: 1.0903 - mae: 0.7717 - val_loss: 13.6776 - val_mae: 2.6808\n",
      "Epoch 374/500\n",
      "303/303 - 0s - loss: 1.0499 - mae: 0.7695 - val_loss: 12.4846 - val_mae: 2.5783\n",
      "Epoch 375/500\n",
      "303/303 - 0s - loss: 1.0327 - mae: 0.7287 - val_loss: 13.1297 - val_mae: 2.6316\n",
      "Epoch 376/500\n",
      "303/303 - 0s - loss: 0.9930 - mae: 0.7488 - val_loss: 14.2380 - val_mae: 2.7506\n",
      "Epoch 377/500\n",
      "303/303 - 0s - loss: 1.0026 - mae: 0.7424 - val_loss: 13.6817 - val_mae: 2.6447\n",
      "Epoch 378/500\n",
      "303/303 - 0s - loss: 1.0971 - mae: 0.7306 - val_loss: 12.9441 - val_mae: 2.5707\n",
      "Epoch 379/500\n",
      "303/303 - 0s - loss: 0.9482 - mae: 0.7061 - val_loss: 13.7180 - val_mae: 2.6654\n",
      "Epoch 380/500\n",
      "303/303 - 0s - loss: 1.0475 - mae: 0.7668 - val_loss: 14.7824 - val_mae: 2.8373\n",
      "Epoch 381/500\n",
      "303/303 - 0s - loss: 0.9936 - mae: 0.7430 - val_loss: 13.6411 - val_mae: 2.6911\n",
      "Epoch 382/500\n",
      "303/303 - 0s - loss: 1.0215 - mae: 0.7454 - val_loss: 14.4475 - val_mae: 2.8234\n",
      "Epoch 383/500\n",
      "303/303 - 0s - loss: 1.0162 - mae: 0.7357 - val_loss: 13.6060 - val_mae: 2.6802\n",
      "Epoch 384/500\n",
      "303/303 - 0s - loss: 0.9728 - mae: 0.7237 - val_loss: 13.8662 - val_mae: 2.7038\n",
      "Epoch 385/500\n",
      "303/303 - 0s - loss: 0.9831 - mae: 0.7147 - val_loss: 12.7315 - val_mae: 2.6121\n",
      "Epoch 386/500\n",
      "303/303 - 0s - loss: 0.9689 - mae: 0.7253 - val_loss: 14.7201 - val_mae: 2.8721\n",
      "Epoch 387/500\n",
      "303/303 - 0s - loss: 0.9805 - mae: 0.7463 - val_loss: 14.0142 - val_mae: 2.7280\n",
      "Epoch 388/500\n",
      "303/303 - 0s - loss: 1.1201 - mae: 0.7434 - val_loss: 14.0116 - val_mae: 2.6880\n",
      "Epoch 389/500\n",
      "303/303 - 0s - loss: 0.9450 - mae: 0.7094 - val_loss: 14.5159 - val_mae: 2.7831\n",
      "Epoch 390/500\n",
      "303/303 - 0s - loss: 0.9905 - mae: 0.7359 - val_loss: 13.5101 - val_mae: 2.6472\n",
      "Epoch 391/500\n",
      "303/303 - 0s - loss: 1.0885 - mae: 0.7359 - val_loss: 13.9684 - val_mae: 2.7087\n",
      "Epoch 392/500\n",
      "303/303 - 0s - loss: 0.9649 - mae: 0.7184 - val_loss: 14.6333 - val_mae: 2.8428\n",
      "Epoch 393/500\n",
      "303/303 - 0s - loss: 1.0555 - mae: 0.7336 - val_loss: 13.8666 - val_mae: 2.6962\n",
      "Epoch 394/500\n",
      "303/303 - 0s - loss: 1.1098 - mae: 0.7514 - val_loss: 14.1209 - val_mae: 2.7797\n",
      "Epoch 395/500\n",
      "303/303 - 0s - loss: 1.0578 - mae: 0.7410 - val_loss: 15.1960 - val_mae: 2.8043\n",
      "Epoch 396/500\n",
      "303/303 - 0s - loss: 1.0222 - mae: 0.7076 - val_loss: 14.8851 - val_mae: 2.8722\n",
      "Epoch 397/500\n",
      "303/303 - 0s - loss: 0.9517 - mae: 0.7121 - val_loss: 14.3910 - val_mae: 2.7708\n",
      "Epoch 398/500\n",
      "303/303 - 0s - loss: 1.0142 - mae: 0.7157 - val_loss: 14.0684 - val_mae: 2.7226\n",
      "Epoch 399/500\n",
      "303/303 - 0s - loss: 0.8817 - mae: 0.6981 - val_loss: 15.0497 - val_mae: 2.7815\n",
      "Epoch 400/500\n",
      "303/303 - 0s - loss: 1.0358 - mae: 0.7265 - val_loss: 14.6609 - val_mae: 2.7492\n",
      "Epoch 401/500\n",
      "303/303 - 0s - loss: 0.9685 - mae: 0.7070 - val_loss: 14.8445 - val_mae: 2.7816\n",
      "Epoch 402/500\n",
      "303/303 - 0s - loss: 0.9998 - mae: 0.7175 - val_loss: 15.5414 - val_mae: 2.8620\n",
      "Epoch 403/500\n",
      "303/303 - 0s - loss: 0.8838 - mae: 0.6876 - val_loss: 13.7442 - val_mae: 2.7205\n",
      "Epoch 404/500\n",
      "303/303 - 0s - loss: 0.8657 - mae: 0.7087 - val_loss: 13.9319 - val_mae: 2.7178\n",
      "Epoch 405/500\n",
      "303/303 - 0s - loss: 0.9259 - mae: 0.7129 - val_loss: 15.7402 - val_mae: 2.8760\n",
      "Epoch 406/500\n",
      "303/303 - 0s - loss: 0.9905 - mae: 0.7345 - val_loss: 14.0447 - val_mae: 2.7284\n",
      "Epoch 407/500\n",
      "303/303 - 0s - loss: 0.8463 - mae: 0.6896 - val_loss: 13.3460 - val_mae: 2.6652\n",
      "Epoch 408/500\n",
      "303/303 - 0s - loss: 0.9315 - mae: 0.6854 - val_loss: 14.5391 - val_mae: 2.7812\n",
      "Epoch 409/500\n",
      "303/303 - 0s - loss: 1.0976 - mae: 0.7361 - val_loss: 13.8360 - val_mae: 2.7204\n",
      "Epoch 410/500\n",
      "303/303 - 0s - loss: 1.0128 - mae: 0.7156 - val_loss: 14.9500 - val_mae: 2.8046\n",
      "Epoch 411/500\n",
      "303/303 - 0s - loss: 0.9979 - mae: 0.7219 - val_loss: 13.4311 - val_mae: 2.7183\n",
      "Epoch 412/500\n",
      "303/303 - 0s - loss: 0.8496 - mae: 0.6728 - val_loss: 13.6494 - val_mae: 2.6749\n",
      "Epoch 413/500\n",
      "303/303 - 0s - loss: 0.9841 - mae: 0.7133 - val_loss: 14.2293 - val_mae: 2.7452\n",
      "Epoch 414/500\n",
      "303/303 - 0s - loss: 0.9928 - mae: 0.7057 - val_loss: 13.9895 - val_mae: 2.7610\n",
      "Epoch 415/500\n",
      "303/303 - 0s - loss: 0.9766 - mae: 0.7227 - val_loss: 15.4819 - val_mae: 2.8262\n",
      "Epoch 416/500\n",
      "303/303 - 0s - loss: 1.0080 - mae: 0.7309 - val_loss: 14.7062 - val_mae: 2.7407\n",
      "Epoch 417/500\n",
      "303/303 - 0s - loss: 0.9771 - mae: 0.7207 - val_loss: 13.6496 - val_mae: 2.7206\n",
      "Epoch 418/500\n",
      "303/303 - 0s - loss: 0.9735 - mae: 0.7094 - val_loss: 14.0833 - val_mae: 2.7352\n",
      "Epoch 419/500\n",
      "303/303 - 0s - loss: 1.0306 - mae: 0.7161 - val_loss: 14.6085 - val_mae: 2.8085\n",
      "Epoch 420/500\n",
      "303/303 - 0s - loss: 0.9630 - mae: 0.7283 - val_loss: 14.3190 - val_mae: 2.8000\n",
      "Epoch 421/500\n",
      "303/303 - 0s - loss: 0.9117 - mae: 0.6888 - val_loss: 13.8776 - val_mae: 2.7844\n",
      "Epoch 422/500\n",
      "303/303 - 0s - loss: 1.0236 - mae: 0.6869 - val_loss: 13.7477 - val_mae: 2.6970\n",
      "Epoch 423/500\n",
      "303/303 - 0s - loss: 0.9546 - mae: 0.7208 - val_loss: 14.0684 - val_mae: 2.7977\n",
      "Epoch 424/500\n",
      "303/303 - 0s - loss: 0.9154 - mae: 0.6883 - val_loss: 14.7599 - val_mae: 2.7609\n",
      "Epoch 425/500\n",
      "303/303 - 0s - loss: 0.8988 - mae: 0.7107 - val_loss: 14.0262 - val_mae: 2.7359\n",
      "Epoch 426/500\n",
      "303/303 - 0s - loss: 0.9446 - mae: 0.6967 - val_loss: 14.1451 - val_mae: 2.7209\n",
      "Epoch 427/500\n",
      "303/303 - 0s - loss: 0.9403 - mae: 0.6780 - val_loss: 13.8677 - val_mae: 2.7432\n",
      "Epoch 428/500\n",
      "303/303 - 0s - loss: 0.8407 - mae: 0.6882 - val_loss: 14.0322 - val_mae: 2.7975\n",
      "Epoch 429/500\n",
      "303/303 - 0s - loss: 0.8634 - mae: 0.6707 - val_loss: 15.1253 - val_mae: 2.7919\n",
      "Epoch 430/500\n",
      "303/303 - 0s - loss: 0.8759 - mae: 0.6995 - val_loss: 16.2270 - val_mae: 2.9243\n",
      "Epoch 431/500\n",
      "303/303 - 0s - loss: 0.9788 - mae: 0.7138 - val_loss: 15.1882 - val_mae: 2.7804\n",
      "Epoch 432/500\n",
      "303/303 - 0s - loss: 0.9453 - mae: 0.7151 - val_loss: 14.0937 - val_mae: 2.7678\n",
      "Epoch 433/500\n",
      "303/303 - 0s - loss: 0.9217 - mae: 0.7012 - val_loss: 13.6739 - val_mae: 2.6767\n",
      "Epoch 434/500\n",
      "303/303 - 0s - loss: 0.8403 - mae: 0.6748 - val_loss: 14.9482 - val_mae: 2.8179\n",
      "Epoch 435/500\n",
      "303/303 - 0s - loss: 1.0231 - mae: 0.7451 - val_loss: 14.1302 - val_mae: 2.7272\n",
      "Epoch 436/500\n",
      "303/303 - 0s - loss: 0.8266 - mae: 0.6563 - val_loss: 13.8907 - val_mae: 2.6877\n",
      "Epoch 437/500\n",
      "303/303 - 0s - loss: 0.8027 - mae: 0.6771 - val_loss: 14.1698 - val_mae: 2.7553\n",
      "Epoch 438/500\n",
      "303/303 - 0s - loss: 0.9066 - mae: 0.6846 - val_loss: 13.6707 - val_mae: 2.6923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 439/500\n",
      "303/303 - 0s - loss: 0.8876 - mae: 0.6840 - val_loss: 14.7355 - val_mae: 2.8364\n",
      "Epoch 440/500\n",
      "303/303 - 0s - loss: 0.9534 - mae: 0.7060 - val_loss: 14.0996 - val_mae: 2.6678\n",
      "Epoch 441/500\n",
      "303/303 - 0s - loss: 0.8470 - mae: 0.6684 - val_loss: 14.9492 - val_mae: 2.8293\n",
      "Epoch 442/500\n",
      "303/303 - 0s - loss: 1.0398 - mae: 0.6908 - val_loss: 14.9590 - val_mae: 2.8744\n",
      "Epoch 443/500\n",
      "303/303 - 0s - loss: 0.7819 - mae: 0.6571 - val_loss: 15.8839 - val_mae: 2.9450\n",
      "Epoch 444/500\n",
      "303/303 - 0s - loss: 0.7853 - mae: 0.6805 - val_loss: 14.9557 - val_mae: 2.7702\n",
      "Epoch 445/500\n",
      "303/303 - 0s - loss: 0.9037 - mae: 0.7083 - val_loss: 13.9800 - val_mae: 2.7111\n",
      "Epoch 446/500\n",
      "303/303 - 0s - loss: 0.7954 - mae: 0.6574 - val_loss: 14.4273 - val_mae: 2.7537\n",
      "Epoch 447/500\n",
      "303/303 - 0s - loss: 0.8728 - mae: 0.6874 - val_loss: 12.9912 - val_mae: 2.5960\n",
      "Epoch 448/500\n",
      "303/303 - 0s - loss: 0.8717 - mae: 0.6691 - val_loss: 13.4084 - val_mae: 2.7066\n",
      "Epoch 449/500\n",
      "303/303 - 0s - loss: 0.8962 - mae: 0.7042 - val_loss: 13.7799 - val_mae: 2.7669\n",
      "Epoch 450/500\n",
      "303/303 - 0s - loss: 0.9298 - mae: 0.6953 - val_loss: 14.0800 - val_mae: 2.7301\n",
      "Epoch 451/500\n",
      "303/303 - 0s - loss: 0.8005 - mae: 0.6649 - val_loss: 13.6114 - val_mae: 2.6635\n",
      "Epoch 452/500\n",
      "303/303 - 0s - loss: 0.8304 - mae: 0.6641 - val_loss: 14.4226 - val_mae: 2.8489\n",
      "Epoch 453/500\n",
      "303/303 - 0s - loss: 0.8269 - mae: 0.6671 - val_loss: 13.9966 - val_mae: 2.7339\n",
      "Epoch 454/500\n",
      "303/303 - 0s - loss: 0.9322 - mae: 0.6695 - val_loss: 14.0939 - val_mae: 2.7069\n",
      "Epoch 455/500\n",
      "303/303 - 0s - loss: 0.7660 - mae: 0.6385 - val_loss: 14.2551 - val_mae: 2.7557\n",
      "Epoch 456/500\n",
      "303/303 - 0s - loss: 0.8790 - mae: 0.6661 - val_loss: 13.8405 - val_mae: 2.7211\n",
      "Epoch 457/500\n",
      "303/303 - 0s - loss: 0.8289 - mae: 0.6635 - val_loss: 14.4243 - val_mae: 2.7664\n",
      "Epoch 458/500\n",
      "303/303 - 0s - loss: 0.9425 - mae: 0.6847 - val_loss: 14.1571 - val_mae: 2.7823\n",
      "Epoch 459/500\n",
      "303/303 - 0s - loss: 0.8235 - mae: 0.6787 - val_loss: 13.2118 - val_mae: 2.6525\n",
      "Epoch 460/500\n",
      "303/303 - 0s - loss: 0.7752 - mae: 0.6582 - val_loss: 15.3103 - val_mae: 2.8847\n",
      "Epoch 461/500\n",
      "303/303 - 0s - loss: 0.9216 - mae: 0.6940 - val_loss: 15.0833 - val_mae: 2.8718\n",
      "Epoch 462/500\n",
      "303/303 - 0s - loss: 0.8520 - mae: 0.6608 - val_loss: 13.5645 - val_mae: 2.7389\n",
      "Epoch 463/500\n",
      "303/303 - 0s - loss: 0.8429 - mae: 0.6614 - val_loss: 13.5395 - val_mae: 2.6861\n",
      "Epoch 464/500\n",
      "303/303 - 0s - loss: 0.8389 - mae: 0.6653 - val_loss: 13.8704 - val_mae: 2.7332\n",
      "Epoch 465/500\n",
      "303/303 - 0s - loss: 0.7987 - mae: 0.6713 - val_loss: 14.8145 - val_mae: 2.8492\n",
      "Epoch 466/500\n",
      "303/303 - 0s - loss: 0.8110 - mae: 0.6483 - val_loss: 13.7188 - val_mae: 2.7512\n",
      "Epoch 467/500\n",
      "303/303 - 0s - loss: 0.9627 - mae: 0.7064 - val_loss: 13.1375 - val_mae: 2.6602\n",
      "Epoch 468/500\n",
      "303/303 - 0s - loss: 0.8848 - mae: 0.6691 - val_loss: 12.8304 - val_mae: 2.6823\n",
      "Epoch 469/500\n",
      "303/303 - 0s - loss: 0.8355 - mae: 0.6605 - val_loss: 13.8764 - val_mae: 2.7536\n",
      "Epoch 470/500\n",
      "303/303 - 0s - loss: 0.8814 - mae: 0.6745 - val_loss: 12.8662 - val_mae: 2.6020\n",
      "Epoch 471/500\n",
      "303/303 - 0s - loss: 0.8267 - mae: 0.6608 - val_loss: 13.9901 - val_mae: 2.7371\n",
      "Epoch 472/500\n",
      "303/303 - 0s - loss: 0.9248 - mae: 0.6777 - val_loss: 13.8637 - val_mae: 2.7620\n",
      "Epoch 473/500\n",
      "303/303 - 0s - loss: 0.7943 - mae: 0.6751 - val_loss: 13.6417 - val_mae: 2.6940\n",
      "Epoch 474/500\n",
      "303/303 - 0s - loss: 0.7234 - mae: 0.6494 - val_loss: 12.8083 - val_mae: 2.6349\n",
      "Epoch 475/500\n",
      "303/303 - 0s - loss: 0.8852 - mae: 0.6858 - val_loss: 13.0219 - val_mae: 2.6490\n",
      "Epoch 476/500\n",
      "303/303 - 0s - loss: 0.7767 - mae: 0.6476 - val_loss: 13.3688 - val_mae: 2.7647\n",
      "Epoch 477/500\n",
      "303/303 - 0s - loss: 0.7456 - mae: 0.6597 - val_loss: 13.7445 - val_mae: 2.6922\n",
      "Epoch 478/500\n",
      "303/303 - 0s - loss: 0.8874 - mae: 0.6814 - val_loss: 13.6804 - val_mae: 2.7246\n",
      "Epoch 479/500\n",
      "303/303 - 0s - loss: 0.8679 - mae: 0.6944 - val_loss: 12.6589 - val_mae: 2.6316\n",
      "Epoch 480/500\n",
      "303/303 - 0s - loss: 0.8247 - mae: 0.6489 - val_loss: 15.4900 - val_mae: 2.8991\n",
      "Epoch 481/500\n",
      "303/303 - 0s - loss: 0.9169 - mae: 0.7173 - val_loss: 12.9967 - val_mae: 2.6900\n",
      "Epoch 482/500\n",
      "303/303 - 0s - loss: 0.7867 - mae: 0.6335 - val_loss: 13.3687 - val_mae: 2.6966\n",
      "Epoch 483/500\n",
      "303/303 - 0s - loss: 0.8301 - mae: 0.6596 - val_loss: 13.4169 - val_mae: 2.7003\n",
      "Epoch 484/500\n",
      "303/303 - 0s - loss: 0.7865 - mae: 0.6292 - val_loss: 13.6500 - val_mae: 2.7176\n",
      "Epoch 485/500\n",
      "303/303 - 0s - loss: 0.8432 - mae: 0.6663 - val_loss: 13.7040 - val_mae: 2.7480\n",
      "Epoch 486/500\n",
      "303/303 - 0s - loss: 0.7618 - mae: 0.6367 - val_loss: 13.7881 - val_mae: 2.7286\n",
      "Epoch 487/500\n",
      "303/303 - 0s - loss: 0.7711 - mae: 0.6693 - val_loss: 14.1454 - val_mae: 2.7003\n",
      "Epoch 488/500\n",
      "303/303 - 0s - loss: 0.8211 - mae: 0.6397 - val_loss: 13.4858 - val_mae: 2.7200\n",
      "Epoch 489/500\n",
      "303/303 - 0s - loss: 0.8271 - mae: 0.6526 - val_loss: 13.9730 - val_mae: 2.7418\n",
      "Epoch 490/500\n",
      "303/303 - 0s - loss: 0.8168 - mae: 0.6439 - val_loss: 13.5620 - val_mae: 2.7646\n",
      "Epoch 491/500\n",
      "303/303 - 0s - loss: 0.8811 - mae: 0.6668 - val_loss: 13.1521 - val_mae: 2.6688\n",
      "Epoch 492/500\n",
      "303/303 - 0s - loss: 0.7149 - mae: 0.6140 - val_loss: 14.6272 - val_mae: 2.8069\n",
      "Epoch 493/500\n",
      "303/303 - 0s - loss: 0.9324 - mae: 0.6896 - val_loss: 12.7538 - val_mae: 2.5835\n",
      "Epoch 494/500\n",
      "303/303 - 0s - loss: 0.7929 - mae: 0.6458 - val_loss: 13.1908 - val_mae: 2.7045\n",
      "Epoch 495/500\n",
      "303/303 - 0s - loss: 0.8490 - mae: 0.6737 - val_loss: 13.8636 - val_mae: 2.6728\n",
      "Epoch 496/500\n",
      "303/303 - 0s - loss: 0.7750 - mae: 0.6485 - val_loss: 13.1232 - val_mae: 2.7415\n",
      "Epoch 497/500\n",
      "303/303 - 0s - loss: 0.7634 - mae: 0.6199 - val_loss: 13.9889 - val_mae: 2.8439\n",
      "Epoch 498/500\n",
      "303/303 - 0s - loss: 0.8127 - mae: 0.6555 - val_loss: 13.5221 - val_mae: 2.7367\n",
      "Epoch 499/500\n",
      "303/303 - 0s - loss: 0.7888 - mae: 0.6660 - val_loss: 13.5031 - val_mae: 2.6771\n",
      "Epoch 500/500\n",
      "303/303 - 0s - loss: 0.8589 - mae: 0.6468 - val_loss: 14.3266 - val_mae: 2.7743\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "all_mae_histories = []\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    # Prepare the validation data: data from partition # k\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "\n",
    "    # Prepare the training data: data from all other partitions\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "         train_data[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    # Build the Keras model (already compiled)\n",
    "    model = build_model()\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    history = model.fit(partial_train_data, partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs, batch_size=1, verbose=2)\n",
    "    mae_history = history.history['val_mae']\n",
    "    all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.6397271156311035,\n",
       " 3.363842725753784,\n",
       " 3.1136538982391357,\n",
       " 2.9792721271514893,\n",
       " 2.976030111312866,\n",
       " 3.003058910369873,\n",
       " 2.726698875427246,\n",
       " 3.1360666751861572,\n",
       " 2.8481671810150146,\n",
       " 2.5766868591308594,\n",
       " 2.6238715648651123,\n",
       " 2.493695020675659,\n",
       " 2.5826897621154785,\n",
       " 2.5075807571411133,\n",
       " 2.561372756958008,\n",
       " 2.8423001766204834,\n",
       " 2.568312168121338,\n",
       " 2.427208423614502,\n",
       " 2.5298938751220703,\n",
       " 2.5173909664154053,\n",
       " 2.422870397567749,\n",
       " 2.615527391433716,\n",
       " 2.514080762863159,\n",
       " 2.560713291168213,\n",
       " 2.7506113052368164,\n",
       " 2.375450611114502,\n",
       " 2.4689109325408936,\n",
       " 2.392299175262451,\n",
       " 2.449002742767334,\n",
       " 2.4342784881591797,\n",
       " 2.4503445625305176,\n",
       " 2.5684306621551514,\n",
       " 2.4357690811157227,\n",
       " 2.5313196182250977,\n",
       " 2.526344060897827,\n",
       " 2.703587532043457,\n",
       " 2.5354576110839844,\n",
       " 2.5992026329040527,\n",
       " 2.5463411808013916,\n",
       " 2.515913248062134,\n",
       " 2.5150833129882812,\n",
       " 2.639561414718628,\n",
       " 2.5009617805480957,\n",
       " 2.407827615737915,\n",
       " 2.3559439182281494,\n",
       " 2.625257730484009,\n",
       " 2.7069509029388428,\n",
       " 2.5282981395721436,\n",
       " 2.4497079849243164,\n",
       " 2.375375986099243,\n",
       " 2.4879250526428223,\n",
       " 2.394496440887451,\n",
       " 2.334498643875122,\n",
       " 2.3992040157318115,\n",
       " 2.5270802974700928,\n",
       " 2.6572747230529785,\n",
       " 2.70625376701355,\n",
       " 2.466139078140259,\n",
       " 2.548485279083252,\n",
       " 2.4894661903381348,\n",
       " 2.520305633544922,\n",
       " 2.440612554550171,\n",
       " 2.3912065029144287,\n",
       " 2.6419544219970703,\n",
       " 2.527658700942993,\n",
       " 2.5842816829681396,\n",
       " 2.425144672393799,\n",
       " 2.4485549926757812,\n",
       " 3.017796039581299,\n",
       " 2.3643100261688232,\n",
       " 2.4205799102783203,\n",
       " 2.5267930030822754,\n",
       " 2.502166748046875,\n",
       " 2.3706562519073486,\n",
       " 2.473299503326416,\n",
       " 2.5256121158599854,\n",
       " 2.6045761108398438,\n",
       " 2.425790548324585,\n",
       " 2.668367862701416,\n",
       " 2.744050979614258,\n",
       " 2.456758737564087,\n",
       " 2.502868890762329,\n",
       " 2.4438843727111816,\n",
       " 2.601046323776245,\n",
       " 2.5847585201263428,\n",
       " 2.601640462875366,\n",
       " 2.3825268745422363,\n",
       " 2.787625789642334,\n",
       " 2.6644906997680664,\n",
       " 2.556915521621704,\n",
       " 2.5169291496276855,\n",
       " 2.4984450340270996,\n",
       " 2.564100742340088,\n",
       " 2.8982038497924805,\n",
       " 2.5668485164642334,\n",
       " 2.3295657634735107,\n",
       " 2.5380218029022217,\n",
       " 2.4419236183166504,\n",
       " 2.4792091846466064,\n",
       " 2.4904396533966064,\n",
       " 2.40771484375,\n",
       " 2.4731595516204834,\n",
       " 2.4366564750671387,\n",
       " 2.4978461265563965,\n",
       " 2.3481996059417725,\n",
       " 2.410825252532959,\n",
       " 2.4366519451141357,\n",
       " 2.4271247386932373,\n",
       " 2.4414453506469727,\n",
       " 2.509526252746582,\n",
       " 2.4889965057373047,\n",
       " 2.706172466278076,\n",
       " 2.411616325378418,\n",
       " 2.462096929550171,\n",
       " 2.58691668510437,\n",
       " 2.436563014984131,\n",
       " 2.525312662124634,\n",
       " 2.4181747436523438,\n",
       " 2.6509249210357666,\n",
       " 2.6228106021881104,\n",
       " 2.5332016944885254,\n",
       " 2.8527891635894775,\n",
       " 2.7043895721435547,\n",
       " 2.511399984359741,\n",
       " 2.8697001934051514,\n",
       " 2.482388973236084,\n",
       " 2.361584424972534,\n",
       " 2.5081875324249268,\n",
       " 2.4623348712921143,\n",
       " 2.3980727195739746,\n",
       " 2.4071762561798096,\n",
       " 2.553544044494629,\n",
       " 2.409571409225464,\n",
       " 2.461315155029297,\n",
       " 2.4149880409240723,\n",
       " 2.5741419792175293,\n",
       " 2.4151320457458496,\n",
       " 2.4065890312194824,\n",
       " 2.6434175968170166,\n",
       " 2.475334644317627,\n",
       " 2.3909406661987305,\n",
       " 2.284001350402832,\n",
       " 2.5389678478240967,\n",
       " 2.4910857677459717,\n",
       " 2.4595916271209717,\n",
       " 2.504161834716797,\n",
       " 2.741525888442993,\n",
       " 2.6738922595977783,\n",
       " 2.5361416339874268,\n",
       " 2.6257994174957275,\n",
       " 2.4574270248413086,\n",
       " 2.5231270790100098,\n",
       " 2.5333609580993652,\n",
       " 2.4522311687469482,\n",
       " 2.4856162071228027,\n",
       " 2.6801109313964844,\n",
       " 2.5095226764678955,\n",
       " 2.5044872760772705,\n",
       " 2.4656124114990234,\n",
       " 2.504373073577881,\n",
       " 2.688722848892212,\n",
       " 2.5664334297180176,\n",
       " 2.5861523151397705,\n",
       " 2.424581289291382,\n",
       " 2.473217010498047,\n",
       " 2.471247673034668,\n",
       " 2.4854178428649902,\n",
       " 2.4726788997650146,\n",
       " 2.4459176063537598,\n",
       " 2.617492437362671,\n",
       " 2.7569000720977783,\n",
       " 2.5846707820892334,\n",
       " 2.485848903656006,\n",
       " 2.555130958557129,\n",
       " 2.6663503646850586,\n",
       " 2.5860378742218018,\n",
       " 2.4798424243927,\n",
       " 2.4938132762908936,\n",
       " 2.429741621017456,\n",
       " 2.536931037902832,\n",
       " 2.5183634757995605,\n",
       " 2.552455186843872,\n",
       " 2.570462703704834,\n",
       " 2.4568941593170166,\n",
       " 2.433924913406372,\n",
       " 2.400667667388916,\n",
       " 2.504805088043213,\n",
       " 2.4015839099884033,\n",
       " 2.583545446395874,\n",
       " 2.463874101638794,\n",
       " 2.4631965160369873,\n",
       " 2.4913218021392822,\n",
       " 2.6024184226989746,\n",
       " 2.43294620513916,\n",
       " 2.496276617050171,\n",
       " 2.472879648208618,\n",
       " 2.5855987071990967,\n",
       " 2.580677032470703,\n",
       " 2.721813917160034,\n",
       " 2.4140243530273438,\n",
       " 2.5615384578704834,\n",
       " 2.5439846515655518,\n",
       " 2.7616801261901855,\n",
       " 2.5997540950775146,\n",
       " 2.7629170417785645,\n",
       " 2.6747686862945557,\n",
       " 2.5065627098083496,\n",
       " 2.536303758621216,\n",
       " 2.514380693435669,\n",
       " 2.6508965492248535,\n",
       " 2.526836395263672,\n",
       " 2.6869544982910156,\n",
       " 2.452821731567383,\n",
       " 2.656550884246826,\n",
       " 2.6818394660949707,\n",
       " 2.7002034187316895,\n",
       " 2.5309853553771973,\n",
       " 2.489903688430786,\n",
       " 2.9041125774383545,\n",
       " 2.5216434001922607,\n",
       " 2.671083927154541,\n",
       " 2.412031888961792,\n",
       " 2.4771721363067627,\n",
       " 2.5995254516601562,\n",
       " 2.7326762676239014,\n",
       " 2.6075384616851807,\n",
       " 2.6054892539978027,\n",
       " 2.6524181365966797,\n",
       " 2.696939706802368,\n",
       " 2.4208436012268066,\n",
       " 2.548002243041992,\n",
       " 2.552396059036255,\n",
       " 2.5768773555755615,\n",
       " 2.5431487560272217,\n",
       " 2.542877435684204,\n",
       " 2.651050567626953,\n",
       " 2.4971330165863037,\n",
       " 2.5933315753936768,\n",
       " 2.5474913120269775,\n",
       " 2.4840242862701416,\n",
       " 2.6167452335357666,\n",
       " 2.552198648452759,\n",
       " 2.5183804035186768,\n",
       " 2.7304978370666504,\n",
       " 2.432605504989624,\n",
       " 2.7376482486724854,\n",
       " 2.6996655464172363,\n",
       " 2.6365861892700195,\n",
       " 2.4413845539093018,\n",
       " 2.557328939437866,\n",
       " 2.6093719005584717,\n",
       " 2.764695167541504,\n",
       " 2.666229248046875,\n",
       " 2.6669256687164307,\n",
       " 2.6893811225891113,\n",
       " 2.6074185371398926,\n",
       " 2.5504372119903564,\n",
       " 2.665409564971924,\n",
       " 2.560152769088745,\n",
       " 2.712186574935913,\n",
       " 2.8519020080566406,\n",
       " 2.6490931510925293,\n",
       " 2.690157175064087,\n",
       " 2.62268328666687,\n",
       " 2.707761764526367,\n",
       " 2.5736382007598877,\n",
       " 2.5808796882629395,\n",
       " 2.6154532432556152,\n",
       " 2.634150981903076,\n",
       " 2.5537822246551514,\n",
       " 2.9081478118896484,\n",
       " 2.5405068397521973,\n",
       " 2.6336638927459717,\n",
       " 2.952014207839966,\n",
       " 2.6113338470458984,\n",
       " 2.576321840286255,\n",
       " 2.619995355606079,\n",
       " 2.4970955848693848,\n",
       " 2.6340954303741455,\n",
       " 2.75968337059021,\n",
       " 2.6220004558563232,\n",
       " 2.557497262954712,\n",
       " 2.9465253353118896,\n",
       " 2.7970454692840576,\n",
       " 2.864389181137085,\n",
       " 2.6873292922973633,\n",
       " 2.7550690174102783,\n",
       " 2.677401304244995,\n",
       " 2.7771859169006348,\n",
       " 2.6073780059814453,\n",
       " 2.5567080974578857,\n",
       " 2.7285118103027344,\n",
       " 2.670708179473877,\n",
       " 2.5742077827453613,\n",
       " 2.5680832862854004,\n",
       " 2.5611178874969482,\n",
       " 2.8211376667022705,\n",
       " 2.7681894302368164,\n",
       " 2.6346912384033203,\n",
       " 2.6285600662231445,\n",
       " 2.749013662338257,\n",
       " 2.714520215988159,\n",
       " 2.6773552894592285,\n",
       " 2.8064231872558594,\n",
       " 2.6835436820983887,\n",
       " 2.6870760917663574,\n",
       " 2.6280746459960938,\n",
       " 2.6828792095184326,\n",
       " 2.607977867126465,\n",
       " 2.6280009746551514,\n",
       " 2.614868402481079,\n",
       " 2.608802080154419,\n",
       " 2.747853994369507,\n",
       " 2.556408643722534,\n",
       " 2.907189130783081,\n",
       " 2.5928871631622314,\n",
       " 2.583498477935791,\n",
       " 2.6337780952453613,\n",
       " 2.6364171504974365,\n",
       " 2.6128909587860107,\n",
       " 2.596867322921753,\n",
       " 2.718407154083252,\n",
       " 2.6133904457092285,\n",
       " 2.7189526557922363,\n",
       " 2.657331705093384,\n",
       " 2.647953510284424,\n",
       " 2.771308183670044,\n",
       " 2.901944398880005,\n",
       " 2.6312198638916016,\n",
       " 2.762957811355591,\n",
       " 2.5958712100982666,\n",
       " 3.0719215869903564,\n",
       " 2.7137765884399414,\n",
       " 2.6133782863616943,\n",
       " 2.704620361328125,\n",
       " 2.6969077587127686,\n",
       " 2.8790693283081055,\n",
       " 2.5977299213409424,\n",
       " 2.6763105392456055,\n",
       " 2.6477670669555664,\n",
       " 2.6597275733947754,\n",
       " 2.775918483734131,\n",
       " 2.639392614364624,\n",
       " 2.8708417415618896,\n",
       " 2.5640223026275635,\n",
       " 2.6846423149108887,\n",
       " 2.550781011581421,\n",
       " 2.6394314765930176,\n",
       " 2.745718240737915,\n",
       " 2.569730758666992,\n",
       " 2.5931737422943115,\n",
       " 2.6327810287475586,\n",
       " 2.645768642425537,\n",
       " 2.792473793029785,\n",
       " 2.627385139465332,\n",
       " 2.7191851139068604,\n",
       " 2.5495219230651855,\n",
       " 2.6871538162231445,\n",
       " 2.693686008453369,\n",
       " 2.6761701107025146,\n",
       " 2.7392449378967285,\n",
       " 2.8655295372009277,\n",
       " 2.743185520172119,\n",
       " 2.6900529861450195,\n",
       " 2.8315773010253906,\n",
       " 2.8091654777526855,\n",
       " 2.8421242237091064,\n",
       " 2.838560104370117,\n",
       " 2.6312665939331055,\n",
       " 2.6524360179901123,\n",
       " 2.6791293621063232,\n",
       " 2.7399303913116455,\n",
       " 2.680830955505371,\n",
       " 2.5783252716064453,\n",
       " 2.6316401958465576,\n",
       " 2.7506232261657715,\n",
       " 2.644697666168213,\n",
       " 2.5707364082336426,\n",
       " 2.665433645248413,\n",
       " 2.837322950363159,\n",
       " 2.691141366958618,\n",
       " 2.823435068130493,\n",
       " 2.6802101135253906,\n",
       " 2.7038211822509766,\n",
       " 2.612065315246582,\n",
       " 2.8721485137939453,\n",
       " 2.728013753890991,\n",
       " 2.6880438327789307,\n",
       " 2.783148765563965,\n",
       " 2.6471669673919678,\n",
       " 2.708683490753174,\n",
       " 2.8428356647491455,\n",
       " 2.6961746215820312,\n",
       " 2.7796788215637207,\n",
       " 2.804255962371826,\n",
       " 2.8722150325775146,\n",
       " 2.770751953125,\n",
       " 2.722614049911499,\n",
       " 2.781503438949585,\n",
       " 2.7491612434387207,\n",
       " 2.7816200256347656,\n",
       " 2.8620054721832275,\n",
       " 2.720454454421997,\n",
       " 2.717783212661743,\n",
       " 2.875983715057373,\n",
       " 2.728416919708252,\n",
       " 2.6652281284332275,\n",
       " 2.7812137603759766,\n",
       " 2.7203733921051025,\n",
       " 2.80462384223938,\n",
       " 2.7183125019073486,\n",
       " 2.6749050617218018,\n",
       " 2.745230197906494,\n",
       " 2.7610394954681396,\n",
       " 2.826200008392334,\n",
       " 2.7407121658325195,\n",
       " 2.7206294536590576,\n",
       " 2.7351653575897217,\n",
       " 2.8085336685180664,\n",
       " 2.7999961376190186,\n",
       " 2.7843821048736572,\n",
       " 2.6969783306121826,\n",
       " 2.7976937294006348,\n",
       " 2.760935068130493,\n",
       " 2.73587703704834,\n",
       " 2.720914125442505,\n",
       " 2.7432405948638916,\n",
       " 2.797459125518799,\n",
       " 2.7918636798858643,\n",
       " 2.924314498901367,\n",
       " 2.7804484367370605,\n",
       " 2.7677998542785645,\n",
       " 2.6766581535339355,\n",
       " 2.817946434020996,\n",
       " 2.7272045612335205,\n",
       " 2.687736988067627,\n",
       " 2.755326986312866,\n",
       " 2.6922619342803955,\n",
       " 2.8363962173461914,\n",
       " 2.6678061485290527,\n",
       " 2.8293068408966064,\n",
       " 2.874401092529297,\n",
       " 2.944953441619873,\n",
       " 2.770216226577759,\n",
       " 2.711052894592285,\n",
       " 2.7537004947662354,\n",
       " 2.5960323810577393,\n",
       " 2.706631898880005,\n",
       " 2.7668616771698,\n",
       " 2.7301361560821533,\n",
       " 2.6635355949401855,\n",
       " 2.848896026611328,\n",
       " 2.7339117527008057,\n",
       " 2.7069027423858643,\n",
       " 2.755692958831787,\n",
       " 2.721132755279541,\n",
       " 2.7664096355438232,\n",
       " 2.78229022026062,\n",
       " 2.652529001235962,\n",
       " 2.884711742401123,\n",
       " 2.8718454837799072,\n",
       " 2.738917827606201,\n",
       " 2.6861472129821777,\n",
       " 2.7331840991973877,\n",
       " 2.849247932434082,\n",
       " 2.751232385635376,\n",
       " 2.66019344329834,\n",
       " 2.6823337078094482,\n",
       " 2.7535653114318848,\n",
       " 2.602013111114502,\n",
       " 2.737114667892456,\n",
       " 2.761993646621704,\n",
       " 2.6940226554870605,\n",
       " 2.634899854660034,\n",
       " 2.648953914642334,\n",
       " 2.7646965980529785,\n",
       " 2.69217586517334,\n",
       " 2.724613904953003,\n",
       " 2.6316490173339844,\n",
       " 2.8990747928619385,\n",
       " 2.6900014877319336,\n",
       " 2.696568489074707,\n",
       " 2.7002980709075928,\n",
       " 2.717618227005005,\n",
       " 2.7480309009552,\n",
       " 2.7286014556884766,\n",
       " 2.7002511024475098,\n",
       " 2.7200496196746826,\n",
       " 2.7417922019958496,\n",
       " 2.7646000385284424,\n",
       " 2.668842315673828,\n",
       " 2.806943416595459,\n",
       " 2.583522081375122,\n",
       " 2.7044520378112793,\n",
       " 2.6727688312530518,\n",
       " 2.741530418395996,\n",
       " 2.843883514404297,\n",
       " 2.7366750240325928,\n",
       " 2.677060842514038,\n",
       " 2.7742698192596436]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_history #因为会覆盖所以这个是第4次的mae_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4.340725421905518,\n",
       "  2.9673473834991455,\n",
       "  2.7650771141052246,\n",
       "  2.6791744232177734,\n",
       "  2.3203494548797607,\n",
       "  2.3405418395996094,\n",
       "  2.462209463119507,\n",
       "  2.3548362255096436,\n",
       "  2.801302671432495,\n",
       "  2.0079216957092285,\n",
       "  2.0931997299194336,\n",
       "  1.9810785055160522,\n",
       "  2.100679636001587,\n",
       "  2.145681619644165,\n",
       "  1.9017456769943237,\n",
       "  2.130722761154175,\n",
       "  2.018975257873535,\n",
       "  2.447056293487549,\n",
       "  2.0006980895996094,\n",
       "  2.114788770675659,\n",
       "  1.8910057544708252,\n",
       "  1.9309592247009277,\n",
       "  2.0102078914642334,\n",
       "  1.958176612854004,\n",
       "  2.043541431427002,\n",
       "  1.9282175302505493,\n",
       "  1.910223364830017,\n",
       "  1.8347249031066895,\n",
       "  1.9426041841506958,\n",
       "  2.1337473392486572,\n",
       "  1.9686133861541748,\n",
       "  1.7717620134353638,\n",
       "  2.0223257541656494,\n",
       "  1.908780813217163,\n",
       "  1.8486003875732422,\n",
       "  2.110375165939331,\n",
       "  1.740657091140747,\n",
       "  1.8181710243225098,\n",
       "  2.1871516704559326,\n",
       "  1.8969663381576538,\n",
       "  2.1882057189941406,\n",
       "  1.985932469367981,\n",
       "  1.921201229095459,\n",
       "  2.1719248294830322,\n",
       "  1.8899452686309814,\n",
       "  1.7924280166625977,\n",
       "  2.1527910232543945,\n",
       "  1.8925385475158691,\n",
       "  1.937271237373352,\n",
       "  1.7536379098892212,\n",
       "  1.9513493776321411,\n",
       "  1.7093019485473633,\n",
       "  1.9080312252044678,\n",
       "  2.081467390060425,\n",
       "  1.972322702407837,\n",
       "  1.934778094291687,\n",
       "  1.8952666521072388,\n",
       "  2.107520580291748,\n",
       "  1.6940323114395142,\n",
       "  1.900945782661438,\n",
       "  1.8034424781799316,\n",
       "  1.9492262601852417,\n",
       "  1.995585560798645,\n",
       "  1.8822150230407715,\n",
       "  2.375591278076172,\n",
       "  1.9272620677947998,\n",
       "  1.9645735025405884,\n",
       "  1.890937089920044,\n",
       "  1.8654016256332397,\n",
       "  2.017958164215088,\n",
       "  2.3414082527160645,\n",
       "  1.7750694751739502,\n",
       "  1.8297456502914429,\n",
       "  1.8619754314422607,\n",
       "  2.001004934310913,\n",
       "  1.7631303071975708,\n",
       "  2.1439669132232666,\n",
       "  2.1085150241851807,\n",
       "  1.7801227569580078,\n",
       "  2.10634708404541,\n",
       "  1.7813422679901123,\n",
       "  1.7513765096664429,\n",
       "  1.7310154438018799,\n",
       "  2.078981399536133,\n",
       "  1.8451815843582153,\n",
       "  2.0409419536590576,\n",
       "  1.905889630317688,\n",
       "  1.7931462526321411,\n",
       "  2.205564260482788,\n",
       "  2.4378275871276855,\n",
       "  1.8705533742904663,\n",
       "  2.104665994644165,\n",
       "  1.8631325960159302,\n",
       "  1.940493106842041,\n",
       "  1.8887698650360107,\n",
       "  1.7796977758407593,\n",
       "  1.9270272254943848,\n",
       "  2.289235830307007,\n",
       "  1.957595944404602,\n",
       "  2.0378103256225586,\n",
       "  2.624030590057373,\n",
       "  2.0091240406036377,\n",
       "  2.0106186866760254,\n",
       "  2.1535255908966064,\n",
       "  2.063413619995117,\n",
       "  1.8282861709594727,\n",
       "  1.9401018619537354,\n",
       "  2.0319509506225586,\n",
       "  2.016070604324341,\n",
       "  1.7610167264938354,\n",
       "  2.193711280822754,\n",
       "  1.8581531047821045,\n",
       "  1.9990657567977905,\n",
       "  1.9829744100570679,\n",
       "  1.8813985586166382,\n",
       "  1.9500560760498047,\n",
       "  1.8373717069625854,\n",
       "  2.000959634780884,\n",
       "  1.9756557941436768,\n",
       "  1.8535398244857788,\n",
       "  1.9947508573532104,\n",
       "  1.8909296989440918,\n",
       "  1.9487881660461426,\n",
       "  2.191448450088501,\n",
       "  2.0291335582733154,\n",
       "  2.346341609954834,\n",
       "  1.8844870328903198,\n",
       "  2.029017686843872,\n",
       "  2.3829524517059326,\n",
       "  2.2402265071868896,\n",
       "  1.9249917268753052,\n",
       "  2.160571336746216,\n",
       "  2.019394874572754,\n",
       "  1.9404393434524536,\n",
       "  2.0651304721832275,\n",
       "  2.0775225162506104,\n",
       "  1.9906277656555176,\n",
       "  2.024322748184204,\n",
       "  1.9551576375961304,\n",
       "  1.9830158948898315,\n",
       "  1.991418719291687,\n",
       "  1.878065824508667,\n",
       "  2.015897274017334,\n",
       "  2.1296498775482178,\n",
       "  1.95941162109375,\n",
       "  2.1257753372192383,\n",
       "  2.0273616313934326,\n",
       "  2.1691653728485107,\n",
       "  2.7446460723876953,\n",
       "  1.9649665355682373,\n",
       "  2.080176591873169,\n",
       "  2.187272071838379,\n",
       "  1.8870997428894043,\n",
       "  1.9329670667648315,\n",
       "  1.9637118577957153,\n",
       "  2.206261396408081,\n",
       "  1.9560010433197021,\n",
       "  2.176685333251953,\n",
       "  1.977384328842163,\n",
       "  1.9892339706420898,\n",
       "  2.000995635986328,\n",
       "  1.9053254127502441,\n",
       "  2.2790327072143555,\n",
       "  1.957041621208191,\n",
       "  2.011831521987915,\n",
       "  2.236751079559326,\n",
       "  2.352475166320801,\n",
       "  2.0791144371032715,\n",
       "  2.482534170150757,\n",
       "  1.9237045049667358,\n",
       "  2.3806612491607666,\n",
       "  2.0226335525512695,\n",
       "  2.0658888816833496,\n",
       "  2.3989133834838867,\n",
       "  2.0721611976623535,\n",
       "  2.0489306449890137,\n",
       "  1.9901807308197021,\n",
       "  1.9709502458572388,\n",
       "  2.2345876693725586,\n",
       "  2.2439796924591064,\n",
       "  1.9191175699234009,\n",
       "  2.161954164505005,\n",
       "  2.223381519317627,\n",
       "  1.977237343788147,\n",
       "  2.05126690864563,\n",
       "  1.9729487895965576,\n",
       "  1.9596501588821411,\n",
       "  2.1183741092681885,\n",
       "  1.8960480690002441,\n",
       "  2.3837051391601562,\n",
       "  2.014815330505371,\n",
       "  2.001908779144287,\n",
       "  1.9698643684387207,\n",
       "  2.2953765392303467,\n",
       "  1.9672399759292603,\n",
       "  2.087435483932495,\n",
       "  2.0936717987060547,\n",
       "  1.9609456062316895,\n",
       "  2.116490125656128,\n",
       "  2.361628770828247,\n",
       "  2.112208604812622,\n",
       "  2.169358015060425,\n",
       "  2.111457347869873,\n",
       "  1.920580267906189,\n",
       "  2.35224986076355,\n",
       "  2.121143102645874,\n",
       "  2.1465611457824707,\n",
       "  2.1210992336273193,\n",
       "  2.010465145111084,\n",
       "  2.530003547668457,\n",
       "  2.043726682662964,\n",
       "  2.1097893714904785,\n",
       "  1.9839942455291748,\n",
       "  2.1946685314178467,\n",
       "  2.0587828159332275,\n",
       "  2.1156511306762695,\n",
       "  2.03737473487854,\n",
       "  2.043205976486206,\n",
       "  2.074028491973877,\n",
       "  2.007749319076538,\n",
       "  2.220581293106079,\n",
       "  2.1873297691345215,\n",
       "  2.031604528427124,\n",
       "  2.010450839996338,\n",
       "  2.1330947875976562,\n",
       "  2.041640520095825,\n",
       "  2.042722702026367,\n",
       "  1.920575737953186,\n",
       "  2.089421510696411,\n",
       "  2.025636911392212,\n",
       "  2.0370044708251953,\n",
       "  2.256315231323242,\n",
       "  2.192943572998047,\n",
       "  1.9535003900527954,\n",
       "  2.062426805496216,\n",
       "  2.0775208473205566,\n",
       "  1.8155251741409302,\n",
       "  1.9259127378463745,\n",
       "  1.9547333717346191,\n",
       "  2.0129544734954834,\n",
       "  2.0861599445343018,\n",
       "  1.9038610458374023,\n",
       "  2.071131944656372,\n",
       "  2.0561587810516357,\n",
       "  2.0110771656036377,\n",
       "  2.161367654800415,\n",
       "  2.236163377761841,\n",
       "  1.979843258857727,\n",
       "  2.0621120929718018,\n",
       "  2.1448521614074707,\n",
       "  2.1052606105804443,\n",
       "  2.1258232593536377,\n",
       "  2.175753116607666,\n",
       "  2.0812759399414062,\n",
       "  2.1136515140533447,\n",
       "  2.171795129776001,\n",
       "  2.0649685859680176,\n",
       "  2.1958470344543457,\n",
       "  1.9920461177825928,\n",
       "  2.1600358486175537,\n",
       "  1.9644440412521362,\n",
       "  2.0872581005096436,\n",
       "  2.034140110015869,\n",
       "  2.0637221336364746,\n",
       "  2.142359733581543,\n",
       "  2.030895233154297,\n",
       "  2.0559327602386475,\n",
       "  2.3191652297973633,\n",
       "  2.1003403663635254,\n",
       "  2.04067063331604,\n",
       "  1.95392906665802,\n",
       "  2.0300652980804443,\n",
       "  1.953790545463562,\n",
       "  1.9304072856903076,\n",
       "  2.1146273612976074,\n",
       "  2.1801857948303223,\n",
       "  2.118908405303955,\n",
       "  2.06465482711792,\n",
       "  2.2003860473632812,\n",
       "  2.0458054542541504,\n",
       "  2.1606853008270264,\n",
       "  1.98668372631073,\n",
       "  2.0353715419769287,\n",
       "  2.0965824127197266,\n",
       "  2.069389820098877,\n",
       "  2.001660108566284,\n",
       "  2.2163639068603516,\n",
       "  2.052898406982422,\n",
       "  2.144683837890625,\n",
       "  2.0602264404296875,\n",
       "  2.0475518703460693,\n",
       "  2.13002872467041,\n",
       "  2.201586961746216,\n",
       "  2.26505184173584,\n",
       "  2.372602701187134,\n",
       "  2.119326114654541,\n",
       "  2.270212411880493,\n",
       "  2.2914628982543945,\n",
       "  2.2336912155151367,\n",
       "  2.2267634868621826,\n",
       "  2.2770259380340576,\n",
       "  2.1645002365112305,\n",
       "  2.082777976989746,\n",
       "  2.0272045135498047,\n",
       "  2.1489038467407227,\n",
       "  2.067511558532715,\n",
       "  2.166745662689209,\n",
       "  2.1998817920684814,\n",
       "  2.1328842639923096,\n",
       "  2.102008104324341,\n",
       "  2.045912265777588,\n",
       "  2.053987979888916,\n",
       "  2.2751145362854004,\n",
       "  2.2923638820648193,\n",
       "  2.1351306438446045,\n",
       "  2.189835548400879,\n",
       "  2.145253896713257,\n",
       "  2.1468005180358887,\n",
       "  2.08760142326355,\n",
       "  2.142971992492676,\n",
       "  2.114133596420288,\n",
       "  2.1250202655792236,\n",
       "  2.11604905128479,\n",
       "  2.0575010776519775,\n",
       "  2.2068841457366943,\n",
       "  2.417452335357666,\n",
       "  2.0496275424957275,\n",
       "  2.321276903152466,\n",
       "  2.1213979721069336,\n",
       "  2.031299591064453,\n",
       "  2.089991569519043,\n",
       "  2.1082160472869873,\n",
       "  2.1035547256469727,\n",
       "  2.3631539344787598,\n",
       "  2.1842424869537354,\n",
       "  2.1793439388275146,\n",
       "  2.1795706748962402,\n",
       "  2.2032670974731445,\n",
       "  2.0634849071502686,\n",
       "  2.2079832553863525,\n",
       "  2.1200952529907227,\n",
       "  2.2284655570983887,\n",
       "  2.068460702896118,\n",
       "  2.1909968852996826,\n",
       "  2.34932541847229,\n",
       "  2.187178611755371,\n",
       "  2.1077141761779785,\n",
       "  2.0673091411590576,\n",
       "  2.292551040649414,\n",
       "  2.068185806274414,\n",
       "  2.2700536251068115,\n",
       "  2.2935776710510254,\n",
       "  2.317298412322998,\n",
       "  2.168750047683716,\n",
       "  2.176490306854248,\n",
       "  2.2705137729644775,\n",
       "  2.128269910812378,\n",
       "  2.253267526626587,\n",
       "  2.189182996749878,\n",
       "  2.0861215591430664,\n",
       "  2.1861488819122314,\n",
       "  2.195852518081665,\n",
       "  2.2617571353912354,\n",
       "  2.1505990028381348,\n",
       "  2.239455223083496,\n",
       "  2.2616238594055176,\n",
       "  2.1945693492889404,\n",
       "  2.1106886863708496,\n",
       "  2.313260316848755,\n",
       "  2.1589150428771973,\n",
       "  2.2205843925476074,\n",
       "  2.297818899154663,\n",
       "  2.1820318698883057,\n",
       "  2.139280319213867,\n",
       "  2.454371452331543,\n",
       "  2.3711178302764893,\n",
       "  2.225062847137451,\n",
       "  2.163821220397949,\n",
       "  2.310889720916748,\n",
       "  2.2142333984375,\n",
       "  2.3965160846710205,\n",
       "  2.1436843872070312,\n",
       "  2.1645867824554443,\n",
       "  2.234487295150757,\n",
       "  2.3453786373138428,\n",
       "  2.233628988265991,\n",
       "  2.3424127101898193,\n",
       "  2.6437630653381348,\n",
       "  2.328425884246826,\n",
       "  2.117692232131958,\n",
       "  2.2749667167663574,\n",
       "  2.1900389194488525,\n",
       "  2.374105930328369,\n",
       "  2.5159683227539062,\n",
       "  2.2280781269073486,\n",
       "  2.3821160793304443,\n",
       "  2.2910990715026855,\n",
       "  2.2654025554656982,\n",
       "  2.2312355041503906,\n",
       "  2.226597785949707,\n",
       "  2.1767690181732178,\n",
       "  2.4171531200408936,\n",
       "  2.273977041244507,\n",
       "  2.235438585281372,\n",
       "  2.1789305210113525,\n",
       "  2.3682074546813965,\n",
       "  2.2454190254211426,\n",
       "  2.2173573970794678,\n",
       "  2.333958625793457,\n",
       "  2.2060446739196777,\n",
       "  2.2416141033172607,\n",
       "  2.3124053478240967,\n",
       "  2.0688703060150146,\n",
       "  2.212998390197754,\n",
       "  2.1218338012695312,\n",
       "  2.2765285968780518,\n",
       "  2.322742462158203,\n",
       "  2.222285032272339,\n",
       "  2.4201650619506836,\n",
       "  2.2741355895996094,\n",
       "  2.192917585372925,\n",
       "  2.256364107131958,\n",
       "  2.2499024868011475,\n",
       "  2.2833921909332275,\n",
       "  2.1657278537750244,\n",
       "  2.1234207153320312,\n",
       "  2.247786283493042,\n",
       "  2.2564146518707275,\n",
       "  2.2912447452545166,\n",
       "  2.3249475955963135,\n",
       "  2.247913360595703,\n",
       "  2.3266615867614746,\n",
       "  2.2187981605529785,\n",
       "  2.306225061416626,\n",
       "  2.2582883834838867,\n",
       "  2.1754939556121826,\n",
       "  2.1729254722595215,\n",
       "  2.1903367042541504,\n",
       "  2.5752718448638916,\n",
       "  2.297603130340576,\n",
       "  2.262150764465332,\n",
       "  2.2307467460632324,\n",
       "  2.344144344329834,\n",
       "  2.1907403469085693,\n",
       "  2.461564064025879,\n",
       "  2.334900140762329,\n",
       "  2.358069658279419,\n",
       "  2.2930638790130615,\n",
       "  2.422929286956787,\n",
       "  2.404689073562622,\n",
       "  2.2799735069274902,\n",
       "  2.2275891304016113,\n",
       "  2.3456671237945557,\n",
       "  2.1364548206329346,\n",
       "  2.1481757164001465,\n",
       "  2.1599042415618896,\n",
       "  2.4415879249572754,\n",
       "  2.215592384338379,\n",
       "  2.2642478942871094,\n",
       "  2.276616096496582,\n",
       "  2.3432891368865967,\n",
       "  2.273934841156006,\n",
       "  2.42069411277771,\n",
       "  2.286867141723633,\n",
       "  2.287903070449829,\n",
       "  2.274534225463867,\n",
       "  2.1390745639801025,\n",
       "  2.2979750633239746,\n",
       "  2.2664363384246826,\n",
       "  2.396364212036133,\n",
       "  2.2905421257019043,\n",
       "  2.3468120098114014,\n",
       "  2.194859266281128,\n",
       "  2.2903642654418945,\n",
       "  2.3651771545410156,\n",
       "  2.2593882083892822,\n",
       "  2.218557596206665,\n",
       "  2.4242424964904785,\n",
       "  2.1776320934295654,\n",
       "  2.307765483856201,\n",
       "  2.3320891857147217,\n",
       "  2.19138765335083,\n",
       "  2.4096970558166504,\n",
       "  2.4202795028686523,\n",
       "  2.340399742126465,\n",
       "  2.3856475353240967,\n",
       "  2.3487517833709717,\n",
       "  2.263108253479004,\n",
       "  2.53061842918396,\n",
       "  2.2125139236450195,\n",
       "  2.306490421295166,\n",
       "  2.149186134338379,\n",
       "  2.2220065593719482,\n",
       "  2.3303256034851074,\n",
       "  2.4149892330169678,\n",
       "  2.4225168228149414,\n",
       "  2.19560170173645,\n",
       "  2.282721519470215,\n",
       "  2.4017364978790283,\n",
       "  2.2703640460968018],\n",
       " [4.02976131439209,\n",
       "  3.258894920349121,\n",
       "  2.9208738803863525,\n",
       "  2.7571029663085938,\n",
       "  2.8744168281555176,\n",
       "  2.7060844898223877,\n",
       "  2.9838621616363525,\n",
       "  2.9202866554260254,\n",
       "  2.6189043521881104,\n",
       "  2.5700104236602783,\n",
       "  2.7901973724365234,\n",
       "  2.6035821437835693,\n",
       "  2.5882070064544678,\n",
       "  2.5664634704589844,\n",
       "  2.629063367843628,\n",
       "  2.5080690383911133,\n",
       "  2.5276882648468018,\n",
       "  2.653536558151245,\n",
       "  2.7064075469970703,\n",
       "  2.6379153728485107,\n",
       "  2.6252689361572266,\n",
       "  2.680731773376465,\n",
       "  2.536160707473755,\n",
       "  2.5416038036346436,\n",
       "  2.4695961475372314,\n",
       "  2.445094585418701,\n",
       "  2.4628450870513916,\n",
       "  2.6288132667541504,\n",
       "  2.377988338470459,\n",
       "  2.2735440731048584,\n",
       "  2.6777162551879883,\n",
       "  2.4521243572235107,\n",
       "  2.2879226207733154,\n",
       "  2.5017693042755127,\n",
       "  2.2766597270965576,\n",
       "  2.3536078929901123,\n",
       "  2.3113837242126465,\n",
       "  2.6853411197662354,\n",
       "  2.4280340671539307,\n",
       "  2.3667800426483154,\n",
       "  2.621485710144043,\n",
       "  2.1851742267608643,\n",
       "  2.5781593322753906,\n",
       "  2.351654291152954,\n",
       "  2.651689291000366,\n",
       "  2.3899712562561035,\n",
       "  2.577547788619995,\n",
       "  2.4785683155059814,\n",
       "  2.3249011039733887,\n",
       "  2.682737112045288,\n",
       "  2.628962516784668,\n",
       "  2.585191488265991,\n",
       "  2.3905413150787354,\n",
       "  2.2602548599243164,\n",
       "  2.518716335296631,\n",
       "  2.4369819164276123,\n",
       "  2.339890956878662,\n",
       "  2.9538826942443848,\n",
       "  2.2599802017211914,\n",
       "  2.2015621662139893,\n",
       "  2.3595008850097656,\n",
       "  2.2701656818389893,\n",
       "  2.662653923034668,\n",
       "  2.348234176635742,\n",
       "  2.6385927200317383,\n",
       "  2.19342041015625,\n",
       "  2.237201690673828,\n",
       "  2.2857720851898193,\n",
       "  2.4853577613830566,\n",
       "  2.266652822494507,\n",
       "  2.4135186672210693,\n",
       "  2.273190975189209,\n",
       "  2.3665096759796143,\n",
       "  2.421248435974121,\n",
       "  2.398996114730835,\n",
       "  2.8397293090820312,\n",
       "  2.3165838718414307,\n",
       "  2.635272264480591,\n",
       "  2.4306793212890625,\n",
       "  2.9378914833068848,\n",
       "  2.665112257003784,\n",
       "  2.4457850456237793,\n",
       "  2.4914112091064453,\n",
       "  2.768968343734741,\n",
       "  2.350029945373535,\n",
       "  2.502223491668701,\n",
       "  2.60089111328125,\n",
       "  2.4799864292144775,\n",
       "  2.474388360977173,\n",
       "  2.4514920711517334,\n",
       "  2.511622428894043,\n",
       "  2.7713727951049805,\n",
       "  2.6539995670318604,\n",
       "  2.801692247390747,\n",
       "  2.762133836746216,\n",
       "  2.6649112701416016,\n",
       "  2.911592483520508,\n",
       "  2.7774713039398193,\n",
       "  2.4989802837371826,\n",
       "  2.470186233520508,\n",
       "  2.520427942276001,\n",
       "  2.439037561416626,\n",
       "  2.8229165077209473,\n",
       "  2.9320755004882812,\n",
       "  2.431710958480835,\n",
       "  2.6054069995880127,\n",
       "  2.7956578731536865,\n",
       "  2.7771754264831543,\n",
       "  2.913957118988037,\n",
       "  2.9283454418182373,\n",
       "  2.8123323917388916,\n",
       "  2.750091314315796,\n",
       "  2.906697988510132,\n",
       "  2.772353172302246,\n",
       "  3.1563103199005127,\n",
       "  2.8097522258758545,\n",
       "  2.95900559425354,\n",
       "  2.678070306777954,\n",
       "  2.8408429622650146,\n",
       "  2.930016279220581,\n",
       "  2.879138946533203,\n",
       "  2.9558510780334473,\n",
       "  2.7573649883270264,\n",
       "  3.0395193099975586,\n",
       "  2.909665584564209,\n",
       "  2.857705593109131,\n",
       "  2.726146697998047,\n",
       "  3.088472366333008,\n",
       "  2.8958218097686768,\n",
       "  2.8394479751586914,\n",
       "  3.0183358192443848,\n",
       "  2.9400410652160645,\n",
       "  2.849032163619995,\n",
       "  2.9831957817077637,\n",
       "  2.7017722129821777,\n",
       "  3.0678470134735107,\n",
       "  2.9211630821228027,\n",
       "  2.98787522315979,\n",
       "  2.9426465034484863,\n",
       "  3.0452165603637695,\n",
       "  3.1478798389434814,\n",
       "  3.2557907104492188,\n",
       "  2.8849971294403076,\n",
       "  3.297797679901123,\n",
       "  2.926945209503174,\n",
       "  2.8661069869995117,\n",
       "  3.131805658340454,\n",
       "  3.125743865966797,\n",
       "  2.9007351398468018,\n",
       "  2.876873016357422,\n",
       "  3.222963571548462,\n",
       "  3.059516191482544,\n",
       "  2.983844041824341,\n",
       "  3.312314748764038,\n",
       "  3.087099552154541,\n",
       "  3.2423806190490723,\n",
       "  2.9147911071777344,\n",
       "  3.323634386062622,\n",
       "  3.0976803302764893,\n",
       "  3.1453371047973633,\n",
       "  3.6551594734191895,\n",
       "  3.148635149002075,\n",
       "  3.01094913482666,\n",
       "  3.130427598953247,\n",
       "  2.973647356033325,\n",
       "  2.9346776008605957,\n",
       "  3.0645766258239746,\n",
       "  3.0290286540985107,\n",
       "  3.2343060970306396,\n",
       "  3.062471628189087,\n",
       "  3.2978451251983643,\n",
       "  3.337106227874756,\n",
       "  3.021383047103882,\n",
       "  3.075277090072632,\n",
       "  3.009331226348877,\n",
       "  3.363767385482788,\n",
       "  3.053274631500244,\n",
       "  3.5128254890441895,\n",
       "  3.268073081970215,\n",
       "  3.2825522422790527,\n",
       "  3.6748950481414795,\n",
       "  3.407996654510498,\n",
       "  3.1004953384399414,\n",
       "  2.981881618499756,\n",
       "  3.427628517150879,\n",
       "  2.976430654525757,\n",
       "  3.0526318550109863,\n",
       "  2.987452983856201,\n",
       "  3.333096742630005,\n",
       "  3.4241244792938232,\n",
       "  3.0761101245880127,\n",
       "  3.1370654106140137,\n",
       "  3.1526310443878174,\n",
       "  3.643584966659546,\n",
       "  3.303483486175537,\n",
       "  3.138338327407837,\n",
       "  3.111515998840332,\n",
       "  3.3551228046417236,\n",
       "  3.5416767597198486,\n",
       "  3.4516046047210693,\n",
       "  3.3250787258148193,\n",
       "  3.2417328357696533,\n",
       "  3.1714396476745605,\n",
       "  3.337162733078003,\n",
       "  3.170220136642456,\n",
       "  3.4702422618865967,\n",
       "  3.110172748565674,\n",
       "  3.13614821434021,\n",
       "  3.350008726119995,\n",
       "  2.9460649490356445,\n",
       "  2.985337018966675,\n",
       "  3.303678512573242,\n",
       "  3.0175468921661377,\n",
       "  3.096250534057617,\n",
       "  3.3035888671875,\n",
       "  3.2193095684051514,\n",
       "  3.4049007892608643,\n",
       "  3.2723865509033203,\n",
       "  3.180459499359131,\n",
       "  3.0023598670959473,\n",
       "  2.910259485244751,\n",
       "  2.9837377071380615,\n",
       "  3.1738440990448,\n",
       "  2.9881491661071777,\n",
       "  3.1952898502349854,\n",
       "  2.8174614906311035,\n",
       "  3.2416419982910156,\n",
       "  3.0868258476257324,\n",
       "  3.2842814922332764,\n",
       "  3.135791540145874,\n",
       "  3.3346245288848877,\n",
       "  2.8808414936065674,\n",
       "  3.243617057800293,\n",
       "  2.973597764968872,\n",
       "  3.290815830230713,\n",
       "  3.1612472534179688,\n",
       "  3.158442974090576,\n",
       "  3.1875662803649902,\n",
       "  3.3043978214263916,\n",
       "  3.046308994293213,\n",
       "  3.1682932376861572,\n",
       "  2.9785022735595703,\n",
       "  3.0907583236694336,\n",
       "  3.2137396335601807,\n",
       "  2.845263719558716,\n",
       "  3.273049831390381,\n",
       "  3.0837650299072266,\n",
       "  3.325144052505493,\n",
       "  2.7870140075683594,\n",
       "  3.1420087814331055,\n",
       "  3.048745632171631,\n",
       "  3.2012226581573486,\n",
       "  3.359222173690796,\n",
       "  3.482678174972534,\n",
       "  2.9184036254882812,\n",
       "  3.085691452026367,\n",
       "  3.169797420501709,\n",
       "  2.9764177799224854,\n",
       "  3.170609474182129,\n",
       "  3.3977479934692383,\n",
       "  2.926727056503296,\n",
       "  3.23361873626709,\n",
       "  3.079967737197876,\n",
       "  3.251662492752075,\n",
       "  3.2733752727508545,\n",
       "  3.077488422393799,\n",
       "  3.2226738929748535,\n",
       "  3.1860620975494385,\n",
       "  2.9512240886688232,\n",
       "  3.1339359283447266,\n",
       "  2.9946048259735107,\n",
       "  3.1237599849700928,\n",
       "  3.0497772693634033,\n",
       "  3.0259385108947754,\n",
       "  3.3695218563079834,\n",
       "  3.302126407623291,\n",
       "  3.0982046127319336,\n",
       "  2.724531412124634,\n",
       "  3.3253567218780518,\n",
       "  2.855421304702759,\n",
       "  3.1559252738952637,\n",
       "  2.9530110359191895,\n",
       "  3.0913844108581543,\n",
       "  2.931530714035034,\n",
       "  3.0098931789398193,\n",
       "  3.3590550422668457,\n",
       "  3.008831024169922,\n",
       "  3.0066301822662354,\n",
       "  3.0640316009521484,\n",
       "  3.0421323776245117,\n",
       "  3.1407361030578613,\n",
       "  3.120851516723633,\n",
       "  3.1742076873779297,\n",
       "  2.9651310443878174,\n",
       "  2.903571128845215,\n",
       "  3.083247184753418,\n",
       "  3.2006189823150635,\n",
       "  2.999110221862793,\n",
       "  2.996927499771118,\n",
       "  2.9518043994903564,\n",
       "  2.9998104572296143,\n",
       "  2.9584059715270996,\n",
       "  3.0693631172180176,\n",
       "  2.7720348834991455,\n",
       "  2.926361083984375,\n",
       "  2.825638771057129,\n",
       "  2.841478109359741,\n",
       "  3.2307636737823486,\n",
       "  2.852715253829956,\n",
       "  2.9847514629364014,\n",
       "  3.1488046646118164,\n",
       "  3.364863634109497,\n",
       "  3.007469654083252,\n",
       "  3.07023549079895,\n",
       "  2.8684356212615967,\n",
       "  2.908965826034546,\n",
       "  2.9108095169067383,\n",
       "  3.106353998184204,\n",
       "  2.910987138748169,\n",
       "  3.1355414390563965,\n",
       "  2.9474151134490967,\n",
       "  2.9527928829193115,\n",
       "  3.050283193588257,\n",
       "  2.797736644744873,\n",
       "  3.053818702697754,\n",
       "  3.3279223442077637,\n",
       "  2.9138996601104736,\n",
       "  3.025641918182373,\n",
       "  3.231901168823242,\n",
       "  3.1397287845611572,\n",
       "  3.2449986934661865,\n",
       "  3.056842803955078,\n",
       "  2.9232306480407715,\n",
       "  3.05440616607666,\n",
       "  2.9106340408325195,\n",
       "  2.679677724838257,\n",
       "  2.9473214149475098,\n",
       "  2.905445098876953,\n",
       "  2.8969593048095703,\n",
       "  2.8373796939849854,\n",
       "  3.0263702869415283,\n",
       "  3.2824466228485107,\n",
       "  2.9552536010742188,\n",
       "  2.8201258182525635,\n",
       "  2.8035387992858887,\n",
       "  3.088993787765503,\n",
       "  3.101808547973633,\n",
       "  3.1881091594696045,\n",
       "  3.0839414596557617,\n",
       "  3.1856346130371094,\n",
       "  3.0307202339172363,\n",
       "  3.1210529804229736,\n",
       "  3.000994920730591,\n",
       "  2.8520500659942627,\n",
       "  2.935525417327881,\n",
       "  2.837127923965454,\n",
       "  2.9104208946228027,\n",
       "  2.961690664291382,\n",
       "  3.0644428730010986,\n",
       "  2.8250205516815186,\n",
       "  3.0781970024108887,\n",
       "  2.8046746253967285,\n",
       "  3.321842670440674,\n",
       "  2.7854549884796143,\n",
       "  2.8488612174987793,\n",
       "  2.8794891834259033,\n",
       "  2.9727907180786133,\n",
       "  3.1049320697784424,\n",
       "  3.0405690670013428,\n",
       "  2.991206645965576,\n",
       "  3.056900978088379,\n",
       "  3.0956292152404785,\n",
       "  3.0540192127227783,\n",
       "  2.960793972015381,\n",
       "  2.946347951889038,\n",
       "  2.986602544784546,\n",
       "  3.0494983196258545,\n",
       "  2.913853168487549,\n",
       "  3.066615104675293,\n",
       "  3.0002849102020264,\n",
       "  2.976691484451294,\n",
       "  2.9447689056396484,\n",
       "  3.051513671875,\n",
       "  2.963134527206421,\n",
       "  3.0382137298583984,\n",
       "  3.064891815185547,\n",
       "  2.952209711074829,\n",
       "  2.8465733528137207,\n",
       "  3.0696494579315186,\n",
       "  3.0283865928649902,\n",
       "  2.899941921234131,\n",
       "  3.14406418800354,\n",
       "  3.030594825744629,\n",
       "  2.8550755977630615,\n",
       "  3.0574898719787598,\n",
       "  3.097031593322754,\n",
       "  2.775425434112549,\n",
       "  3.093782901763916,\n",
       "  3.1888458728790283,\n",
       "  2.863900661468506,\n",
       "  3.1569323539733887,\n",
       "  2.75044846534729,\n",
       "  2.903806209564209,\n",
       "  3.0734691619873047,\n",
       "  2.9218130111694336,\n",
       "  2.829456329345703,\n",
       "  2.7894647121429443,\n",
       "  2.7560360431671143,\n",
       "  2.806774139404297,\n",
       "  2.9034311771392822,\n",
       "  2.8249919414520264,\n",
       "  2.9581713676452637,\n",
       "  2.9592673778533936,\n",
       "  3.000425100326538,\n",
       "  2.8627262115478516,\n",
       "  2.899109125137329,\n",
       "  2.681412696838379,\n",
       "  2.707951068878174,\n",
       "  2.9287045001983643,\n",
       "  2.6891684532165527,\n",
       "  2.743842601776123,\n",
       "  2.857802629470825,\n",
       "  2.9039828777313232,\n",
       "  3.0355801582336426,\n",
       "  3.0834360122680664,\n",
       "  2.8967158794403076,\n",
       "  3.161858081817627,\n",
       "  3.0258126258850098,\n",
       "  2.871920347213745,\n",
       "  2.7966530323028564,\n",
       "  2.7674686908721924,\n",
       "  2.878695249557495,\n",
       "  2.9709203243255615,\n",
       "  3.119931697845459,\n",
       "  2.904228687286377,\n",
       "  2.924921989440918,\n",
       "  2.733189344406128,\n",
       "  2.6455190181732178,\n",
       "  2.9616689682006836,\n",
       "  2.757836103439331,\n",
       "  2.98709774017334,\n",
       "  3.006459951400757,\n",
       "  2.8419456481933594,\n",
       "  3.181867837905884,\n",
       "  3.0872626304626465,\n",
       "  3.0588274002075195,\n",
       "  3.166541576385498,\n",
       "  3.1239676475524902,\n",
       "  2.8800160884857178,\n",
       "  2.8349251747131348,\n",
       "  2.940575361251831,\n",
       "  3.0927250385284424,\n",
       "  3.1312038898468018,\n",
       "  2.772153615951538,\n",
       "  3.131450891494751,\n",
       "  2.8460628986358643,\n",
       "  2.995326280593872,\n",
       "  3.018080949783325,\n",
       "  2.9827370643615723,\n",
       "  3.031325578689575,\n",
       "  3.0073676109313965,\n",
       "  3.031327724456787,\n",
       "  2.9297566413879395,\n",
       "  2.9381678104400635,\n",
       "  2.8348467350006104,\n",
       "  2.9366612434387207,\n",
       "  3.1520895957946777,\n",
       "  3.100511312484741,\n",
       "  2.9977962970733643,\n",
       "  3.0769097805023193,\n",
       "  2.8079464435577393,\n",
       "  2.9942753314971924,\n",
       "  3.0134050846099854,\n",
       "  2.9985873699188232,\n",
       "  3.1535215377807617,\n",
       "  3.1097934246063232,\n",
       "  3.0055384635925293,\n",
       "  3.1285345554351807,\n",
       "  3.2663872241973877,\n",
       "  3.001169443130493,\n",
       "  3.026881217956543,\n",
       "  3.143777370452881,\n",
       "  2.893813371658325,\n",
       "  2.8586509227752686,\n",
       "  2.7587947845458984,\n",
       "  2.9071269035339355,\n",
       "  2.7700023651123047,\n",
       "  3.0154807567596436,\n",
       "  2.663320779800415,\n",
       "  2.9081976413726807,\n",
       "  2.956569194793701,\n",
       "  2.9260201454162598,\n",
       "  2.918797492980957,\n",
       "  3.102102041244507,\n",
       "  3.083850860595703,\n",
       "  2.7759454250335693,\n",
       "  2.8382322788238525,\n",
       "  3.0399882793426514,\n",
       "  2.9708728790283203,\n",
       "  2.900299072265625],\n",
       " [4.219700813293457,\n",
       "  3.248889207839966,\n",
       "  2.9988958835601807,\n",
       "  2.9327919483184814,\n",
       "  2.6964356899261475,\n",
       "  2.6333391666412354,\n",
       "  2.686828851699829,\n",
       "  2.6184024810791016,\n",
       "  2.655109405517578,\n",
       "  2.9007740020751953,\n",
       "  2.7162318229675293,\n",
       "  2.9176011085510254,\n",
       "  2.4138453006744385,\n",
       "  2.5567119121551514,\n",
       "  2.585597515106201,\n",
       "  2.4535205364227295,\n",
       "  2.513653039932251,\n",
       "  2.8877644538879395,\n",
       "  2.5373175144195557,\n",
       "  2.5838942527770996,\n",
       "  2.6728765964508057,\n",
       "  2.810107946395874,\n",
       "  2.528928279876709,\n",
       "  2.58832049369812,\n",
       "  2.5356287956237793,\n",
       "  2.610116720199585,\n",
       "  2.7650530338287354,\n",
       "  2.425616502761841,\n",
       "  2.6026461124420166,\n",
       "  2.6292381286621094,\n",
       "  2.6037397384643555,\n",
       "  2.348741054534912,\n",
       "  2.4812445640563965,\n",
       "  2.650394916534424,\n",
       "  2.4735465049743652,\n",
       "  2.924137592315674,\n",
       "  2.5267443656921387,\n",
       "  2.4175119400024414,\n",
       "  2.6170542240142822,\n",
       "  2.4562528133392334,\n",
       "  2.660433292388916,\n",
       "  2.662277936935425,\n",
       "  2.4897284507751465,\n",
       "  2.4654650688171387,\n",
       "  2.624311685562134,\n",
       "  2.6785309314727783,\n",
       "  2.5354645252227783,\n",
       "  2.479604721069336,\n",
       "  2.5969161987304688,\n",
       "  2.678748607635498,\n",
       "  2.640108823776245,\n",
       "  2.4386816024780273,\n",
       "  2.661797523498535,\n",
       "  2.615910053253174,\n",
       "  2.5617122650146484,\n",
       "  2.6023828983306885,\n",
       "  2.4840610027313232,\n",
       "  2.492980718612671,\n",
       "  2.7588982582092285,\n",
       "  2.6711535453796387,\n",
       "  2.600161075592041,\n",
       "  2.6532039642333984,\n",
       "  2.9291446208953857,\n",
       "  2.6139614582061768,\n",
       "  2.519944190979004,\n",
       "  2.523855447769165,\n",
       "  2.5628809928894043,\n",
       "  2.5237762928009033,\n",
       "  2.847318649291992,\n",
       "  2.566917896270752,\n",
       "  2.5687451362609863,\n",
       "  2.8296451568603516,\n",
       "  2.558607339859009,\n",
       "  2.752753257751465,\n",
       "  2.5170085430145264,\n",
       "  2.7150018215179443,\n",
       "  2.5713343620300293,\n",
       "  2.7231268882751465,\n",
       "  2.805927038192749,\n",
       "  2.7369134426116943,\n",
       "  2.8217129707336426,\n",
       "  2.6262423992156982,\n",
       "  2.642137289047241,\n",
       "  2.5657994747161865,\n",
       "  2.4968948364257812,\n",
       "  2.6177191734313965,\n",
       "  2.5790460109710693,\n",
       "  2.7433218955993652,\n",
       "  2.9501452445983887,\n",
       "  2.5138676166534424,\n",
       "  2.7563204765319824,\n",
       "  2.5842037200927734,\n",
       "  2.67354679107666,\n",
       "  2.5563931465148926,\n",
       "  2.717463493347168,\n",
       "  2.6150336265563965,\n",
       "  2.6235320568084717,\n",
       "  2.6656837463378906,\n",
       "  2.6481595039367676,\n",
       "  2.6976921558380127,\n",
       "  3.2479777336120605,\n",
       "  2.975611686706543,\n",
       "  2.7907965183258057,\n",
       "  2.589754581451416,\n",
       "  2.6542553901672363,\n",
       "  2.7546443939208984,\n",
       "  2.8285646438598633,\n",
       "  2.651149272918701,\n",
       "  2.699620246887207,\n",
       "  2.576836109161377,\n",
       "  2.6690480709075928,\n",
       "  2.6556835174560547,\n",
       "  2.876634359359741,\n",
       "  2.9145150184631348,\n",
       "  2.709613800048828,\n",
       "  2.6873319149017334,\n",
       "  2.7544307708740234,\n",
       "  2.6152400970458984,\n",
       "  2.8200716972351074,\n",
       "  2.6857402324676514,\n",
       "  2.611034631729126,\n",
       "  2.649181604385376,\n",
       "  2.7542412281036377,\n",
       "  2.8092041015625,\n",
       "  2.8110010623931885,\n",
       "  2.9141745567321777,\n",
       "  2.817136764526367,\n",
       "  2.598243236541748,\n",
       "  2.6494061946868896,\n",
       "  2.702824115753174,\n",
       "  2.6641130447387695,\n",
       "  2.6918516159057617,\n",
       "  2.7507131099700928,\n",
       "  2.7032294273376465,\n",
       "  2.7805020809173584,\n",
       "  2.6813082695007324,\n",
       "  2.7552268505096436,\n",
       "  2.756040334701538,\n",
       "  2.7777931690216064,\n",
       "  2.6696436405181885,\n",
       "  2.8399884700775146,\n",
       "  3.152744770050049,\n",
       "  2.7087929248809814,\n",
       "  2.741943359375,\n",
       "  2.958310842514038,\n",
       "  2.689887285232544,\n",
       "  2.8695878982543945,\n",
       "  2.828774929046631,\n",
       "  2.7556841373443604,\n",
       "  2.7604191303253174,\n",
       "  2.779188632965088,\n",
       "  2.903778076171875,\n",
       "  2.6395511627197266,\n",
       "  2.6480767726898193,\n",
       "  2.6130826473236084,\n",
       "  2.95497727394104,\n",
       "  2.726564645767212,\n",
       "  2.606855869293213,\n",
       "  2.8117713928222656,\n",
       "  2.7458572387695312,\n",
       "  2.947967290878296,\n",
       "  2.519686460494995,\n",
       "  2.6751320362091064,\n",
       "  2.6363742351531982,\n",
       "  2.6359939575195312,\n",
       "  2.592174768447876,\n",
       "  2.724442958831787,\n",
       "  2.7411396503448486,\n",
       "  2.9440433979034424,\n",
       "  3.1425604820251465,\n",
       "  2.678102731704712,\n",
       "  2.668790578842163,\n",
       "  2.750002145767212,\n",
       "  2.6394405364990234,\n",
       "  2.7302370071411133,\n",
       "  2.717325448989868,\n",
       "  2.6414239406585693,\n",
       "  2.684030771255493,\n",
       "  2.6418392658233643,\n",
       "  2.566235303878784,\n",
       "  2.717334032058716,\n",
       "  2.8594892024993896,\n",
       "  2.583080291748047,\n",
       "  2.701413631439209,\n",
       "  2.6100316047668457,\n",
       "  2.689950704574585,\n",
       "  2.8858261108398438,\n",
       "  2.701716661453247,\n",
       "  2.8423163890838623,\n",
       "  2.696173906326294,\n",
       "  2.6998937129974365,\n",
       "  2.7344024181365967,\n",
       "  2.6540582180023193,\n",
       "  2.7039566040039062,\n",
       "  2.4996731281280518,\n",
       "  2.5906736850738525,\n",
       "  2.6967036724090576,\n",
       "  2.6359140872955322,\n",
       "  2.7821648120880127,\n",
       "  2.69061279296875,\n",
       "  2.8513782024383545,\n",
       "  2.6831483840942383,\n",
       "  2.7955334186553955,\n",
       "  2.743210792541504,\n",
       "  2.5268008708953857,\n",
       "  2.597327709197998,\n",
       "  2.7368197441101074,\n",
       "  2.841564416885376,\n",
       "  2.6741585731506348,\n",
       "  2.585444927215576,\n",
       "  2.7145135402679443,\n",
       "  2.8502447605133057,\n",
       "  2.6007936000823975,\n",
       "  2.733370304107666,\n",
       "  2.8277454376220703,\n",
       "  2.5810041427612305,\n",
       "  2.5308005809783936,\n",
       "  2.6404917240142822,\n",
       "  2.673443555831909,\n",
       "  2.6200761795043945,\n",
       "  2.731214761734009,\n",
       "  2.5993118286132812,\n",
       "  2.5602076053619385,\n",
       "  2.698242425918579,\n",
       "  2.518765687942505,\n",
       "  2.6276540756225586,\n",
       "  2.628286838531494,\n",
       "  2.685645341873169,\n",
       "  2.6222639083862305,\n",
       "  2.575284242630005,\n",
       "  2.5698561668395996,\n",
       "  2.633037805557251,\n",
       "  2.7382540702819824,\n",
       "  2.639801263809204,\n",
       "  2.676074743270874,\n",
       "  2.8708183765411377,\n",
       "  2.5055272579193115,\n",
       "  2.6355440616607666,\n",
       "  2.603175163269043,\n",
       "  2.6451733112335205,\n",
       "  2.781175136566162,\n",
       "  2.579882860183716,\n",
       "  2.664862632751465,\n",
       "  2.7276155948638916,\n",
       "  2.6446533203125,\n",
       "  2.640763282775879,\n",
       "  2.55031418800354,\n",
       "  2.5071702003479004,\n",
       "  2.5423731803894043,\n",
       "  2.4463934898376465,\n",
       "  2.6240134239196777,\n",
       "  2.6187970638275146,\n",
       "  2.6076316833496094,\n",
       "  2.654575824737549,\n",
       "  2.670858860015869,\n",
       "  2.5506227016448975,\n",
       "  2.511676788330078,\n",
       "  2.5385582447052,\n",
       "  2.628713846206665,\n",
       "  2.6174232959747314,\n",
       "  2.5790276527404785,\n",
       "  2.551363229751587,\n",
       "  2.524054765701294,\n",
       "  2.6328859329223633,\n",
       "  2.5904910564422607,\n",
       "  2.568424701690674,\n",
       "  2.607889413833618,\n",
       "  2.5335967540740967,\n",
       "  2.735135555267334,\n",
       "  2.644296169281006,\n",
       "  2.6004490852355957,\n",
       "  2.511345148086548,\n",
       "  2.545304298400879,\n",
       "  2.6024460792541504,\n",
       "  2.785374402999878,\n",
       "  2.6068942546844482,\n",
       "  2.7778990268707275,\n",
       "  2.595304250717163,\n",
       "  2.6775364875793457,\n",
       "  2.5933473110198975,\n",
       "  2.5775065422058105,\n",
       "  2.645573139190674,\n",
       "  2.6149237155914307,\n",
       "  2.5334038734436035,\n",
       "  2.652216911315918,\n",
       "  2.57458758354187,\n",
       "  2.530640125274658,\n",
       "  2.7927348613739014,\n",
       "  2.653203010559082,\n",
       "  2.687329053878784,\n",
       "  2.5264029502868652,\n",
       "  2.7169504165649414,\n",
       "  2.635227680206299,\n",
       "  2.6108410358428955,\n",
       "  2.5980064868927,\n",
       "  2.6043851375579834,\n",
       "  2.6683669090270996,\n",
       "  2.6042747497558594,\n",
       "  2.6342644691467285,\n",
       "  2.736186981201172,\n",
       "  2.5828542709350586,\n",
       "  2.69174861907959,\n",
       "  2.666152238845825,\n",
       "  2.5604407787323,\n",
       "  2.549858570098877,\n",
       "  2.57800555229187,\n",
       "  2.6738486289978027,\n",
       "  2.6621758937835693,\n",
       "  2.6635360717773438,\n",
       "  2.6398675441741943,\n",
       "  2.545295238494873,\n",
       "  2.8255016803741455,\n",
       "  2.4800779819488525,\n",
       "  2.503307819366455,\n",
       "  2.569981336593628,\n",
       "  2.566558599472046,\n",
       "  2.602545976638794,\n",
       "  2.815251350402832,\n",
       "  2.6093411445617676,\n",
       "  2.62408447265625,\n",
       "  2.6501035690307617,\n",
       "  2.6419832706451416,\n",
       "  2.5128333568573,\n",
       "  2.5089380741119385,\n",
       "  2.7023870944976807,\n",
       "  2.62178897857666,\n",
       "  2.63218092918396,\n",
       "  2.682643175125122,\n",
       "  2.634342670440674,\n",
       "  2.5341286659240723,\n",
       "  2.5887210369110107,\n",
       "  2.6053056716918945,\n",
       "  2.6045525074005127,\n",
       "  2.5713491439819336,\n",
       "  2.6854798793792725,\n",
       "  2.5916383266448975,\n",
       "  2.6601691246032715,\n",
       "  2.7754693031311035,\n",
       "  2.617767572402954,\n",
       "  2.6450207233428955,\n",
       "  2.7244157791137695,\n",
       "  2.6715290546417236,\n",
       "  2.7737538814544678,\n",
       "  2.550414800643921,\n",
       "  2.6571319103240967,\n",
       "  2.6651358604431152,\n",
       "  2.655770778656006,\n",
       "  2.733370065689087,\n",
       "  2.6701138019561768,\n",
       "  2.6054203510284424,\n",
       "  2.6243934631347656,\n",
       "  2.655104875564575,\n",
       "  2.647479772567749,\n",
       "  2.6582720279693604,\n",
       "  2.5754363536834717,\n",
       "  2.4586591720581055,\n",
       "  2.5889267921447754,\n",
       "  2.577878952026367,\n",
       "  2.570624828338623,\n",
       "  2.5575180053710938,\n",
       "  2.61899471282959,\n",
       "  2.5304949283599854,\n",
       "  2.5951523780822754,\n",
       "  2.5258750915527344,\n",
       "  2.5923616886138916,\n",
       "  2.658942461013794,\n",
       "  2.6362273693084717,\n",
       "  2.6042168140411377,\n",
       "  2.5376384258270264,\n",
       "  2.5525989532470703,\n",
       "  2.5793182849884033,\n",
       "  2.6018989086151123,\n",
       "  2.605449676513672,\n",
       "  2.7618112564086914,\n",
       "  2.693612813949585,\n",
       "  2.876633405685425,\n",
       "  2.674482822418213,\n",
       "  2.8144280910491943,\n",
       "  2.651474952697754,\n",
       "  2.654543161392212,\n",
       "  2.5392799377441406,\n",
       "  2.6434378623962402,\n",
       "  2.7256641387939453,\n",
       "  2.7454335689544678,\n",
       "  2.630159616470337,\n",
       "  2.6213059425354004,\n",
       "  2.6214590072631836,\n",
       "  2.573276996612549,\n",
       "  2.678194046020508,\n",
       "  2.618774652481079,\n",
       "  2.648347854614258,\n",
       "  2.6735591888427734,\n",
       "  2.6182823181152344,\n",
       "  2.633405923843384,\n",
       "  2.6970081329345703,\n",
       "  2.640044927597046,\n",
       "  2.645655632019043,\n",
       "  2.658667802810669,\n",
       "  2.575967311859131,\n",
       "  2.5995943546295166,\n",
       "  2.809476613998413,\n",
       "  2.5396103858947754,\n",
       "  2.5404891967773438,\n",
       "  2.7178070545196533,\n",
       "  2.76662278175354,\n",
       "  2.6803035736083984,\n",
       "  2.5981285572052,\n",
       "  2.672119379043579,\n",
       "  2.604170799255371,\n",
       "  2.623584508895874,\n",
       "  2.6493849754333496,\n",
       "  2.6796908378601074,\n",
       "  2.6523303985595703,\n",
       "  2.6053905487060547,\n",
       "  2.5889430046081543,\n",
       "  2.604454517364502,\n",
       "  2.5564191341400146,\n",
       "  2.564436435699463,\n",
       "  2.6243646144866943,\n",
       "  2.710919141769409,\n",
       "  2.6176540851593018,\n",
       "  2.6088147163391113,\n",
       "  2.694242238998413,\n",
       "  2.5436785221099854,\n",
       "  2.6413824558258057,\n",
       "  2.65590500831604,\n",
       "  2.5986969470977783,\n",
       "  2.6767897605895996,\n",
       "  2.5969760417938232,\n",
       "  2.6343228816986084,\n",
       "  2.658492088317871,\n",
       "  2.6383440494537354,\n",
       "  2.7042531967163086,\n",
       "  2.5970959663391113,\n",
       "  2.6402883529663086,\n",
       "  2.724680185317993,\n",
       "  2.8945038318634033,\n",
       "  2.8007473945617676,\n",
       "  2.7826550006866455,\n",
       "  2.6691296100616455,\n",
       "  2.6869571208953857,\n",
       "  2.668560743331909,\n",
       "  2.625638246536255,\n",
       "  2.693479299545288,\n",
       "  2.6759588718414307,\n",
       "  2.6600658893585205,\n",
       "  2.5651633739471436,\n",
       "  2.671098232269287,\n",
       "  2.6563503742218018,\n",
       "  2.6548500061035156,\n",
       "  2.592729091644287,\n",
       "  2.6173043251037598,\n",
       "  2.6542792320251465,\n",
       "  2.652928352355957,\n",
       "  2.658968448638916,\n",
       "  2.626518964767456,\n",
       "  2.6266093254089355,\n",
       "  2.642742395401001,\n",
       "  2.593940258026123,\n",
       "  2.687812089920044,\n",
       "  2.55011248588562,\n",
       "  2.6567986011505127,\n",
       "  2.5424749851226807,\n",
       "  2.5536277294158936,\n",
       "  2.5226454734802246,\n",
       "  2.607065439224243,\n",
       "  2.6727521419525146,\n",
       "  2.610379934310913,\n",
       "  2.657811164855957,\n",
       "  2.7111971378326416,\n",
       "  2.557331085205078,\n",
       "  2.5181949138641357,\n",
       "  2.729952335357666,\n",
       "  2.587925434112549,\n",
       "  2.595038414001465,\n",
       "  2.683316946029663,\n",
       "  2.6768648624420166,\n",
       "  2.6601269245147705,\n",
       "  2.618868350982666,\n",
       "  2.7312583923339844,\n",
       "  2.598175048828125,\n",
       "  2.817070484161377,\n",
       "  2.6444530487060547,\n",
       "  2.6406848430633545,\n",
       "  2.717780113220215,\n",
       "  2.6452033519744873,\n",
       "  2.6821208000183105,\n",
       "  2.649625062942505,\n",
       "  2.6697332859039307,\n",
       "  2.8000612258911133,\n",
       "  2.644643545150757,\n",
       "  2.640484571456909,\n",
       "  2.7038865089416504,\n",
       "  2.6612815856933594,\n",
       "  2.7409090995788574,\n",
       "  2.724926710128784,\n",
       "  2.766399383544922,\n",
       "  2.7325327396392822,\n",
       "  2.549633264541626,\n",
       "  2.640681505203247],\n",
       " [4.6397271156311035,\n",
       "  3.363842725753784,\n",
       "  3.1136538982391357,\n",
       "  2.9792721271514893,\n",
       "  2.976030111312866,\n",
       "  3.003058910369873,\n",
       "  2.726698875427246,\n",
       "  3.1360666751861572,\n",
       "  2.8481671810150146,\n",
       "  2.5766868591308594,\n",
       "  2.6238715648651123,\n",
       "  2.493695020675659,\n",
       "  2.5826897621154785,\n",
       "  2.5075807571411133,\n",
       "  2.561372756958008,\n",
       "  2.8423001766204834,\n",
       "  2.568312168121338,\n",
       "  2.427208423614502,\n",
       "  2.5298938751220703,\n",
       "  2.5173909664154053,\n",
       "  2.422870397567749,\n",
       "  2.615527391433716,\n",
       "  2.514080762863159,\n",
       "  2.560713291168213,\n",
       "  2.7506113052368164,\n",
       "  2.375450611114502,\n",
       "  2.4689109325408936,\n",
       "  2.392299175262451,\n",
       "  2.449002742767334,\n",
       "  2.4342784881591797,\n",
       "  2.4503445625305176,\n",
       "  2.5684306621551514,\n",
       "  2.4357690811157227,\n",
       "  2.5313196182250977,\n",
       "  2.526344060897827,\n",
       "  2.703587532043457,\n",
       "  2.5354576110839844,\n",
       "  2.5992026329040527,\n",
       "  2.5463411808013916,\n",
       "  2.515913248062134,\n",
       "  2.5150833129882812,\n",
       "  2.639561414718628,\n",
       "  2.5009617805480957,\n",
       "  2.407827615737915,\n",
       "  2.3559439182281494,\n",
       "  2.625257730484009,\n",
       "  2.7069509029388428,\n",
       "  2.5282981395721436,\n",
       "  2.4497079849243164,\n",
       "  2.375375986099243,\n",
       "  2.4879250526428223,\n",
       "  2.394496440887451,\n",
       "  2.334498643875122,\n",
       "  2.3992040157318115,\n",
       "  2.5270802974700928,\n",
       "  2.6572747230529785,\n",
       "  2.70625376701355,\n",
       "  2.466139078140259,\n",
       "  2.548485279083252,\n",
       "  2.4894661903381348,\n",
       "  2.520305633544922,\n",
       "  2.440612554550171,\n",
       "  2.3912065029144287,\n",
       "  2.6419544219970703,\n",
       "  2.527658700942993,\n",
       "  2.5842816829681396,\n",
       "  2.425144672393799,\n",
       "  2.4485549926757812,\n",
       "  3.017796039581299,\n",
       "  2.3643100261688232,\n",
       "  2.4205799102783203,\n",
       "  2.5267930030822754,\n",
       "  2.502166748046875,\n",
       "  2.3706562519073486,\n",
       "  2.473299503326416,\n",
       "  2.5256121158599854,\n",
       "  2.6045761108398438,\n",
       "  2.425790548324585,\n",
       "  2.668367862701416,\n",
       "  2.744050979614258,\n",
       "  2.456758737564087,\n",
       "  2.502868890762329,\n",
       "  2.4438843727111816,\n",
       "  2.601046323776245,\n",
       "  2.5847585201263428,\n",
       "  2.601640462875366,\n",
       "  2.3825268745422363,\n",
       "  2.787625789642334,\n",
       "  2.6644906997680664,\n",
       "  2.556915521621704,\n",
       "  2.5169291496276855,\n",
       "  2.4984450340270996,\n",
       "  2.564100742340088,\n",
       "  2.8982038497924805,\n",
       "  2.5668485164642334,\n",
       "  2.3295657634735107,\n",
       "  2.5380218029022217,\n",
       "  2.4419236183166504,\n",
       "  2.4792091846466064,\n",
       "  2.4904396533966064,\n",
       "  2.40771484375,\n",
       "  2.4731595516204834,\n",
       "  2.4366564750671387,\n",
       "  2.4978461265563965,\n",
       "  2.3481996059417725,\n",
       "  2.410825252532959,\n",
       "  2.4366519451141357,\n",
       "  2.4271247386932373,\n",
       "  2.4414453506469727,\n",
       "  2.509526252746582,\n",
       "  2.4889965057373047,\n",
       "  2.706172466278076,\n",
       "  2.411616325378418,\n",
       "  2.462096929550171,\n",
       "  2.58691668510437,\n",
       "  2.436563014984131,\n",
       "  2.525312662124634,\n",
       "  2.4181747436523438,\n",
       "  2.6509249210357666,\n",
       "  2.6228106021881104,\n",
       "  2.5332016944885254,\n",
       "  2.8527891635894775,\n",
       "  2.7043895721435547,\n",
       "  2.511399984359741,\n",
       "  2.8697001934051514,\n",
       "  2.482388973236084,\n",
       "  2.361584424972534,\n",
       "  2.5081875324249268,\n",
       "  2.4623348712921143,\n",
       "  2.3980727195739746,\n",
       "  2.4071762561798096,\n",
       "  2.553544044494629,\n",
       "  2.409571409225464,\n",
       "  2.461315155029297,\n",
       "  2.4149880409240723,\n",
       "  2.5741419792175293,\n",
       "  2.4151320457458496,\n",
       "  2.4065890312194824,\n",
       "  2.6434175968170166,\n",
       "  2.475334644317627,\n",
       "  2.3909406661987305,\n",
       "  2.284001350402832,\n",
       "  2.5389678478240967,\n",
       "  2.4910857677459717,\n",
       "  2.4595916271209717,\n",
       "  2.504161834716797,\n",
       "  2.741525888442993,\n",
       "  2.6738922595977783,\n",
       "  2.5361416339874268,\n",
       "  2.6257994174957275,\n",
       "  2.4574270248413086,\n",
       "  2.5231270790100098,\n",
       "  2.5333609580993652,\n",
       "  2.4522311687469482,\n",
       "  2.4856162071228027,\n",
       "  2.6801109313964844,\n",
       "  2.5095226764678955,\n",
       "  2.5044872760772705,\n",
       "  2.4656124114990234,\n",
       "  2.504373073577881,\n",
       "  2.688722848892212,\n",
       "  2.5664334297180176,\n",
       "  2.5861523151397705,\n",
       "  2.424581289291382,\n",
       "  2.473217010498047,\n",
       "  2.471247673034668,\n",
       "  2.4854178428649902,\n",
       "  2.4726788997650146,\n",
       "  2.4459176063537598,\n",
       "  2.617492437362671,\n",
       "  2.7569000720977783,\n",
       "  2.5846707820892334,\n",
       "  2.485848903656006,\n",
       "  2.555130958557129,\n",
       "  2.6663503646850586,\n",
       "  2.5860378742218018,\n",
       "  2.4798424243927,\n",
       "  2.4938132762908936,\n",
       "  2.429741621017456,\n",
       "  2.536931037902832,\n",
       "  2.5183634757995605,\n",
       "  2.552455186843872,\n",
       "  2.570462703704834,\n",
       "  2.4568941593170166,\n",
       "  2.433924913406372,\n",
       "  2.400667667388916,\n",
       "  2.504805088043213,\n",
       "  2.4015839099884033,\n",
       "  2.583545446395874,\n",
       "  2.463874101638794,\n",
       "  2.4631965160369873,\n",
       "  2.4913218021392822,\n",
       "  2.6024184226989746,\n",
       "  2.43294620513916,\n",
       "  2.496276617050171,\n",
       "  2.472879648208618,\n",
       "  2.5855987071990967,\n",
       "  2.580677032470703,\n",
       "  2.721813917160034,\n",
       "  2.4140243530273438,\n",
       "  2.5615384578704834,\n",
       "  2.5439846515655518,\n",
       "  2.7616801261901855,\n",
       "  2.5997540950775146,\n",
       "  2.7629170417785645,\n",
       "  2.6747686862945557,\n",
       "  2.5065627098083496,\n",
       "  2.536303758621216,\n",
       "  2.514380693435669,\n",
       "  2.6508965492248535,\n",
       "  2.526836395263672,\n",
       "  2.6869544982910156,\n",
       "  2.452821731567383,\n",
       "  2.656550884246826,\n",
       "  2.6818394660949707,\n",
       "  2.7002034187316895,\n",
       "  2.5309853553771973,\n",
       "  2.489903688430786,\n",
       "  2.9041125774383545,\n",
       "  2.5216434001922607,\n",
       "  2.671083927154541,\n",
       "  2.412031888961792,\n",
       "  2.4771721363067627,\n",
       "  2.5995254516601562,\n",
       "  2.7326762676239014,\n",
       "  2.6075384616851807,\n",
       "  2.6054892539978027,\n",
       "  2.6524181365966797,\n",
       "  2.696939706802368,\n",
       "  2.4208436012268066,\n",
       "  2.548002243041992,\n",
       "  2.552396059036255,\n",
       "  2.5768773555755615,\n",
       "  2.5431487560272217,\n",
       "  2.542877435684204,\n",
       "  2.651050567626953,\n",
       "  2.4971330165863037,\n",
       "  2.5933315753936768,\n",
       "  2.5474913120269775,\n",
       "  2.4840242862701416,\n",
       "  2.6167452335357666,\n",
       "  2.552198648452759,\n",
       "  2.5183804035186768,\n",
       "  2.7304978370666504,\n",
       "  2.432605504989624,\n",
       "  2.7376482486724854,\n",
       "  2.6996655464172363,\n",
       "  2.6365861892700195,\n",
       "  2.4413845539093018,\n",
       "  2.557328939437866,\n",
       "  2.6093719005584717,\n",
       "  2.764695167541504,\n",
       "  2.666229248046875,\n",
       "  2.6669256687164307,\n",
       "  2.6893811225891113,\n",
       "  2.6074185371398926,\n",
       "  2.5504372119903564,\n",
       "  2.665409564971924,\n",
       "  2.560152769088745,\n",
       "  2.712186574935913,\n",
       "  2.8519020080566406,\n",
       "  2.6490931510925293,\n",
       "  2.690157175064087,\n",
       "  2.62268328666687,\n",
       "  2.707761764526367,\n",
       "  2.5736382007598877,\n",
       "  2.5808796882629395,\n",
       "  2.6154532432556152,\n",
       "  2.634150981903076,\n",
       "  2.5537822246551514,\n",
       "  2.9081478118896484,\n",
       "  2.5405068397521973,\n",
       "  2.6336638927459717,\n",
       "  2.952014207839966,\n",
       "  2.6113338470458984,\n",
       "  2.576321840286255,\n",
       "  2.619995355606079,\n",
       "  2.4970955848693848,\n",
       "  2.6340954303741455,\n",
       "  2.75968337059021,\n",
       "  2.6220004558563232,\n",
       "  2.557497262954712,\n",
       "  2.9465253353118896,\n",
       "  2.7970454692840576,\n",
       "  2.864389181137085,\n",
       "  2.6873292922973633,\n",
       "  2.7550690174102783,\n",
       "  2.677401304244995,\n",
       "  2.7771859169006348,\n",
       "  2.6073780059814453,\n",
       "  2.5567080974578857,\n",
       "  2.7285118103027344,\n",
       "  2.670708179473877,\n",
       "  2.5742077827453613,\n",
       "  2.5680832862854004,\n",
       "  2.5611178874969482,\n",
       "  2.8211376667022705,\n",
       "  2.7681894302368164,\n",
       "  2.6346912384033203,\n",
       "  2.6285600662231445,\n",
       "  2.749013662338257,\n",
       "  2.714520215988159,\n",
       "  2.6773552894592285,\n",
       "  2.8064231872558594,\n",
       "  2.6835436820983887,\n",
       "  2.6870760917663574,\n",
       "  2.6280746459960938,\n",
       "  2.6828792095184326,\n",
       "  2.607977867126465,\n",
       "  2.6280009746551514,\n",
       "  2.614868402481079,\n",
       "  2.608802080154419,\n",
       "  2.747853994369507,\n",
       "  2.556408643722534,\n",
       "  2.907189130783081,\n",
       "  2.5928871631622314,\n",
       "  2.583498477935791,\n",
       "  2.6337780952453613,\n",
       "  2.6364171504974365,\n",
       "  2.6128909587860107,\n",
       "  2.596867322921753,\n",
       "  2.718407154083252,\n",
       "  2.6133904457092285,\n",
       "  2.7189526557922363,\n",
       "  2.657331705093384,\n",
       "  2.647953510284424,\n",
       "  2.771308183670044,\n",
       "  2.901944398880005,\n",
       "  2.6312198638916016,\n",
       "  2.762957811355591,\n",
       "  2.5958712100982666,\n",
       "  3.0719215869903564,\n",
       "  2.7137765884399414,\n",
       "  2.6133782863616943,\n",
       "  2.704620361328125,\n",
       "  2.6969077587127686,\n",
       "  2.8790693283081055,\n",
       "  2.5977299213409424,\n",
       "  2.6763105392456055,\n",
       "  2.6477670669555664,\n",
       "  2.6597275733947754,\n",
       "  2.775918483734131,\n",
       "  2.639392614364624,\n",
       "  2.8708417415618896,\n",
       "  2.5640223026275635,\n",
       "  2.6846423149108887,\n",
       "  2.550781011581421,\n",
       "  2.6394314765930176,\n",
       "  2.745718240737915,\n",
       "  2.569730758666992,\n",
       "  2.5931737422943115,\n",
       "  2.6327810287475586,\n",
       "  2.645768642425537,\n",
       "  2.792473793029785,\n",
       "  2.627385139465332,\n",
       "  2.7191851139068604,\n",
       "  2.5495219230651855,\n",
       "  2.6871538162231445,\n",
       "  2.693686008453369,\n",
       "  2.6761701107025146,\n",
       "  2.7392449378967285,\n",
       "  2.8655295372009277,\n",
       "  2.743185520172119,\n",
       "  2.6900529861450195,\n",
       "  2.8315773010253906,\n",
       "  2.8091654777526855,\n",
       "  2.8421242237091064,\n",
       "  2.838560104370117,\n",
       "  2.6312665939331055,\n",
       "  2.6524360179901123,\n",
       "  2.6791293621063232,\n",
       "  2.7399303913116455,\n",
       "  2.680830955505371,\n",
       "  2.5783252716064453,\n",
       "  2.6316401958465576,\n",
       "  2.7506232261657715,\n",
       "  2.644697666168213,\n",
       "  2.5707364082336426,\n",
       "  2.665433645248413,\n",
       "  2.837322950363159,\n",
       "  2.691141366958618,\n",
       "  2.823435068130493,\n",
       "  2.6802101135253906,\n",
       "  2.7038211822509766,\n",
       "  2.612065315246582,\n",
       "  2.8721485137939453,\n",
       "  2.728013753890991,\n",
       "  2.6880438327789307,\n",
       "  2.783148765563965,\n",
       "  2.6471669673919678,\n",
       "  2.708683490753174,\n",
       "  2.8428356647491455,\n",
       "  2.6961746215820312,\n",
       "  2.7796788215637207,\n",
       "  2.804255962371826,\n",
       "  2.8722150325775146,\n",
       "  2.770751953125,\n",
       "  2.722614049911499,\n",
       "  2.781503438949585,\n",
       "  2.7491612434387207,\n",
       "  2.7816200256347656,\n",
       "  2.8620054721832275,\n",
       "  2.720454454421997,\n",
       "  2.717783212661743,\n",
       "  2.875983715057373,\n",
       "  2.728416919708252,\n",
       "  2.6652281284332275,\n",
       "  2.7812137603759766,\n",
       "  2.7203733921051025,\n",
       "  2.80462384223938,\n",
       "  2.7183125019073486,\n",
       "  2.6749050617218018,\n",
       "  2.745230197906494,\n",
       "  2.7610394954681396,\n",
       "  2.826200008392334,\n",
       "  2.7407121658325195,\n",
       "  2.7206294536590576,\n",
       "  2.7351653575897217,\n",
       "  2.8085336685180664,\n",
       "  2.7999961376190186,\n",
       "  2.7843821048736572,\n",
       "  2.6969783306121826,\n",
       "  2.7976937294006348,\n",
       "  2.760935068130493,\n",
       "  2.73587703704834,\n",
       "  2.720914125442505,\n",
       "  2.7432405948638916,\n",
       "  2.797459125518799,\n",
       "  2.7918636798858643,\n",
       "  2.924314498901367,\n",
       "  2.7804484367370605,\n",
       "  2.7677998542785645,\n",
       "  2.6766581535339355,\n",
       "  2.817946434020996,\n",
       "  2.7272045612335205,\n",
       "  2.687736988067627,\n",
       "  2.755326986312866,\n",
       "  2.6922619342803955,\n",
       "  2.8363962173461914,\n",
       "  2.6678061485290527,\n",
       "  2.8293068408966064,\n",
       "  2.874401092529297,\n",
       "  2.944953441619873,\n",
       "  2.770216226577759,\n",
       "  2.711052894592285,\n",
       "  2.7537004947662354,\n",
       "  2.5960323810577393,\n",
       "  2.706631898880005,\n",
       "  2.7668616771698,\n",
       "  2.7301361560821533,\n",
       "  2.6635355949401855,\n",
       "  2.848896026611328,\n",
       "  2.7339117527008057,\n",
       "  2.7069027423858643,\n",
       "  2.755692958831787,\n",
       "  2.721132755279541,\n",
       "  2.7664096355438232,\n",
       "  2.78229022026062,\n",
       "  2.652529001235962,\n",
       "  2.884711742401123,\n",
       "  2.8718454837799072,\n",
       "  2.738917827606201,\n",
       "  2.6861472129821777,\n",
       "  2.7331840991973877,\n",
       "  2.849247932434082,\n",
       "  2.751232385635376,\n",
       "  2.66019344329834,\n",
       "  2.6823337078094482,\n",
       "  2.7535653114318848,\n",
       "  2.602013111114502,\n",
       "  2.737114667892456,\n",
       "  2.761993646621704,\n",
       "  2.6940226554870605,\n",
       "  2.634899854660034,\n",
       "  2.648953914642334,\n",
       "  2.7646965980529785,\n",
       "  2.69217586517334,\n",
       "  2.724613904953003,\n",
       "  2.6316490173339844,\n",
       "  2.8990747928619385,\n",
       "  2.6900014877319336,\n",
       "  2.696568489074707,\n",
       "  2.7002980709075928,\n",
       "  2.717618227005005,\n",
       "  2.7480309009552,\n",
       "  2.7286014556884766,\n",
       "  2.7002511024475098,\n",
       "  2.7200496196746826,\n",
       "  2.7417922019958496,\n",
       "  2.7646000385284424,\n",
       "  2.668842315673828,\n",
       "  2.806943416595459,\n",
       "  2.583522081375122,\n",
       "  2.7044520378112793,\n",
       "  2.6727688312530518,\n",
       "  2.741530418395996,\n",
       "  2.843883514404297,\n",
       "  2.7366750240325928,\n",
       "  2.677060842514038,\n",
       "  2.7742698192596436]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mae_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_mae_histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.307478666305542"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([x[0] for x in all_mae_histories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.340725421905518"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mae_histories[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.02976131439209"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mae_histories[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.219700813293457"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mae_histories[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6397271156311035"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mae_histories[3][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_mae_history=[\n",
    "    np.mean([x[i] for x in all_mae_histories]) for i in range (num_epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.307478666305542,\n",
       " 3.209743559360504,\n",
       " 2.9496251940727234,\n",
       " 2.8370853662490845,\n",
       " 2.716808021068573,\n",
       " 2.6707561016082764,\n",
       " 2.7148998379707336,\n",
       " 2.757398009300232,\n",
       " 2.7308709025382996,\n",
       " 2.5138482451438904,\n",
       " 2.5558751225471497,\n",
       " 2.4989891946315765,\n",
       " 2.421355426311493,\n",
       " 2.4441094398498535,\n",
       " 2.41944482922554,\n",
       " 2.4836531281471252,\n",
       " 2.4071571826934814,\n",
       " 2.603891432285309,\n",
       " 2.4435792565345764,\n",
       " 2.4634973406791687,\n",
       " 2.4030054211616516,\n",
       " 2.5093315839767456,\n",
       " 2.397344410419464,\n",
       " 2.412203550338745,\n",
       " 2.4498444199562073,\n",
       " 2.3397198617458344,\n",
       " 2.4017581045627594,\n",
       " 2.320363461971283,\n",
       " 2.3430603444576263,\n",
       " 2.367702007293701,\n",
       " 2.425103485584259,\n",
       " 2.2852645218372345,\n",
       " 2.306815505027771,\n",
       " 2.3980661630630493,\n",
       " 2.281287670135498,\n",
       " 2.5229270458221436,\n",
       " 2.278560698032379,\n",
       " 2.38005667924881,\n",
       " 2.4446452856063843,\n",
       " 2.308978110551834,\n",
       " 2.496302008628845,\n",
       " 2.3682365119457245,\n",
       " 2.372512698173523,\n",
       " 2.34921795129776,\n",
       " 2.3804725408554077,\n",
       " 2.371546983718872,\n",
       " 2.4931885600090027,\n",
       " 2.3447524309158325,\n",
       " 2.3271991312503815,\n",
       " 2.3726249039173126,\n",
       " 2.427086442708969,\n",
       " 2.2819178700447083,\n",
       " 2.323717176914215,\n",
       " 2.3392090797424316,\n",
       " 2.3949579000473022,\n",
       " 2.4078544080257416,\n",
       " 2.3563680946826935,\n",
       " 2.5051307678222656,\n",
       " 2.3153490126132965,\n",
       " 2.3157819211483,\n",
       " 2.320852518081665,\n",
       " 2.32830211520195,\n",
       " 2.494647651910782,\n",
       " 2.37159126996994,\n",
       " 2.515446722507477,\n",
       " 2.3072049021720886,\n",
       " 2.297450214624405,\n",
       " 2.287260115146637,\n",
       " 2.553968518972397,\n",
       " 2.3039597272872925,\n",
       " 2.43606299161911,\n",
       " 2.3511746525764465,\n",
       " 2.3142573535442352,\n",
       " 2.351658344268799,\n",
       " 2.3475772738456726,\n",
       " 2.460868388414383,\n",
       " 2.4091153144836426,\n",
       " 2.4731761813163757,\n",
       " 2.421274244785309,\n",
       " 2.6313007473945618,\n",
       " 2.4312315583229065,\n",
       " 2.3315682113170624,\n",
       " 2.327112078666687,\n",
       " 2.5036988854408264,\n",
       " 2.3192162215709686,\n",
       " 2.4406312704086304,\n",
       " 2.367088407278061,\n",
       " 2.4510200917720795,\n",
       " 2.573647141456604,\n",
       " 2.4900256991386414,\n",
       " 2.4138563573360443,\n",
       " 2.4896718859672546,\n",
       " 2.4386949241161346,\n",
       " 2.5491955876350403,\n",
       " 2.483803927898407,\n",
       " 2.347302109003067,\n",
       " 2.5000433921813965,\n",
       " 2.543578624725342,\n",
       " 2.3959862291812897,\n",
       " 2.4240320920944214,\n",
       " 2.7000377774238586,\n",
       " 2.4742332100868225,\n",
       " 2.5152470469474792,\n",
       " 2.543300449848175,\n",
       " 2.3743948936462402,\n",
       " 2.3997907042503357,\n",
       " 2.5002440810203552,\n",
       " 2.471850097179413,\n",
       " 2.5177733302116394,\n",
       " 2.443931132555008,\n",
       " 2.5410220623016357,\n",
       " 2.492525100708008,\n",
       " 2.5485036075115204,\n",
       " 2.532984882593155,\n",
       " 2.5835598409175873,\n",
       " 2.470925807952881,\n",
       " 2.5190301835536957,\n",
       " 2.42811119556427,\n",
       " 2.5718738436698914,\n",
       " 2.5230267345905304,\n",
       " 2.5045315325260162,\n",
       " 2.587187886238098,\n",
       " 2.5411959886550903,\n",
       " 2.637892961502075,\n",
       " 2.654875099658966,\n",
       " 2.6501526832580566,\n",
       " 2.447338730096817,\n",
       " 2.5559802055358887,\n",
       " 2.5976288318634033,\n",
       " 2.5451428294181824,\n",
       " 2.5036542117595673,\n",
       " 2.5865020155906677,\n",
       " 2.5071778893470764,\n",
       " 2.52204492688179,\n",
       " 2.490598201751709,\n",
       " 2.6002049446105957,\n",
       " 2.5205374360084534,\n",
       " 2.5437068343162537,\n",
       " 2.57975372672081,\n",
       " 2.543302685022354,\n",
       " 2.5925569236278534,\n",
       " 2.6426506638526917,\n",
       " 2.53716379404068,\n",
       " 2.665119171142578,\n",
       " 2.5760648250579834,\n",
       " 2.5464828610420227,\n",
       " 2.6925702691078186,\n",
       " 2.699394106864929,\n",
       " 2.734301745891571,\n",
       " 2.557014524936676,\n",
       " 2.634938955307007,\n",
       " 2.668423354625702,\n",
       " 2.5109639763832092,\n",
       " 2.5863974392414093,\n",
       " 2.537377566099167,\n",
       " 2.7709325551986694,\n",
       " 2.526719868183136,\n",
       " 2.6529157161712646,\n",
       " 2.5881121158599854,\n",
       " 2.5962003469467163,\n",
       " 2.8232113122940063,\n",
       " 2.535020112991333,\n",
       " 2.637816548347473,\n",
       " 2.5371061861515045,\n",
       " 2.5236724615097046,\n",
       " 2.5587127804756165,\n",
       " 2.656728148460388,\n",
       " 2.5804904103279114,\n",
       " 2.7767003178596497,\n",
       " 2.68655726313591,\n",
       " 2.7783772945404053,\n",
       " 2.6533002853393555,\n",
       " 2.5807807445526123,\n",
       " 2.6671904921531677,\n",
       " 2.6195199489593506,\n",
       " 2.679015338420868,\n",
       " 2.541180431842804,\n",
       " 2.6654049456119537,\n",
       " 2.6435604095458984,\n",
       " 2.657424569129944,\n",
       " 2.707427531480789,\n",
       " 2.745473802089691,\n",
       " 2.6193549633026123,\n",
       " 2.529356688261032,\n",
       " 2.6307129859924316,\n",
       " 2.509999454021454,\n",
       " 2.600728303194046,\n",
       " 2.55228191614151,\n",
       " 2.6637516617774963,\n",
       " 2.741969406604767,\n",
       " 2.563503921031952,\n",
       " 2.591174602508545,\n",
       " 2.594743013381958,\n",
       " 2.7689660787582397,\n",
       " 2.566668301820755,\n",
       " 2.5723317861557007,\n",
       " 2.6218725442886353,\n",
       " 2.633164882659912,\n",
       " 2.790536403656006,\n",
       " 2.7294676303863525,\n",
       " 2.71255099773407,\n",
       " 2.659555971622467,\n",
       " 2.7100276350975037,\n",
       " 2.6501769721508026,\n",
       " 2.703046977519989,\n",
       " 2.715870440006256,\n",
       " 2.6250290870666504,\n",
       " 2.6587789058685303,\n",
       " 2.6372532844543457,\n",
       " 2.678102493286133,\n",
       " 2.5676034092903137,\n",
       " 2.7376667857170105,\n",
       " 2.513789117336273,\n",
       " 2.670210063457489,\n",
       " 2.717989146709442,\n",
       " 2.654042065143585,\n",
       " 2.626015365123749,\n",
       " 2.6114969849586487,\n",
       " 2.708011031150818,\n",
       " 2.537957191467285,\n",
       " 2.633284866809845,\n",
       " 2.545602798461914,\n",
       " 2.5607070922851562,\n",
       " 2.5740919709205627,\n",
       " 2.644956648349762,\n",
       " 2.523573637008667,\n",
       " 2.62953519821167,\n",
       " 2.5863662660121918,\n",
       " 2.6732266545295715,\n",
       " 2.5393890738487244,\n",
       " 2.6223718523979187,\n",
       " 2.580647647380829,\n",
       " 2.687923014163971,\n",
       " 2.5275120437145233,\n",
       " 2.6430487036705017,\n",
       " 2.690159261226654,\n",
       " 2.4941571056842804,\n",
       " 2.585588663816452,\n",
       " 2.602449417114258,\n",
       " 2.5471152663230896,\n",
       " 2.663093388080597,\n",
       " 2.503611207008362,\n",
       " 2.586283326148987,\n",
       " 2.6820029616355896,\n",
       " 2.4833999276161194,\n",
       " 2.70320725440979,\n",
       " 2.642477035522461,\n",
       " 2.612185925245285,\n",
       " 2.458220958709717,\n",
       " 2.572645843029022,\n",
       " 2.596847891807556,\n",
       " 2.677634537220001,\n",
       " 2.7022090554237366,\n",
       " 2.72136390209198,\n",
       " 2.5980737805366516,\n",
       " 2.6038819551467896,\n",
       " 2.5742200016975403,\n",
       " 2.5940581560134888,\n",
       " 2.587880551815033,\n",
       " 2.721848428249359,\n",
       " 2.580525189638138,\n",
       " 2.6303333044052124,\n",
       " 2.5820799469947815,\n",
       " 2.642738461494446,\n",
       " 2.6784969568252563,\n",
       " 2.5626116394996643,\n",
       " 2.6168439388275146,\n",
       " 2.6635693311691284,\n",
       " 2.6052127480506897,\n",
       " 2.593171238899231,\n",
       " 2.6142826974391937,\n",
       " 2.5514193177223206,\n",
       " 2.545634001493454,\n",
       " 2.6277015209198,\n",
       " 2.720214366912842,\n",
       " 2.666382074356079,\n",
       " 2.653751850128174,\n",
       " 2.4703965187072754,\n",
       " 2.709343671798706,\n",
       " 2.563564360141754,\n",
       " 2.629029393196106,\n",
       " 2.5356912910938263,\n",
       " 2.672051250934601,\n",
       " 2.5896406173706055,\n",
       " 2.648972272872925,\n",
       " 2.655658006668091,\n",
       " 2.6277260184288025,\n",
       " 2.6324161887168884,\n",
       " 2.6597760915756226,\n",
       " 2.599266469478607,\n",
       " 2.5678497552871704,\n",
       " 2.6740856170654297,\n",
       " 2.6704326272010803,\n",
       " 2.6038079261779785,\n",
       " 2.6105659008026123,\n",
       " 2.5920190811157227,\n",
       " 2.7400839924812317,\n",
       " 2.665759325027466,\n",
       " 2.624893605709076,\n",
       " 2.635828733444214,\n",
       " 2.652176082134247,\n",
       " 2.6322937607765198,\n",
       " 2.6239121556282043,\n",
       " 2.5415258407592773,\n",
       " 2.577166795730591,\n",
       " 2.539557993412018,\n",
       " 2.5775367617607117,\n",
       " 2.693925142288208,\n",
       " 2.5642783641815186,\n",
       " 2.588657021522522,\n",
       " 2.588720142841339,\n",
       " 2.7132888436317444,\n",
       " 2.627629041671753,\n",
       " 2.6055789589881897,\n",
       " 2.6201841831207275,\n",
       " 2.5645617842674255,\n",
       " 2.560526967048645,\n",
       " 2.6755459904670715,\n",
       " 2.5610867142677307,\n",
       " 2.6288722157478333,\n",
       " 2.577129900455475,\n",
       " 2.609550893306732,\n",
       " 2.573139011859894,\n",
       " 2.5207821130752563,\n",
       " 2.655105412006378,\n",
       " 2.7537792921066284,\n",
       " 2.5917540788650513,\n",
       " 2.7328765988349915,\n",
       " 2.654715418815613,\n",
       " 2.6170287132263184,\n",
       " 2.6298956274986267,\n",
       " 2.710571527481079,\n",
       " 2.5862786173820496,\n",
       " 2.650571882724762,\n",
       " 2.621244192123413,\n",
       " 2.5368919372558594,\n",
       " 2.6665326356887817,\n",
       " 2.620477855205536,\n",
       " 2.5636305809020996,\n",
       " 2.58453768491745,\n",
       " 2.632652223110199,\n",
       " 2.7395899295806885,\n",
       " 2.609215199947357,\n",
       " 2.608094811439514,\n",
       " 2.5935046076774597,\n",
       " 2.6564876437187195,\n",
       " 2.6040186285972595,\n",
       " 2.6570549607276917,\n",
       " 2.698081135749817,\n",
       " 2.6072428822517395,\n",
       " 2.6295852661132812,\n",
       " 2.675629138946533,\n",
       " 2.6528854370117188,\n",
       " 2.617886483669281,\n",
       " 2.578709304332733,\n",
       " 2.5713714957237244,\n",
       " 2.5442848801612854,\n",
       " 2.61999773979187,\n",
       " 2.629484176635742,\n",
       " 2.5362075567245483,\n",
       " 2.6556463837623596,\n",
       " 2.5991379022598267,\n",
       " 2.730484426021576,\n",
       " 2.5379955172538757,\n",
       " 2.6280638575553894,\n",
       " 2.652305245399475,\n",
       " 2.661427915096283,\n",
       " 2.6645994186401367,\n",
       " 2.6306836009025574,\n",
       " 2.588789165019989,\n",
       " 2.6339832544326782,\n",
       " 2.683819353580475,\n",
       " 2.6305829286575317,\n",
       " 2.610052704811096,\n",
       " 2.681493103504181,\n",
       " 2.746244251728058,\n",
       " 2.648435413837433,\n",
       " 2.6157097220420837,\n",
       " 2.673603355884552,\n",
       " 2.6765961050987244,\n",
       " 2.6509072184562683,\n",
       " 2.6388315558433533,\n",
       " 2.655493676662445,\n",
       " 2.6617191433906555,\n",
       " 2.65645432472229,\n",
       " 2.697993814945221,\n",
       " 2.661023795604706,\n",
       " 2.6879143118858337,\n",
       " 2.7148545384407043,\n",
       " 2.603005111217499,\n",
       " 2.63298499584198,\n",
       " 2.712624490261078,\n",
       " 2.679789423942566,\n",
       " 2.696032166481018,\n",
       " 2.696708023548126,\n",
       " 2.7478519082069397,\n",
       " 2.6207330226898193,\n",
       " 2.6851168274879456,\n",
       " 2.6943880319595337,\n",
       " 2.6098135113716125,\n",
       " 2.7311995029449463,\n",
       " 2.6423043608665466,\n",
       " 2.609681725502014,\n",
       " 2.6861245036125183,\n",
       " 2.685837507247925,\n",
       " 2.6515960693359375,\n",
       " 2.5745601058006287,\n",
       " 2.6066816449165344,\n",
       " 2.616319239139557,\n",
       " 2.6344210505485535,\n",
       " 2.6085758805274963,\n",
       " 2.6562931537628174,\n",
       " 2.606424570083618,\n",
       " 2.6449633836746216,\n",
       " 2.5999257564544678,\n",
       " 2.6302011013031006,\n",
       " 2.5703009366989136,\n",
       " 2.5574594736099243,\n",
       " 2.695441961288452,\n",
       " 2.6185548305511475,\n",
       " 2.5846990942955017,\n",
       " 2.6049899458885193,\n",
       " 2.6614553332328796,\n",
       " 2.655896484851837,\n",
       " 2.656605839729309,\n",
       " 2.599238932132721,\n",
       " 2.6878954768180847,\n",
       " 2.689119040966034,\n",
       " 2.6380012035369873,\n",
       " 2.6700595021247864,\n",
       " 2.613580644130707,\n",
       " 2.6528751850128174,\n",
       " 2.642657458782196,\n",
       " 2.710299789905548,\n",
       " 2.632502496242523,\n",
       " 2.62820827960968,\n",
       " 2.6389864087104797,\n",
       " 2.582216262817383,\n",
       " 2.788998007774353,\n",
       " 2.5980937480926514,\n",
       " 2.691378116607666,\n",
       " 2.695042133331299,\n",
       " 2.6891704201698303,\n",
       " 2.709075927734375,\n",
       " 2.7339596152305603,\n",
       " 2.701873481273651,\n",
       " 2.67145174741745,\n",
       " 2.698690414428711,\n",
       " 2.6815393567085266,\n",
       " 2.6561501026153564,\n",
       " 2.6192033886909485,\n",
       " 2.6966286301612854,\n",
       " 2.7162654995918274,\n",
       " 2.5671098828315735,\n",
       " 2.6735720038414,\n",
       " 2.5884047150611877,\n",
       " 2.7074832916259766,\n",
       " 2.6646764874458313,\n",
       " 2.6233635544776917,\n",
       " 2.720116376876831,\n",
       " 2.69315367937088,\n",
       " 2.6752447485923767,\n",
       " 2.644768238067627,\n",
       " 2.6279616951942444,\n",
       " 2.6236608028411865,\n",
       " 2.6423733234405518,\n",
       " 2.6560274362564087,\n",
       " 2.6728000044822693,\n",
       " 2.668902277946472,\n",
       " 2.696621060371399,\n",
       " 2.5982335805892944,\n",
       " 2.6553189754486084,\n",
       " 2.65805983543396,\n",
       " 2.627944231033325,\n",
       " 2.690672755241394,\n",
       " 2.7042987942695618,\n",
       " 2.6482841968536377,\n",
       " 2.734379470348358,\n",
       " 2.673634171485901,\n",
       " 2.7348170280456543,\n",
       " 2.661786735057831,\n",
       " 2.7122009992599487,\n",
       " 2.6620653867721558,\n",
       " 2.65930837392807,\n",
       " 2.6412513852119446,\n",
       " 2.666644811630249,\n",
       " 2.625281512737274,\n",
       " 2.6620659232139587,\n",
       " 2.651366174221039,\n",
       " 2.671343207359314,\n",
       " 2.644136369228363,\n",
       " 2.6306585669517517,\n",
       " 2.6070531606674194,\n",
       " 2.6995403170585632,\n",
       " 2.728129506111145,\n",
       " 2.6662298440933228,\n",
       " 2.6610292196273804,\n",
       " 2.6979793906211853,\n",
       " 2.649825870990753,\n",
       " 2.6464036107063293]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_mae_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then compute the average of the per-epoch MAE scores for all folds:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后你可以计算每个轮次中所有折 MAE 的平均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "average_mae_history = [\n",
    "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(average_mae_history) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It may be a bit hard to see the plot due to scaling issues and relatively high variance. Let's:\n",
    "\n",
    "* Omit the first 10 data points, which are on a different scale from the rest of the curve.\n",
    "* Replace each point with an exponential moving average of the previous points, to obtain a smooth curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为纵轴的范围较大，且数据方差相对较大，所以难以看清这张图的规律。我们来重新绘\n",
    "制一张图。  \n",
    "\n",
    "*  删除前 10 个数据点，因为它们的取值范围与曲线上的其他点不同。\n",
    "*  将每个数据点替换为前面数据点的指数移动平均值，以得到光滑的曲线。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$0.9*EMA(t-1)+0.1*EMA(t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 指数平滑 EMA\n",
    "def smooth_curve(points, factor=0.9):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points\n",
    "\n",
    "smooth_mae_history = smooth_curve(average_mae_history[10:]) #这里把前10个元素丢掉\n",
    "\n",
    "plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(smooth_mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(smooth_mae_history) # 选取到MAE最小的迭代次数+10（10为前面减去的）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "According to this plot, it seems that validation MAE stops improving significantly after 80 epochs. Past that point, we start overfitting.\n",
    "\n",
    "Once we are done tuning other parameters of our model (besides the number of epochs, we could also adjust the size of the hidden layers), we \n",
    "can train a final \"production\" model on all of the training data, with the best parameters, then look at its performance on the test data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完成模型调参之后（除了轮数，还可以调节隐藏层大小），你可以使用最佳参数在所有训练\n",
    "数据上训练最终的生产模型，然后观察模型在测试集上的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 997us/step - loss: 19.8285 - mae: 2.7067\n"
     ]
    }
   ],
   "source": [
    "# Get a fresh, compiled model.\n",
    "model = build_model()\n",
    "# Train it on the entirety of the data.\n",
    "model.fit(train_data, train_targets,\n",
    "          epochs=61, batch_size=16, verbose=0)\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7067432403564453"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mae_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are still off by about \\$2,550."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你预测的房价还是和实际价格相差约 2550 美元"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping up\n",
    "\n",
    "\n",
    "Here's what you should take away from this example:\n",
    "\n",
    "* Regression is done using different loss functions from classification; Mean Squared Error (MSE) is a commonly used loss function for \n",
    "regression.\n",
    "* Similarly, evaluation metrics to be used for regression differ from those used for classification; naturally the concept of \"accuracy\" \n",
    "does not apply for regression. A common regression metric is Mean Absolute Error (MAE).\n",
    "* When features in the input data have values in different ranges, each feature should be scaled independently as a preprocessing step.\n",
    "* When there is little data available, using K-Fold validation is a great way to reliably evaluate a model.\n",
    "* When little training data is available, it is preferable to use a small network with very few hidden layers (typically only one or two), \n",
    "in order to avoid severe overfitting.\n",
    "\n",
    "This example concludes our series of three introductory practical examples. You are now able to handle common types of problems with vector data input:\n",
    "\n",
    "* Binary (2-class) classification.\n",
    "* Multi-class, single-label classification.\n",
    "* Scalar regression.\n",
    "\n",
    "In the next chapter, you will acquire a more formal understanding of some of the concepts you have encountered in these first examples, \n",
    "such as data preprocessing, model evaluation, and overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6.5　小结  \n",
    "下面是你应该从这个例子中学到的要点。  \n",
    "\n",
    "*  回归问题使用的损失函数与分类问题不同。回归常用的损失函数是均方误差（MSE）。\n",
    "*  同样，回归问题使用的评估指标也与分类问题不同。显而易见，精度的概念不适用于回\n",
    "归问题。常见的回归指标是平均绝对误差（MAE）。\n",
    "*  如果输入数据的特征具有不同的取值范围，应该先进行预处理，对每个特征单独进行\n",
    "缩放。\n",
    "*  如果可用的数据很少，使用 K 折验证可以可靠地评估模型。\n",
    "*  如果可用的训练数据很少，最好使用隐藏层较少（通常只有一到两个）的小型网络，以\n",
    "避免严重的过拟合。\n",
    "*  现在你可以处理关于向量数据最常见的机器学习任务了：二分类问题、多分类问题和标\n",
    "量回归问题。前面三节的“小结”总结了你从这些任务中学到的要点。\n",
    "*  在将原始数据输入神经网络之前，通常需要对其进行预处理。\n",
    "*  如果数据特征具有不同的取值范围，那么需要进行预处理，将每个特征单独缩放。\n",
    "*  随着训练的进行，神经网络最终会过拟合，并在前所未见的数据上得到更差的结果。\n",
    "*  如果训练数据不是很多，应该使用只有一两个隐藏层的小型网络，以避免严重的过拟合。\n",
    "*  如果数据被分为多个类别，那么中间层过小可能会导致信息瓶颈。\n",
    "*  回归问题使用的损失函数和评估指标都与分类问题不同。\n",
    "*  如果要处理的数据很少，K 折验证有助于可靠地评估模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "174.176px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
